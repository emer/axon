// Code generated by "core generate -add-types -gosl"; DO NOT EDIT.

package armaze

import (
	"cogentcore.org/core/types"
)

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Arm", IDName: "arm", Doc: "Arm represents the properties of a given arm of the N-maze,\nrepresenting a different choice option with different cost / benefit\ntradeoffs, in terms of distance and effort factors for getting\ndown the arm, and US present at the end, which is delivered with\na given probability and magnitude range.\nEach arm has its own distinctive CS visible at the start, which is the\nonly cue used for the agent to decide whether to choose this arm or not.", Fields: []types.Field{{Name: "CS", Doc: "CS == index of Arm"}, {Name: "Length", Doc: "length of arm: distance from CS start to US end for this arm"}, {Name: "US", Doc: "index of US present at the end of this arm.\nIndexes [0:NDrives] are positive USs, and beyond that are negative USs."}, {Name: "Effort", Doc: "range of different effort levels per step (uniformly randomly sampled per step) for going down this arm"}, {Name: "USMag", Doc: "range of different US magnitudes (uniformly sampled)"}, {Name: "USProb", Doc: "probability of delivering the US"}, {Name: "USAvail", Doc: "USAvail indicates that the US is available on this trial: this is computed\nfrom the USProb at the start of each behavioral trial"}, {Name: "ExValue", Doc: "nominal expected value = US.Prob * US.Mag"}, {Name: "ExCost", Doc: "nominal expected cost = effort + normalized length"}, {Name: "ExUtil", Doc: "nominal expected utility = ExValue - CostFactor * ExCost.\nThis is only meaningful relative to other options, not in any absolute terms."}, {Name: "UtilGroup", Doc: "UtilGroup is the group id for computing the BestOption utility for this arm:\n= US for positive, and NDrives for all negative USs"}, {Name: "BestOption", Doc: "BestOption is true if this arm represents the best option in terms of ExUtil\nrelative to other options _for the same US_.\nAll negative USs are considered as one group for ranking."}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Params", IDName: "params", Doc: "Params are misc environment parameters", Fields: []types.Field{{Name: "TurnEffort", Doc: "effort for turning"}, {Name: "ConsumeEffort", Doc: "effort for consuming US"}, {Name: "CostFactor", Doc: "an arbitrary scaling factor for costs relative to values,\nused in computing the expected utility ExUtil for an arm.\nThese utilities are only useful for relative comparisons,\nthat go into computing the UtilRank, which should be used for evaluating\noverall choices."}, {Name: "ActiveDriveThr", Doc: "threshold for considering a drive to be active; used in evaluating whether\nan Arm choice is considered to be a good option."}, {Name: "AlwaysLeft", Doc: "always turn left -- zoolander style -- reduces degrees of freedom in evaluating behavior"}, {Name: "RandomStart", Doc: "after running down an Arm, a new random starting location is selected (otherwise same arm as last run)"}, {Name: "OpenArms", Doc: "if true, allow movement between arms just by going Left or Right.\nOtherwise once past the start, no switching is allowed"}, {Name: "Inactive", Doc: "strength of inactive inputs (e.g., Drives in Approach paradigm)"}, {Name: "NYReps", Doc: "number of Y-axis repetitions of localist stimuli -- for redundancy in spiking nets"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Config", IDName: "config", Doc: "Config has environment configuration", Fields: []types.Field{{Name: "Paradigm", Doc: "experimental paradigm that governs the configuration of environment based on params,\ne.g., how the Range values are assigned to different arms."}, {Name: "Debug", Doc: "for debugging, print out key steps including a trace of the action generation logic"}, {Name: "NDrives", Doc: "number of different drive-like body states (hunger, thirst, etc),\nthat are satisfied by a corresponding positive US outcome.\nThis is in addition to the first curiosity drive, which is always present."}, {Name: "NNegUSs", Doc: "number of negative US outcomes -- these are added after NDrives positive USs to total US list"}, {Name: "NUSs", Doc: "total number of USs = NDrives + NNegUSs"}, {Name: "NArms", Doc: "number of different arms, each of which has its own distinctive CS.\nThis is determined by the Paradigm (e.g., 2*NUSs for the Group cases)."}, {Name: "LengthRange", Doc: "range of arm length sallocated across arms, per Paradigm"}, {Name: "EffortRange", Doc: "range of effort values allocated across arms, per Paradigm"}, {Name: "USMagRange", Doc: "range of US magnitudes allocated across arms, per Paradigm"}, {Name: "USProbRange", Doc: "range of US probabilities allocated across arms, per Paradigm"}, {Name: "Arms", Doc: "parameters for each arm option: dist, effort, US"}, {Name: "Params", Doc: "misc params"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Geom", IDName: "geom", Doc: "Geom is overall geometry of the space", Fields: []types.Field{{Name: "ArmWidth", Doc: "width of arm -- emery rodent is 1 unit wide"}, {Name: "ArmSpace", Doc: "total space between arms, ends up being divided on either side"}, {Name: "LengthScale", Doc: "multiplier per unit arm length -- keep square with width"}, {Name: "Thick", Doc: "thickness of walls, floor"}, {Name: "Height", Doc: "height of walls"}, {Name: "ArmWidthTot", Doc: "width + space"}, {Name: "Depth", Doc: "computed total depth, starts at 0 goes deep"}, {Name: "Width", Doc: "computed total width"}, {Name: "HalfWidth", Doc: "half width for centering on 0 X"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.GUI", IDName: "gui", Doc: "GUI renders multiple views of the flat world env", Methods: []types.Method{{Name: "Left", Directives: []types.Directive{{Tool: "types", Directive: "add"}}}, {Name: "Right", Directives: []types.Directive{{Tool: "types", Directive: "add"}}}, {Name: "Forward", Directives: []types.Directive{{Tool: "types", Directive: "add"}}}, {Name: "Consume", Directives: []types.Directive{{Tool: "types", Directive: "add"}}}}, Fields: []types.Field{{Name: "Disp", Doc: "update display -- turn off to make it faster"}, {Name: "Env", Doc: "the env being visualized"}, {Name: "EnvName", Doc: "name of current env -- number is NData index"}, {Name: "SceneEditor", Doc: "3D visualization of the Scene"}, {Name: "Scene2D", Doc: "2D visualization of the Scene"}, {Name: "MatColors", Doc: "list of material colors"}, {Name: "StateColors", Doc: "internal state colors"}, {Name: "WallSize", Doc: "thickness (X) and height (Y) of walls"}, {Name: "State", Doc: "current internal / behavioral state"}, {Name: "Trace", Doc: "trace record of recent activity"}, {Name: "EnvForm", Doc: "view of the gui obj"}, {Name: "WorldTabs", Doc: "ArmMaze TabView"}, {Name: "IsRunning", Doc: "ArmMaze is running"}, {Name: "DepthValues", Doc: "current depth map"}, {Name: "Camera", Doc: "offscreen render camera settings"}, {Name: "DepthMap", Doc: "color map to use for rendering depth map"}, {Name: "EyeRFullImage", Doc: "first-person right-eye full field view"}, {Name: "EyeRFovImage", Doc: "first-person right-eye fovea view"}, {Name: "DepthImage", Doc: "depth map bitmap view"}, {Name: "USposPlot", Doc: "plot of positive valence drives, active OFC US state, and reward"}, {Name: "USposData", Doc: "data for USPlot"}, {Name: "USnegPlot", Doc: "plot of negative valence active OFC US state, and outcomes"}, {Name: "USnegData", Doc: "data for USPlot"}, {Name: "Geom", Doc: "geometry of world"}, {Name: "World", Doc: "world"}, {Name: "View3D", Doc: "3D view of world"}, {Name: "Emery", Doc: "emer group"}, {Name: "Arms", Doc: "arms group"}, {Name: "Stims", Doc: "stims group"}, {Name: "EyeR", Doc: "Right eye of emery"}, {Name: "Contacts", Doc: "contacts from last step, for body"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Actions", IDName: "actions", Doc: "Actions is a list of mutually exclusive states\nfor tracing the behavior and internal state of Emery"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Env", IDName: "env", Doc: "Env implements an N-armed maze (\"bandit\")\nwith each Arm having a distinctive CS stimulus visible at the start\n(could be one of multiple possibilities) and (some probability of)\na US outcome at the end of the maze (could be either positive\nor negative, with (variable) magnitude and probability.", Fields: []types.Field{{Name: "Name", Doc: "name of environment -- Train or Test"}, {Name: "Di", Doc: "our data parallel index"}, {Name: "Config", Doc: "configuration parameters"}, {Name: "Drives", Doc: "current drive strength for each of Config.NDrives in normalized\n0-1 units of each drive (beyond built-in curiosity drive)"}, {Name: "Arm", Doc: "current arm location: either facing (Pos=0) or in (Pos > 0)"}, {Name: "Pos", Doc: "current position in the Arm: 0 = at start looking in, otherwise at given distance into the arm"}, {Name: "Dist", Doc: "distance from US within current arm"}, {Name: "Tick", Doc: "current integer time step since last NewStart"}, {Name: "TrgDrive", Doc: "current target drive, in paradigms where that is used (e.g., Approach)"}, {Name: "USConsumed", Doc: "Current US being consumed -- is -1 unless being consumed"}, {Name: "USValue", Doc: "reward or punishment value generated by the current US being consumed.\njust the Magnitude of the US -- does NOT include any modulation by Drive"}, {Name: "JustConsumed", Doc: "just finished consuming a US -- ready to start doing something new"}, {Name: "LastAct", Doc: "last action taken"}, {Name: "Effort", Doc: "effort on current trial"}, {Name: "LastCS", Doc: "last CS seen"}, {Name: "LastUS", Doc: "last US -- previous trial"}, {Name: "ShouldGate", Doc: "true if looking at correct CS for first time"}, {Name: "JustGated", Doc: "just gated on this trial -- set by sim-- used for instinct"}, {Name: "HasGated", Doc: "has gated at some point during sequence -- set by sim -- used for instinct"}, {Name: "States", Doc: "named states -- e.g., USs, CSs, etc"}, {Name: "MaxLength", Doc: "maximum length of any arm"}, {Name: "Rand", Doc: "random number generator for the env -- all random calls must use this"}, {Name: "RandSeed", Doc: "random seed"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.Paradigms", IDName: "paradigms", Doc: "Paradigms is a list of experimental paradigms that\ngovern the configuration of the arms."})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.TraceStates", IDName: "trace-states", Doc: "TraceStates is a list of mutually exclusive states\nfor tracing the behavior and internal state of Emery"})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.TraceRec", IDName: "trace-rec", Doc: "TraceRec holds record of info for tracing behavior, state", Fields: []types.Field{{Name: "Time", Doc: "absolute time"}, {Name: "Trial", Doc: "trial counter"}, {Name: "Arm", Doc: "current arm"}, {Name: "Pos", Doc: "position in arm"}, {Name: "State", Doc: "behavioral / internal state summary"}, {Name: "Drives", Doc: "NDrives current drive state level"}}})

var _ = types.AddType(&types.Type{Name: "github.com/emer/axon/v2/sims/choose/armaze.StateTrace", IDName: "state-trace", Doc: "StateTrace holds trace records"})
