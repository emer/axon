// Copyright (c) 2023, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

// Package armaze represents an N-armed maze ("bandit")
// with each Arm having a distinctive CS stimulus at the start
// (could be one of multiple possibilities) and (some probability of)
// a US outcome at the end of the maze (could be either positive
// or negative, with (variable) magnitude and probability.
//
// The maze can have open or closed arms -- open arms allow
// switching to a neighboring arm anytime, while closed arms
// only allow switching at the start.
package armaze

//go:generate core generate -add-types -gosl

import (
	"fmt"

	"cogentcore.org/core/cli"
	"cogentcore.org/core/math32/minmax"
	"cogentcore.org/lab/base/randx"
	"cogentcore.org/lab/tensor"
)

// Actions is a list of mutually exclusive states
// for tracing the behavior and internal state of Emery
type Actions int32 //enums:enum

const (
	Forward Actions = iota
	Left
	Right
	Consume
	None
)

// General note on US / Drive indexes:
// The env does _not_ represent any built-in drives or USs (curiosity, effort, urgency)
// 0 = start of the sim-specific USs and Drives

// Env implements an N-armed maze ("bandit")
// with each Arm having a distinctive CS stimulus visible at the start
// (could be one of multiple possibilities) and (some probability of)
// a US outcome at the end of the maze (could be either positive
// or negative, with (variable) magnitude and probability.
type Env struct {

	// name of environment -- Train or Test
	Name string

	// our data parallel index
	Di int `edit:"-"`

	// configuration parameters
	Config Config `new-window:"+"`

	// current drive strength for each of Config.NDrives in normalized
	// 0-1 units of each drive (beyond built-in curiosity drive)
	Drives []float32

	// current arm location: either facing (Pos=0) or in (Pos > 0)
	Arm int `edit:"-"`

	// current position in the Arm: 0 = at start looking in, otherwise at given distance into the arm
	Pos int `edit:"-"`

	// distance from US within current arm
	Dist int `edit:"-"`

	// current integer time step since last NewStart
	Tick int `edit:"-"`

	// current target drive, in paradigms where that is used (e.g., Approach)
	TrgDrive int `edit:"-"`

	// Current US being consumed -- is -1 unless being consumed
	USConsumed int `edit:"-"`

	// reward or punishment value generated by the current US being consumed.
	// just the Magnitude of the US -- does NOT include any modulation by Drive
	USValue float32 `edit:"-"`

	// just finished consuming a US -- ready to start doing something new
	JustConsumed bool `edit:"-"`

	// last action taken
	LastAct Actions `edit:"-"`

	// effort on current trial
	Effort float32 `edit:"-"`

	// last CS seen
	LastCS int `edit:"-"`

	// last US -- previous trial
	LastUS int `edit:"-"`

	// true if looking at correct CS for first time
	ShouldGate bool `edit:"-"`

	// just gated on this trial -- set by sim-- used for instinct
	JustGated bool `edit:"-"`

	// has gated at some point during sequence -- set by sim -- used for instinct
	HasGated bool `edit:"-"`

	// named states -- e.g., USs, CSs, etc
	States map[string]*tensor.Float32

	// maximum length of any arm
	MaxLength int `edit:"-"`

	// random number generator for the env -- all random calls must use this
	Rand randx.SysRand `display:"-"`

	// random seed
	RandSeed int64 `edit:"-"`
}

func (ev *Env) Label() string { return ev.Name }

func (ev *Env) String() string { return fmt.Sprintf("%d_%d_%d", ev.Arm, ev.Pos, ev.Dist) }

// Defaults sets default params
func (ev *Env) Defaults() {
	ev.Config.Defaults()
	cli.SetFromDefaults(&ev.Config)
	ev.Config.Update()
}

// ConfigEnv configures the environment.
// additional parameterization via specific configs
// is applied after this step, which initializes
// everything according to basic Ns
// takes the data parallel index di
func (ev *Env) ConfigEnv(di int) {
	ev.Di = di
	if ev.Rand.Rand == nil {
		ev.Rand.NewRand(ev.RandSeed)
	} else {
		ev.Rand.Seed(ev.RandSeed)
	}

	switch ev.Config.Paradigm {
	case GroupGoodBad:
		ev.ConfigGroupGoodBad()
	}
	ev.ExpectedUtilities()
	ev.Validate()
}

func (ev *Env) Validate() error {
	return nil
}

// Init does updating preparing to run -- params could have changed since initial config
// so updates everything except broad overall config stuff.
func (ev *Env) Init(run int) {
	cfg := &ev.Config

	ev.UpdateMaxLength()

	ev.States = make(map[string]*tensor.Float32)
	ev.States["CS"] = tensor.NewFloat32(cfg.Params.NYReps, cfg.NArms)
	ev.States["Pos"] = tensor.NewFloat32(cfg.Params.NYReps, ev.MaxLength+1)
	ev.States["Dist"] = tensor.NewFloat32(cfg.Params.NYReps, ev.MaxLength+1)
	ev.States["Action"] = tensor.NewFloat32(cfg.Params.NYReps, int(ActionsN))

	ev.NewStart()
	ev.JustConsumed = true // will trigger a new start again on Step
}

func (ev *Env) State(el string) tensor.Values {
	return ev.States[el]
}

// NewStart starts a new approach run
func (ev *Env) NewStart() {
	for _, arm := range ev.Config.Arms { // do at start so it is consistent
		arm.USAvail = randx.BoolP32(arm.USProb, &ev.Rand)
	}
	if ev.Config.Params.RandomStart {
		ev.Arm = ev.Rand.Intn(len(ev.Config.Arms))
	}
	arm := ev.Config.Arms[ev.Arm]
	ev.Pos = 0
	ev.Dist = arm.Length - ev.Pos
	ev.Tick = 0
	ev.JustGated = false
	ev.HasGated = false
	ev.USConsumed = -1
	ev.USValue = 0
	ev.JustConsumed = false

	ev.TrgDrive = ev.Rand.Intn(ev.Config.NDrives)
	for i := range ev.Drives {
		if i == ev.TrgDrive {
			ev.Drives[i] = 1
		} else {
			ev.Drives[i] = ev.InactiveValue()
		}
	}
	ev.RenderState()
}

func (ev *Env) ExpectedUtilities() {
	ev.UpdateMaxLength()
	cfg := &ev.Config
	maxLen := float32(ev.MaxLength)
	nus := cfg.NDrives
	if cfg.NNegUSs > 0 {
		nus++
	}
	for ui := 0; ui < nus; ui++ {
		maxUtil := float32(0)
		for _, arm := range ev.Config.Arms {
			usSign := float32(1)
			if ui < cfg.NDrives {
				if arm.US != ui {
					continue
				}
				arm.UtilGroup = ui
			} else {
				usSign = -1
				if arm.US < cfg.NDrives { // no positive
					continue
				}
				arm.UtilGroup = ui
			}
			val := usSign * arm.USMag.Midpoint() * arm.USProb
			arm.ExValue = val
			cost := cfg.Params.CostFactor * ((float32(arm.Length) / maxLen) + arm.Effort.Midpoint())
			arm.ExCost = cost
			util := val - cost
			arm.ExUtil = util
			if util > maxUtil {
				maxUtil = util
			}
		}
		for _, arm := range ev.Config.Arms {
			if arm.UtilGroup != ui {
				continue
			}
			arm.BestOption = (arm.ExUtil >= maxUtil)
		}
	}
}

// ArmIsBest returns true if the given arm is the best choice,
// based on the arm being marked as BestChoice in terms of its
// general expected utility, and in terms of the US matching
// an active drive and not being a negative US outcome.
func (ev *Env) ArmIsBest(armIdx int) bool {
	arm := ev.Config.Arms[armIdx]
	if !arm.BestOption {
		return false
	}
	if ev.ArmIsNegative(armIdx) {
		return false
	}
	return ev.Drives[arm.US] > ev.Config.Params.ActiveDriveThr
}

func (ev *Env) MaxDrive() int {
	mx := float32(0)
	mi := 0
	for i, d := range ev.Drives {
		if d > mx {
			mx = d
			mi = i
		}
	}
	return mi
}

// ArmIsNegative returns true if the given arm has a negative outcome
func (ev *Env) ArmIsNegative(armIdx int) bool {
	arm := ev.Config.Arms[armIdx]
	return (arm.US > ev.Config.NDrives)
}

// Step does one step.  it is up to the driving sim to decide when to call NewStart
func (ev *Env) Step() bool {
	ev.LastCS = ev.CurCS()
	if ev.JustConsumed { // from last time, not this time.
		ev.NewStart()
	} else {
		ev.Tick++
	}
	ev.TakeAct(ev.LastAct)
	ev.RenderState()
	return true
}

//////////////////////////////////////////////////
//   Render

// RenderLocalist renders one localist state
func (ev *Env) RenderLocalist(name string, val int) {
	st := ev.States[name]
	st.SetZeros()
	if val >= st.DimSize(1) {
		return
	}
	for y := 0; y < ev.Config.Params.NYReps; y++ {
		st.Set(1.0, y, val)
	}
}

// RenderLocalist4D renders one localist state in 4D
func (ev *Env) RenderLocalist4D(name string, val int) {
	st := ev.States[name]
	st.SetZeros()
	for y := 0; y < ev.Config.Params.NYReps; y++ {
		st.Set(1.0, 0, val, y, 0)
	}
}

// RenderState renders the current state
func (ev *Env) RenderState() {
	ev.RenderLocalist("CS", ev.CurCS())
	ev.RenderLocalist("Pos", ev.Pos)
	ev.RenderLocalist("Dist", ev.Dist)
}

// RenderAction renders the action
func (ev *Env) RenderAction(act Actions) {
	ev.RenderLocalist("Action", int(act))
}

//////////////////////////////////////////////////
//   Action

func (ev *Env) DecodeAct(vt *tensor.Float32) Actions {
	mxi := ev.DecodeLocalist(vt)
	return Actions(mxi)
}

func (ev *Env) DecodeLocalist(vt *tensor.Float32) int {
	dx := vt.DimSize(1)
	var max float32
	var mxi int
	for i := 0; i < dx; i++ {
		var sum float32
		for j := 0; j < ev.Config.Params.NYReps; j++ {
			sum += vt.Value(j, i)
		}
		if sum > max {
			max = sum
			mxi = i
		}
	}
	return mxi
}

// Action records the LastAct and renders it, but does not
// update the state accordingly.
func (ev *Env) Action(action string, nop tensor.Values) {
	act := None
	act.SetString(action)
	ev.LastAct = act
	ev.RenderAction(act) // plus phase input is action
	// note: action not taken via TakeAct until start of trial in Step()
}

func (ev *Env) TakeAct(act Actions) {
	narms := ev.Config.NArms
	arm := ev.Config.Arms[ev.Arm]
	switch act {
	case Forward:
		ev.Effort = ev.ForwardEffort(arm) // pay effort regardless
		npos := ev.Pos + 1
		if npos <= arm.Length {
			ev.Pos = npos
		} else {
			// todo: bump into wall?
		}
	case Left:
		ev.Effort = ev.TurnEffort() // pay effort regardless
		if ev.Config.Params.OpenArms || ev.Pos == 0 {
			ev.Arm--
		}
		if ev.Arm < 0 {
			ev.Arm += narms
		}
	case Right:
		ev.Effort = ev.TurnEffort() // pay effort regardless
		if ev.Config.Params.OpenArms || ev.Pos == 0 {
			ev.Arm++
		}
		if ev.Arm >= narms {
			ev.Arm += narms
		}
	case Consume:
		ev.Effort = ev.ConsumeEffort()
		if ev.Pos == arm.Length {
			if ev.USConsumed < 0 {
				ev.ConsumeUS(arm)
			}
		}
	}
	// always update Dist
	arm = ev.Config.Arms[ev.Arm]
	ev.Dist = arm.Length - ev.Pos
}

// ConsumeUS implements the consume action at current position in given arm
func (ev *Env) ConsumeUS(arm *Arm) {
	mag := MinMaxRand(arm.USMag, ev.Rand)
	if arm.USAvail {
		ev.USConsumed = arm.US
		ev.USValue = mag
		ev.JustConsumed = true
	} else {
		ev.USConsumed = -1
		ev.USValue = 0
	}
}

// InstinctAct returns an "instinctive" action that implements a basic policy
func (ev *Env) InstinctAct(justGated, hasGated bool) Actions {
	ev.JustGated = justGated
	ev.HasGated = hasGated
	ev.ShouldGate = ((hasGated && ev.USConsumed >= 0) || // To clear the goal after US
		(!hasGated && ev.ArmIsBest(ev.Arm))) // looking at correct, haven't yet gated

	arm := ev.CurArm()
	if ev.Pos >= arm.Length {
		return Consume
	}
	if ev.HasGated {
		return Forward
	}
	if ev.LastAct == Left || ev.LastAct == Right {
		return ev.LastAct
	}
	if ev.Config.Params.AlwaysLeft || randx.BoolP(.5, &ev.Rand) {
		return Left
	}
	return Right
}

//////////////////////////////////////////////////
//   Utils

// CurArm returns current Arm
func (ev *Env) CurArm() *Arm {
	return ev.Config.Arms[ev.Arm]
}

// CurCS returns current CS from current Arm
func (ev *Env) CurCS() int {
	return ev.CurArm().CS
}

// MinMaxRand returns a random number in the range between Min and Max
func MinMaxRand(mm minmax.F32, rand randx.SysRand) float32 {
	return mm.Min + rand.Float32()*mm.Range()
}

// InactiveVal returns a new random inactive value from Config.Params.Inactive
// param range.
func (ev *Env) InactiveValue() float32 {
	return MinMaxRand(ev.Config.Params.Inactive, ev.Rand)
}

// ForwardEffort returns a new random Effort value from Arm Effort range
func (ev *Env) ForwardEffort(arm *Arm) float32 {
	return MinMaxRand(arm.Effort, ev.Rand)
}

// TurnEffort returns a new random Effort value from Config.Params.TurnEffort
// param range.
func (ev *Env) TurnEffort() float32 {
	return MinMaxRand(ev.Config.Params.TurnEffort, ev.Rand)
}

// ConsumeEffort returns a new random Effort value from Config.Params.ConsumeEffort
// param range.
func (ev *Env) ConsumeEffort() float32 {
	return MinMaxRand(ev.Config.Params.ConsumeEffort, ev.Rand)
}

func (ev *Env) UpdateMaxLength() {
	ev.MaxLength = 0
	for _, arm := range ev.Config.Arms {
		if arm.Length > ev.MaxLength {
			ev.MaxLength = arm.Length
		}
	}
}
