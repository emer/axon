[[Base]]
  Sel = "Layer"
  Desc = "all defaults"
  [Base.Params]
    "Layer.Acts.AK.Gbar" = "0.1"
    "Layer.Acts.Decay.Act" = "0.2"
    "Layer.Acts.Decay.Glong" = "0.6"
    "Layer.Acts.Dend.SSGi" = "2.0"
    "Layer.Acts.GabaB.Gbar" = "0.015"
    "Layer.Acts.Mahp.Gbar" = "0.02"
    "Layer.Acts.NMDA.Gbar" = "0.006"
    "Layer.Acts.NMDA.MgC" = "1.2"
    "Layer.Acts.NMDA.Tau" = "100"
    "Layer.Acts.NMDA.Voff" = "0"
    "Layer.Acts.Sahp.CaTau" = "5"
    "Layer.Acts.Sahp.Gbar" = "0.05"
    "Layer.Acts.Sahp.Off" = "0.8"
    "Layer.Acts.Sahp.Slope" = "0.02"
    "Layer.Acts.VGCC.Ca" = "25"
    "Layer.Acts.VGCC.Gbar" = "0.02"
    "Layer.Inhib.ActAvg.AdaptRate" = "0.1"
    "Layer.Inhib.ActAvg.HiTol" = "0.0"
    "Layer.Inhib.ActAvg.LoTol" = "0.8"
    "Layer.Inhib.ActAvg.Nominal" = "0.06"
    "Layer.Inhib.Layer.FB" = "0.5"
    "Layer.Inhib.Layer.FS0" = "0.1"
    "Layer.Inhib.Layer.FSTau" = "6"
    "Layer.Inhib.Layer.Gi" = "1.1"
    "Layer.Inhib.Layer.SS" = "30"
    "Layer.Inhib.Layer.SSfTau" = "20"
    "Layer.Inhib.Layer.SSiTau" = "50"
    "Layer.Learn.CaLearn.Dt.MTau" = "2"
    "Layer.Learn.CaLearn.Norm" = "80"
    "Layer.Learn.CaLearn.SpkVGCC" = "true"
    "Layer.Learn.CaLearn.SpkVgccCa" = "35"
    "Layer.Learn.CaLearn.UpdtThr" = "0.01"
    "Layer.Learn.CaLearn.VgccTau" = "10"
    "Layer.Learn.CaSpk.Dt.MTau" = "5"
    "Layer.Learn.CaSpk.SpikeG" = "8"
    "Layer.Learn.CaSpk.SynTau" = "30"
    "Layer.Learn.LrnNMDA.Gbar" = "0.006"
    "Layer.Learn.LrnNMDA.MgC" = "1.4"
    "Layer.Learn.LrnNMDA.Tau" = "100"
    "Layer.Learn.LrnNMDA.Voff" = "0"
    "Layer.Learn.RLRate.Diff" = "true"
    "Layer.Learn.RLRate.DiffThr" = "0.02"
    "Layer.Learn.RLRate.Min" = "0.001"
    "Layer.Learn.RLRate.On" = "true"
    "Layer.Learn.RLRate.SigmoidMin" = "0.05"
    "Layer.Learn.RLRate.SpkThr" = "0.1"
    "Layer.Learn.TrgAvgAct.RescaleOn" = "true"
    "Layer.Learn.TrgAvgAct.SubMean" = "1"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#Input"
  Desc = "critical now to specify the activity level"
  [Base.Params]
    "Layer.Acts.Clamp.Ge" = "1.5"
    "Layer.Acts.Decay.Act" = "1"
    "Layer.Acts.Decay.Glong" = "1"
    "Layer.Acts.VGCC.Ca" = "1"
    "Layer.Inhib.ActAvg.Nominal" = "0.15"
    "Layer.Inhib.Layer.Gi" = "0.9"

[[Base]]
  Sel = ".SuperLayer"
  Desc = ""
  [Base.Params]
    "Layer.Inhib.ActAvg.AdaptGi" = "true"
    "Layer.Inhib.ActAvg.Nominal" = "0.06"
    "Layer.Inhib.Layer.Gi" = "1.1"

[[Base]]
  Sel = "#Output"
  Desc = "output definitely needs lower inhib -- true for smaller layers in general"
  [Base.Params]
    "Layer.Acts.Clamp.Ge" = "0.8"
    "Layer.Acts.Spikes.Tr" = "1"
    "Layer.Acts.VGCC.Ca" = "1"
    "Layer.Inhib.ActAvg.AdaptGi" = "true"
    "Layer.Inhib.ActAvg.Nominal" = "0.24"
    "Layer.Inhib.Layer.FB" = "0.5"
    "Layer.Inhib.Layer.Gi" = "0.65"
    "Layer.Inhib.Layer.SS" = "30"
    "Layer.Learn.RLRate.On" = "true"
    "Layer.Learn.RLRate.SigmoidMin" = "0.05"

[[Base]]
  Sel = "Prjn"
  Desc = "basic prjn params"
  [Base.Params]
    "Prjn.Learn.KinaseCa.Dt.DTau" = "40"
    "Prjn.Learn.KinaseCa.Dt.MTau" = "5"
    "Prjn.Learn.KinaseCa.Dt.PTau" = "40"
    "Prjn.Learn.KinaseCa.SpikeG" = "12"
    "Prjn.Learn.LRate.Base" = "0.1"
    "Prjn.Learn.Trace.SubMean" = "1"
    "Prjn.Learn.Trace.Tau" = "1"
    "Prjn.SWts.Adapt.LRate" = "0.1"
    "Prjn.SWts.Adapt.SubMean" = "1"
    "Prjn.SWts.Init.SPct" = "0.5"

[[Base]]
  Sel = "#Hidden2ToOutput"
  Desc = ""
  [Base.Params]
    "Prjn.SWts.Adapt.SigGain" = "6"

[[Base]]
  Sel = ".BackPrjn"
  Desc = "top-down back-projections MUST have lower relative weight scale, otherwise network hallucinates"
  [Base.Params]
    "Prjn.PrjnScale.Rel" = "0.3"
