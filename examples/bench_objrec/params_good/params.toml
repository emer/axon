[[Base]]
  Sel = "Layer"
  Desc = "needs some special inhibition and learning params"
  [Base.Params]
    "Layer.Acts.Decay.Act" = "0.0"
    "Layer.Acts.Decay.Glong" = "0.6"
    "Layer.Acts.GabaB.Gbar" = "0.015"
    "Layer.Acts.NMDA.Gbar" = "0.006"
    "Layer.Acts.NMDA.MgC" = "1.4"
    "Layer.Acts.NMDA.Voff" = "0"
    "Layer.Learn.CaSpk.SpikeG" = "12"
    "Layer.Learn.LrnNMDA.Gbar" = "0.006"
    "Layer.Learn.LrnNMDA.MgC" = "1.4"
    "Layer.Learn.LrnNMDA.Tau" = "100"
    "Layer.Learn.LrnNMDA.Voff" = "0"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#V1"
  Desc = "pool inhib (not used), initial activity"
  [Base.Params]
    "Layer.Acts.Clamp.Ge" = "1.5"
    "Layer.Acts.Decay.Act" = "1"
    "Layer.Acts.Decay.Glong" = "1"
    "Layer.Inhib.ActAvg.Nominal" = "0.08"
    "Layer.Inhib.Layer.FB" = "1"
    "Layer.Inhib.Layer.Gi" = "0.9"
    "Layer.Inhib.Pool.FB" = "1"
    "Layer.Inhib.Pool.Gi" = "0.9"
    "Layer.Inhib.Pool.On" = "true"

[[Base]]
  Sel = "#V4"
  Desc = "pool inhib, sparse activity"
  [Base.Params]
    "Layer.Inhib.ActAvg.AdaptGi" = "true"
    "Layer.Inhib.ActAvg.Nominal" = "0.03"
    "Layer.Inhib.Layer.FB" = "1"
    "Layer.Inhib.Layer.Gi" = "1.0"
    "Layer.Inhib.Layer.SS" = "30"
    "Layer.Inhib.Pool.FB" = "4"
    "Layer.Inhib.Pool.Gi" = "0.9"
    "Layer.Inhib.Pool.On" = "true"
    "Layer.Inhib.Pool.SS" = "30"

[[Base]]
  Sel = "#IT"
  Desc = "initial activity"
  [Base.Params]
    "Layer.Inhib.ActAvg.AdaptGi" = "true"
    "Layer.Inhib.ActAvg.Nominal" = "0.04"
    "Layer.Inhib.Layer.FB" = "4"
    "Layer.Inhib.Layer.Gi" = "1.1"

[[Base]]
  Sel = "#Output"
  Desc = "high inhib for one-hot output"
  [Base.Params]
    "Layer.Acts.Clamp.Ge" = "0.8"
    "Layer.Inhib.ActAvg.AdaptGi" = "true"
    "Layer.Inhib.ActAvg.Nominal" = "0.05"
    "Layer.Inhib.ActAvg.Offset" = "-0.005"
    "Layer.Inhib.Layer.FB" = "1"
    "Layer.Inhib.Layer.Gi" = "1.2"

[[Base]]
  Sel = "Prjn"
  Desc = "yes extra learning factors"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"
    "Prjn.Learn.Trace.SubMean" = "1"
    "Prjn.SWts.Adapt.LRate" = "0.0001"
    "Prjn.SWts.Init.SPct" = "1"

[[Base]]
  Sel = ".BackPrjn"
  Desc = "top-down back-projections MUST have lower relative weight scale, otherwise network hallucinates -- smaller as network gets bigger"
  [Base.Params]
    "Prjn.PrjnScale.Rel" = "0.2"
