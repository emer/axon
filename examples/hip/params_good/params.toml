[[Base]]
  Sel = ".InhibLateral"
  Desc = "circle lateral inhibitory connection -- good params, longer time, more ABmem"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.PrjnScale.Abs" = "0.1"
    "Prjn.SWts.Init.Sym" = "false"
    "Prjn.SWts.Init.Var" = "0"

[[Base]]
  Sel = ".EcCa1Prjn"
  Desc = "encoder projections -- Abs only affecting ec3toca1 and ec5toca1, not ca1toec5"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"
    "Prjn.PrjnScale.Abs" = "0.1"

[[Base]]
  Sel = ".HippoCHL"
  Desc = "hippo CHL projections -- no norm, moment, but YES wtbal = sig better"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"
    "Prjn.Learn.Learn" = "true"

[[Base]]
  Sel = ".PPath"
  Desc = "performant path, new Dg error-driven EcCa1Prjn prjns"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"
    "Prjn.Learn.Learn" = "true"

[[Base]]
  Sel = "#CA1ToEC5"
  Desc = "extra strong from CA1 to EC5"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.4"
    "Prjn.PrjnScale.Abs" = "3.0"

[[Base]]
  Sel = "#InputToEC2"
  Desc = "for CAN ec2"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.PrjnScale.Rel" = "2.0"

[[Base]]
  Sel = "#InputToEC3"
  Desc = "one-to-one input to EC"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.SWts.Init.Mean" = "0.8"
    "Prjn.SWts.Init.Var" = "0.0"

[[Base]]
  Sel = "#EC3ToEC2"
  Desc = "copied from InputToEC2"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.PrjnScale.Abs" = "0.5"

[[Base]]
  Sel = "#EC5ToEC3"
  Desc = "one-to-one out to in"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.PrjnScale.Rel" = "0.5"
    "Prjn.SWts.Init.Mean" = "0.9"
    "Prjn.SWts.Init.Var" = "0.01"

[[Base]]
  Sel = "#DGToCA3"
  Desc = "Mossy fibers: strong, non-learning"
  [Base.Params]
    "Prjn.Learn.Learn" = "false"
    "Prjn.PrjnScale.Abs" = "0.3"
    "Prjn.PrjnScale.Rel" = "4"
    "Prjn.SWts.Init.Var" = "0.01"

[[Base]]
  Sel = "#CA3ToCA3"
  Desc = "CA3 recurrent cons: rel=2 still the best"
  [Base.Params]
    "Prjn.PrjnScale.Abs" = "0.3"
    "Prjn.PrjnScale.Rel" = "2"

[[Base]]
  Sel = "#EC2ToDG"
  Desc = "DG learning is surprisingly critical: maxed out fast, hebbian works best"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"
    "Prjn.Learn.Learn" = "true"
    "Prjn.PrjnScale.Abs" = "0.7"

[[Base]]
  Sel = "#CA3ToCA1"
  Desc = "Schaffer collaterals -- slower, less hebb"
  [Base.Params]
    "Prjn.Learn.LRate.Base" = "0.2"

[[Base]]
  Sel = "#EC5ToCA1"
  Desc = "EC5 Perforant Path"
  [Base.Params]
    "Prjn.PrjnScale.Rel" = "0.3"

[[Base]]
  Sel = ".EC"
  Desc = "all EC layers: only pools, no layer-level -- now for EC3 and EC5"
  [Base.Params]
    "Layer.Acts.Clamp.Ge" = "1.4"
    "Layer.Inhib.ActAvg.Nominal" = "0.05"
    "Layer.Inhib.Layer.On" = "false"
    "Layer.Inhib.Pool.Gi" = "1.1"
    "Layer.Inhib.Pool.On" = "true"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#DG"
  Desc = "very sparse = high inhibition"
  [Base.Params]
    "Layer.Inhib.ActAvg.Nominal" = "0.01"
    "Layer.Inhib.Layer.Gi" = "2.4"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#EC2"
  Desc = "very sparse = high inhibition"
  [Base.Params]
    "Layer.Inhib.ActAvg.Nominal" = "0.02"
    "Layer.Inhib.Layer.Gi" = "1.2"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#CA3"
  Desc = "sparse = high inhibition"
  [Base.Params]
    "Layer.Inhib.ActAvg.Nominal" = "0.01"
    "Layer.Inhib.Layer.Gi" = "1.2"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"

[[Base]]
  Sel = "#CA1"
  Desc = "CA1 only Pools"
  [Base.Params]
    "Layer.Inhib.ActAvg.Nominal" = "0.03"
    "Layer.Inhib.Layer.On" = "false"
    "Layer.Inhib.Pool.Gi" = "1.1"
    "Layer.Inhib.Pool.On" = "true"
    "Layer.Learn.TrgAvgAct.SynScaleRate" = "0.0002"
