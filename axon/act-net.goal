// Copyright (c) 2019, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package axon

import (
	"cogentcore.org/core/enums"
)

// Cycle runs one cycle of activation updating, equivalent to 1 msec.
// If getNeurons is true, then neuron state is synced back
// from the GPU (for cycle-level display etc). Otherwise, nothing is.
func (nt *Network) Cycle(getNeurons bool) {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	ld := int(nix.NLayers * ctx.NData)
	pd := int(nix.NPools * ctx.NData)

	RunGatherSpikes(nd)
	RunLayerGi(ld)
	RunBetweenGi(ld)
	RunPoolGi(pd)
	RunCycleNeuron(nd)
	RunSendSpike(nd)
	RunCyclePost(ld)
	RunCycleInc(1)

	if getNeurons {
		RunDoneLayersNeurons()
	}

	// todo: fix this:
	// var ldt, vta *Layer
	// for _, ly := range nt.Layers {
	// 	if ly.Type == VTALayer {
	// 		vta = ly
	// 	} else if ly.Type == LDTLayer {
	// 		ldt = ly
	// 	} else {
	// 		ly.CyclePost(ctx)
	// 	}
	// }
	// // ordering of these is important
	// if ldt != nil {
	// 	ldt.CyclePost(ctx)
	// }
	// if vta != nil {
	// 	vta.CyclePost(ctx)
	// }
}

// ThetaCycleStart starts a new theta cycle, resetting the ctx.Cycle counter
// and all phase state information in the context.
// The current Context.NData should be set properly prior to calling this
// and subsequent Cycle methods.
func (nt *Network) ThetaCycleStart(mode enums.Enum, testing bool) {
	ctx := nt.Context()
	ctx.ThetaCycleStart(mode, testing)
	ToGPUCtxGlobal()
}

// MinusPhaseStart should be called at the start of a new minus phase,
// handling all initialization prior to applying a new input pattern.
func (nt *Network) MinusPhaseStart() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	ctx.MinusPhaseStart()
	ToGPUCtxGlobal()
	RunNewStateLayer(int(nix.NLayers))
	RunNewStateNeuron(nd)
	RunInitGBuffsPath(int(nix.NPaths))
	// note: not completed until run cycles
}

// InitExt initializes external input state.
// Call prior to applying external inputs to layers.
func (nt *Network) InitExt() {
	// note: important to do this for GPU
	// to ensure partial inputs work the same way on CPU and GPU.
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitExt()
	}
}

// ApplyExts applies external inputs to layers, based on values
// that were set in prior layer-specific ApplyExt calls.
// This does nothing on the CPU, but is critical for the GPU,
// and should be added to all sims where GPU will be used.
func (nt *Network) ApplyExts() {
	if !UseGPU {
		return
	}
	ToGPUExts()
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunApplyExtsNeuron(nd)
}

// Beta1 does updating at Beta1 timescale.
func (nt *Network) Beta1() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunBeta1Neuron(nd)
}

// Beta2 does updating at Beta1 timescale.
func (nt *Network) Beta2() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunBeta2Neuron(nd)
}

// MinusPhaseEnd does updating after end of minus phase.
func (nt *Network) MinusPhaseEnd() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunMinusPhasePool(int(nix.NPools))
	RunMinusPhaseNeuron(nd)
	RunMinusPhasePost(int(nix.NLayers))
	RunDoneLayersNeurons() // this is critical for action-taking models to have the minus phase state
}

// PlusPhaseStart does updating at the start of the plus phase:
// applies Target inputs as External inputs.
func (nt *Network) PlusPhaseStart() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)

	RunPlusPhaseStartContext(1)
	RunPlusPhaseStartNeuron(nd)
}

// PlusPhaseEnd does updating after end of plus phase.
// On GPU this is when we finally sync back Layers and Neurons.
func (nt *Network) PlusPhaseEnd() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	// fmt.Println("plus start:", ctx.Cycle)
	nd := int(nix.NNeurons * ctx.NData)
	pd := int(nix.NPools * ctx.NData)
	RunPlusPhaseEndPool(pd)
	RunPlusPhaseEndNeuron(nd)
	RunPlusPhaseEndPost(int(nix.NLayers))
	RunDoneLayersNeurons()
	// fmt.Println("plus post sync:", ctx.Cycle)
}

// TargToExt sets external input Ext from target values Target
// This is done at end of MinusPhase to allow targets to drive activity in plus phase.
// This can be called separately to simulate alpha cycles within theta cycles, for example.
func (nt *Network) TargToExt() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.TargToExt(ctx)
	}
}

// ClearTargExt clears external inputs Ext that were set from target values Target.
// This can be called to simulate alpha cycles within theta cycles, for example.
func (nt *Network) ClearTargExt() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.ClearTargExt(ctx)
	}
}

// GPUTestWrite writes values to neuron, for testing
func (nt *Network) GPUTestWrite() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunGPUTestWrite(nd)
	RunDoneLayersNeurons()
}

//gosl:start

//////// Kernels for all parallel CPU / GPU compute are here:

// GatherSpikes is the kernel over Neurons * Data for gathering
// spike inputs sent on the previous cycle.
func GatherSpikes(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].GatherSpikes(ctx, ni, di)
}

// LayerGi is the kernel over Layers * Data for updating Gi inhibition.
func LayerGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	li := ctx.ItemIndex(i)
	if li >= NetworkIxs[0].NLayers {
		return
	}
	di := ctx.DataIndex(i)
	Layers[li].LayerGi(ctx, li, di)
}

// BetweenGi is the kernel over Layers * Data for updating Gi
// inhibition between layers.
func BetweenGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	li := ctx.ItemIndex(i)
	if li >= NetworkIxs[0].NLayers {
		return
	}
	di := ctx.DataIndex(i)
	Layers[li].BetweenGi(ctx, di)
}

// PoolGi is the kernel over Pools * Data for updating Gi inhibition.
func PoolGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	pi := ctx.ItemIndex(i)
	if pi >= NetworkIxs[0].NPools {
		return
	}
	di := ctx.DataIndex(i)
	PoolPoolGi(ctx, pi, di)
}

// CycleNeuron is the kernel over Neurons * Data to do
// one cycle (msec) of updating at the neuron level.
func CycleNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].CycleNeuron(ctx, ni, di)
}

// SendSpike is the kernel over Neurons * Data to
// send spike signal for neurons over threshold.
func SendSpike(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].SendSpike(ctx, ni, di)
}

// CyclePost is the kernel over Layers * Data to
// update state after each Cycle of updating.
func CyclePost(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	li := ctx.ItemIndex(i)
	if li >= NetworkIxs[0].NLayers {
		return
	}
	di := ctx.DataIndex(i)
	Layers[li].CyclePost(ctx, di)
}

// CycleInc is the kernel over 1 call to increment the cycle counter.
func CycleInc(i uint32) { //gosl:kernel read-write:Ctx
	if i != 0 {
		return
	}
	ctx := GetCtx(0)
	ctx.CycleInc()
}

// ApplyExtsNeuron is the kernel over Neurons * Data to
// apply Ext external input to the neurons receiving inputs.
func ApplyExtsNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].ApplyExtsNeuron(ni, di)
}

// NewStateLayer is the kernel over Layers (not Data)
// which does new state on pools as well.
func NewStateLayer(li uint32) { //gosl:kernel
	ctx := GetCtx(0)
	Layers[li].NewStateLayer(ctx)
}

// NewStateNeuron is the kernel over Neurons * Data to
// do new state on neurons (decay).
func NewStateNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].NewStateNeuron(ctx, ni, di)
}

// InitGBuffsPath is the kernel over Paths to
// initialize PathGBuf, PathGSyns.
func InitGBuffsPath(pti uint32) { //gosl:kernel
	ctx := GetCtx(0)
	Paths[pti].InitGBuffs(ctx)
}

// Beta1Neuron is the kernel over Neurons * Data to
// do neuron-level updating at Beta1.
func Beta1Neuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].Beta1Neuron(ctx, ni, di)
}

// Beta2Neuron is the kernel over Neurons * Data to
// do neuron-level updating at Beta1.
func Beta2Neuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].Beta2Neuron(ctx, ni, di)
}

////////  Minus Phase

// MinusPhasePool is the kernel over Pools to
// do pool-level updating after end of minus phase.
func MinusPhasePool(pi uint32) { //gosl:kernel
	ctx := GetCtx(0)
	li := PoolIxs[pi, PoolLayerIdx]
	Layers[li].MinusPhasePool(ctx, pi)
}

// MinusPhaseNeuron is the kernel over Neurons * Data to
// do neuron-level updating after end of minus phase.
func MinusPhaseNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].MinusPhaseNeuron(ctx, ni, di)
}

// MinusPhasePost does special algorithm post processing.
func MinusPhasePost(li uint32) { //gosl:kernel
	ctx := GetCtx(0)
	Layers[li].MinusPhasePost(ctx)
}

// PlusPhaseStartContext is the kernel over 1 call to call PlusPhaseStart on context.
func PlusPhaseStartContext(i uint32) { //gosl:kernel read-write:Ctx
	if i != 0 {
		return
	}
	ctx := GetCtx(0)
	ctx.PlusPhaseStart()
}

// PlusPhaseStartNeuron is the kernel over Neurons * Data to
// do neuron-level updating at start of plus phase.
func PlusPhaseStartNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].PlusPhaseStartNeuron(ctx, ni, di)
}

// PlusPhaseEndPool is the kernel over Pools * Data to
// do pool-level updating after end of plus phase.
func PlusPhaseEndPool(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	pi := ctx.ItemIndex(i)
	if pi >= NetworkIxs[0].NPools {
		return
	}
	di := ctx.DataIndex(i)
	li := PoolIxs[pi, PoolLayerIdx]
	Layers[li].PlusPhaseEndPool(ctx, pi, di)
}

// PlusPhaseEndNeuron is the kernel over Neurons * Data to
// do neuron-level updating after end of plus phase.
func PlusPhaseEndNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	li := NeuronIxs[ni, NrnLayIndex]
	Layers[li].PlusPhaseEndNeuron(ctx, ni, di)
}

// PlusPhaseEndPost does special algorithm post processing.
func PlusPhaseEndPost(li uint32) { //gosl:kernel
	ctx := GetCtx(0)
	Layers[li].PlusPhaseEndPost(ctx)
}

// GPUTestWrite is the kernel over Neurons * Data for testing
// the unique writing of data on GPU.
func GPUTestWrite(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	ni := ctx.ItemIndex(i)
	if ni >= NetworkIxs[0].NNeurons {
		return
	}
	di := ctx.DataIndex(i)
	for vi := Spike; vi < NeuronVarsN; vi++ {
		Neurons[ni, di, vi] = float32(ni*1000 + uint32(vi))
	}
}

//gosl:end
