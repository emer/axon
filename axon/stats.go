// Code generated by "goal build"; DO NOT EDIT.
//line stats.goal:1
// Copyright (c) 2019, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package axon

import (
	"log"

	"cogentcore.org/core/math32"
	"cogentcore.org/core/math32/minmax"
)

// PctUnitErr returns the proportion of units where the thresholded value of
// Target (Target or Compare types) or ActP does not match that of ActM.
// If Act > ly.Params.Acts.Clamp.ErrThr, effective activity = 1 else 0
// robust to noisy activations.
// returns one result per data parallel index ([ctx.NData])
func (ly *Layer) PctUnitErr(ctx *Context) []float64 {
	nn := ly.NNeurons
	if nn == 0 {
		return nil
	}
	errs := make([]float64, ctx.NData)
	thr := ly.Params.Acts.Clamp.ErrThr
	for di := uint32(0); di < ctx.NData; di++ {
		wrong := 0
		n := 0
		for lni := uint32(0); lni < nn; lni++ {
			ni := ly.NeurStIndex + lni
			if NeuronIsOff(ni) {
				continue
			}
			trg := false
			if ly.Type == CompareLayer || ly.Type == TargetLayer {
				if Neurons.Value(int(ni), int(di), int(Target)) > thr {
					trg = true
				}
			} else {
				if Neurons.Value(int(ni), int(di), int(ActP)) > thr {
					trg = true
				}
			}
			if Neurons.Value(int(ni), int(di), int(ActM)) > thr {
				if !trg {
					wrong++
				}
			} else {
				if trg {
					wrong++
				}
			}
			n++
		}
		if n > 0 {
			errs[di] = float64(wrong) / float64(n)
		}
	}
	return errs
}

// LocalistErr2D decodes a 2D layer with Y axis = redundant units, X = localist units
// returning the indexes of the max activated localist value in the minus and plus phase
// activities, and whether these are the same or different (err = different)
// returns one result per data parallel index ([ctx.NData])
func (ly *Layer) LocalistErr2D(ctx *Context) (err []bool, minusIndex, plusIndex []int) {
	err = make([]bool, ctx.NData)
	minusIndex = make([]int, ctx.NData)
	plusIndex = make([]int, ctx.NData)
	ydim := ly.Shape.DimSize(0)
	xdim := ly.Shape.DimSize(1)
	for di := uint32(0); di < ctx.NData; di++ {
		var maxM, maxP float32
		var mIndex, pIndex int
		for xi := 0; xi < xdim; xi++ {
			var sumP, sumM float32
			for yi := 0; yi < ydim; yi++ {
				lni := uint32(yi*xdim + xi)
				ni := ly.NeurStIndex + lni
				sumM += Neurons.Value(int(ni), int(di), int(ActM))
				sumP += Neurons.Value(int(ni), int(di), int(ActP))
			}
			if sumM > maxM {
				mIndex = xi
				maxM = sumM
			}
			if sumP > maxP {
				pIndex = xi
				maxP = sumP
			}
		}
		er := mIndex != pIndex
		err[di] = er
		minusIndex[di] = mIndex
		plusIndex[di] = pIndex
	}
	return
}

// LocalistErr4D decodes a 4D layer with each pool representing a localist value.
// Returns the flat 1D indexes of the max activated localist value in the minus and plus phase
// activities, and whether these are the same or different (err = different)
func (ly *Layer) LocalistErr4D(ctx *Context) (err []bool, minusIndex, plusIndex []int) {
	err = make([]bool, ctx.NData)
	minusIndex = make([]int, ctx.NData)
	plusIndex = make([]int, ctx.NData)
	npool := ly.Shape.DimSize(0) * ly.Shape.DimSize(1)
	nun := ly.Shape.DimSize(2) * ly.Shape.DimSize(3)
	for di := uint32(0); di < ctx.NData; di++ {
		var maxM, maxP float32
		var mIndex, pIndex int
		for xi := 0; xi < npool; xi++ {
			var sumP, sumM float32
			for yi := 0; yi < nun; yi++ {
				lni := uint32(xi*nun + yi)
				ni := ly.NeurStIndex + lni
				sumM += Neurons.Value(int(ni), int(di), int(ActM))
				sumP += Neurons.Value(int(ni), int(di), int(ActP))
			}
			if sumM > maxM {
				mIndex = xi
				maxM = sumM
			}
			if sumP > maxP {
				pIndex = xi
				maxP = sumP
			}
		}
		er := mIndex != pIndex
		err[di] = er
		minusIndex[di] = mIndex
		plusIndex[di] = pIndex
	}
	return
}

// AvgMaxVarByPool returns the average and maximum value of given variable
// for given pool index (0 = entire layer, 1.. are subpools for 4D only).
// Uses fast index-based variable access.
func (ly *Layer) AvgMaxVarByPool(ctx *Context, varNm string, poolIndex, di int) minmax.AvgMax32 {
	var am minmax.AvgMax32
	vidx, err := ly.UnitVarIndex(varNm)
	if err != nil {
		log.Printf("axon.Layer.AvgMaxVar: %s\n", err)
		return am
	}
	pi := ly.Params.PoolIndex(uint32(poolIndex))
	nsi := PoolsInt.Value(int(pi), int(PoolNeurSt), int(di))
	nei := PoolsInt.Value(int(pi), int(PoolNeurEd), int(di))
	am.Init()
	for lni := nsi; lni < nei; lni++ {
		ni := ly.NeurStIndex + uint32(lni)
		if NeuronIsOff(ni) {
			continue
		}
		vl := ly.UnitValue1D(vidx, int(ni), di)
		am.UpdateValue(vl, int32(ni))
	}
	am.CalcAvg()
	return am
}

// PhaseDiffFromActs computes the phase-wise difference in the
// activity state between the minus [ActM] and plus [ActP] phases,
// measured using 1 minus the correlation (centered cosine aka
// normalized dot product).  0 = no difference, 2 = maximum difference.
func (ly *Layer) PhaseDiffFromActs(ctx *Context) {
	li := ly.Index
	for di := uint32(0); di < ctx.NData; di++ {
		lpi := ly.Params.PoolIndex(0)
		avgM := PoolAvgMax(AMAct, AMMinus, Avg, lpi, di)
		avgP := PoolAvgMax(AMAct, AMPlus, Avg, lpi, di)
		cosv := float32(0)
		ssm := float32(0)
		ssp := float32(0)
		nn := ly.NNeurons
		for lni := uint32(0); lni < nn; lni++ {
			ni := ly.NeurStIndex + lni
			if NeuronIsOff(ni) {
				continue
			}
			ap := Neurons.Value(int(ni), int(di), int(ActP)) - avgP // zero mean = correl
			am := Neurons.Value(int(ni), int(di), int(ActM)) - avgM
			cosv += ap * am
			ssm += am * am
			ssp += ap * ap
		}
		dist := math32.Sqrt(ssm * ssp)
		if dist != 0 {
			cosv /= dist
		}
		LayerStates.Set(1-cosv, int(li), int(LayerPhaseDiff), int(di))
		avg := LayerStates.Value(int(li), int(LayerPhaseDiffAvg), int(di))
		vr := LayerStates.Value(int(li), int(LayerPhaseDiffVar), int(di))
		ly.Params.Acts.Dt.AvgVarUpdate(&avg, &vr, 1-cosv)
		LayerStates.Set(avg, int(li), int(LayerPhaseDiffAvg), int(di))
		LayerStates.Set(vr, int(li), int(LayerPhaseDiffVar), int(di))
	}
}
