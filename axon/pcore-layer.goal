// Copyright (c) 2022, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package axon

import (
	"log"
	"strings"

	"cogentcore.org/core/base/errors"
	"cogentcore.org/core/base/num"
	"cogentcore.org/lab/gosl/slbool"
	"github.com/emer/axon/v2/fsfffb"
)

//gosl:start

// StriatumParams has parameters for BG Striatum layers including
// MatrixLayer and DSPatchLayer.
// DA, ACh learning rate modulation is pre-computed on the recv neuron
// RLRate variable via NeuroMod. Also uses Pool.Gated for InvertNoGate,
// updated in PlusPhase prior to DWt call.
// Must set Learn.NeuroMod.DAMod = D1Mod or D2Mod via SetBuildConfig("DAMod").
type StriatumParams struct {

	// GateThr is the threshold on layer Avg CaPMax for Matrix Go and BG Thal
	// layers to count as having gated.
	GateThr float32 `default:"0.05"`

	// baseline amount of PF activity that modulates credit assignment learning,
	// for neurons with zero PF modulatory activity.
	// These were not part of the actual motor action, but can still get some
	// smaller amount of credit learning.
	BasePF float32 `default:"0.005"`

	// NovelDA is the maximum positive dopamine magnitude associated with novel firing
	// of a matrix pool, which is shunted / discounted by the patchD1 projection to SNc.
	NovelDA float32 `default:"0.01"`

	// MaxPatchD1 is the maximum PatchD1 CaD value for discounting NovelDA.
	MaxPatchD1 float32 `default:"0.5"`

	// BadPatchDA is the maximum negative dopamine magnitude that can be driven by patchD2
	// activity for given pool, reflecting patchD2 to LHb dipping.
	BadPatchDA float32 `default:"0.01"`

	// PatchD2Thr is the threshold for PatchD2 activity to drive dipping: below
	// this level, nothing happens.
	PatchD2Thr float32 `default:"0.2"`

	// IsVS is this a ventral striatum (VS) matrix layer? If true, the gating
	// status of this layer is recorded in the Global state,
	// and used for updating effort and other factors.
	IsVS slbool.Bool

	// Index of other layer (D2 if we are D1 and vice-versa).
	// Set during Build from BuildConfig OtherName.
	OtherIndex int32 `edit:"-"`

	// Index of PF parafasciculus layer to get gating output state from.
	// Set during Build from BuildConfig PFName.
	PFIndex int32 `edit:"-"`

	// Index of PatchD1 layer to get striosome modulation state from.
	// Set during Build from BuildConfig PatchD1Name.
	PatchD1Index int32 `edit:"-"`

	// Index of PatchD2 layer to get striosome modulation state from.
	// Set during Build from BuildConfig PatchD2Name.
	PatchD2Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay1Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay2Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay3Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay4Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay5Index int32 `edit:"-"`

	// Index of thalamus layer that we gate. needed to get gating information.
	// Set during Build from BuildConfig ThalLay1Name if present -- -1 if not used
	ThalLay6Index int32 `edit:"-"`

	pad, pad1, pad2 int32
}

func (mp *StriatumParams) Defaults() {
	mp.GateThr = 0.05
	mp.BasePF = 0.005
	mp.NovelDA = 0.01
	mp.MaxPatchD1 = 0.5
	mp.BadPatchDA = 0.01
	mp.PatchD2Thr = 0.2
}

func (mp *StriatumParams) Update() {
}

// PatchDA computes the dopamine signal due to the given patch activations.
func (mp *StriatumParams) PatchDA(patchD1, patchD2 float32) float32 {
	pD1 := min(patchD1, mp.MaxPatchD1)
	pD2 := max(patchD2-mp.PatchD2Thr, 0.0)
	posDA := mp.NovelDA * (mp.MaxPatchD1 - pD1)
	negDA := mp.BadPatchDA * pD2
	return posDA - negDA
}

//////// GP

// GPLayerTypes is a GPLayer axon-specific layer type enum.
type GPLayerTypes int32 //enums:enum

// The GPLayer types
const (
	// GPePr is the set of prototypical GPe neurons, mediating classical NoGo
	GPePr GPLayerTypes = iota

	// GPeAk is arkypallidal layer of GPe neurons, receiving inhibition from GPePr
	// and projecting inhibition to Mtx
	GPeAk

	// GPi is the inner globus pallidus, functionally equivalent to SNr,
	// receiving from MtxGo and GPePr, and sending inhibition to VThal
	GPi
)

// GPLayer represents a globus pallidus layer, including:
// GPePr, GPeAk (arkypallidal), and GPi (see GPType for type).
// Typically just a single unit per Pool representing a given stripe.
type GPParams struct {

	// type of GP Layer -- must set during config using SetBuildConfig of GPType.
	GPType GPLayerTypes

	pad, pad1, pad2 uint32
}

func (gp *GPParams) Defaults() {
}

func (gp *GPParams) Update() {
}

// MatrixGated is called after std PlusPhase
// Uses Pool state to set Gated flag based on CaPMax activity.
func (ly *LayerParams) MatrixGated(ctx *Context) {
	lpi := ly.PoolIndex(0)
	if ly.Learn.NeuroMod.DAMod != D1Mod {
		oly := Layers[ly.Striatum.OtherIndex]
		olpi := oly.PoolSt
		// note: NoGo layers don't track gating at the sub-pool level!
		for di := uint32(0); di < ctx.NData; di++ {
			PoolsInt[lpi, di, PoolGated] = PoolsInt[olpi, di, PoolGated]
		}
		return
	}
	for di := uint32(0); di < ctx.NData; di++ {
		mtxGated := PoolsInt[lpi, di, PoolGated] > 0
		thalGated := false
		if ly.Striatum.ThalLay1Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay1Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}
		if ly.Striatum.ThalLay2Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay2Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}
		if ly.Striatum.ThalLay3Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay3Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}
		if ly.Striatum.ThalLay4Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay4Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}
		if ly.Striatum.ThalLay5Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay5Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}
		if ly.Striatum.ThalLay6Index >= 0 {
			tly := Layers[ly.Striatum.ThalLay6Index]
			tlpi := tly.PoolSt
			gt := PoolsInt[tlpi, di, PoolGated]
			thalGated = thalGated || gt > 0
		}

		mtxGated = mtxGated && thalGated

		// note: in principle with multi-pool GP, could try to establish
		// a correspondence between thal and matrix pools, such that
		// a failure to gate at the thal level for a given pool would veto
		// just the one corresponding pool.  However, we're not really sure
		// that this will make sense and not doing yet..

		if !mtxGated { // nobody did if thal didn't
			for spi := uint32(0); spi < ly.Indexes.NPools; spi++ {
				pi := ly.PoolIndex(spi)
				PoolsInt[pi, di, PoolGated] = 0
			}
		}
		if ctx.PlusPhase.IsTrue() && ly.Striatum.IsVS.IsTrue() {
			GlobalScalars[GvVSMatrixJustGated, di] = num.FromBool[float32](mtxGated)
			if mtxGated {
				poolIndex := int32(-1)
				for spi := uint32(1); spi < ly.Indexes.NPools; spi++ {
					pi := ly.PoolIndex(spi)
					if poolIndex < 0 && PoolsInt[pi, di, PoolGated] > 0 {
						poolIndex = int32(spi)
					}
				}
				if poolIndex > 0 {
					GlobalVectors[GvVSMatrixPoolGated, poolIndex, di] = float32(1.0)
				}
			}
		}
	}
}

// GatedFromCaPMax updates the Gated state in Pools of given layer,
// based on Avg CaPMax being above given threshold.
func (ly *LayerParams) GatedFromCaPMax(ctx *Context, di uint32) {
	anyGated := false
	lpi := ly.PoolIndex(0)
	thr := ly.Striatum.GateThr
	if ly.Indexes.NPools > 1 {
		for spi := uint32(1); spi < ly.Indexes.NPools; spi++ {
			pi := ly.PoolIndex(spi)
			spkavg := PoolAvgMax(AMCaPMax, AMCycle, Avg, pi, di)
			gthr := spkavg > thr
			if gthr {
				anyGated = true
				PoolsInt[pi, di, PoolGated] = 1
			} else {
				PoolsInt[pi, di, PoolGated] = 0
			}
		}
	} else {
		spkavg := PoolAvgMax(AMCaPMax, AMCycle, Avg, lpi, di)
		if spkavg > thr {
			anyGated = true
		}
	}
	if anyGated {
		PoolsInt[lpi, di, PoolGated] = 1
	} else {
		PoolsInt[lpi, di, PoolGated] = 0
	}
}

// AnyGated returns true if the layer-level pool Gated flag is true,
// which indicates if any of the layers gated.
func (ly *LayerParams) AnyGated(di uint32) bool {
	lpi := ly.PoolIndex(0)
	return PoolsInt[lpi, di, PoolGated] > 0
}

// MatrixPostPlus is called after std PlusPhase,
// sets pool-specific DA dopamine signal based on patch modulation of SNc.
// Only for non-reward trials.
func (ly *LayerParams) MatrixPostPlus(ctx *Context) {
	if ly.Striatum.IsVS.IsTrue() || ly.Indexes.NPools == 1 {
		return
	}
	pf := Layers[ly.Striatum.PFIndex]
	patchD1 := Layers[ly.Striatum.PatchD1Index]
	patchD2 := Layers[ly.Striatum.PatchD2Index]
	for di := uint32(0); di < ctx.NData; di++ {
		if (GlobalScalars[GvHasRew, di]) > 0 { // has rew, do nothing
			continue
		}
		for spi := uint32(1); spi < ly.Indexes.NPools; spi++ {
			pfact := PoolAvgMax(AMCaP, AMCycle, Avg, pf.PoolIndex(spi), di) // must be CaP
			pfnet := ly.Striatum.BasePF + pfact
			ptD1act := PoolAvgMax(AMCaP, AMCycle, Avg, patchD1.PoolIndex(spi), di)
			ptD2act := PoolAvgMax(AMCaP, AMCycle, Avg, patchD2.PoolIndex(spi), di)
			da := pfnet * ly.Striatum.PatchDA(ptD1act, ptD2act) * ly.Learn.NeuroMod.DASign()
			pi := ly.PoolIndex(spi)
			Pools[pi, di, fsfffb.DA] = da
			Pools[pi, di, fsfffb.ModAct] = pfnet
		}
	}
}

// PatchPostPlus is called after std PlusPhase,
// sets pool-specific DA dopamine signal based on PF activity and DA.
func (ly *LayerParams) PatchPostPlus(ctx *Context) {
	if ly.Indexes.NPools == 1 {
		return
	}
	pf := Layers[ly.Striatum.PFIndex]
	for di := uint32(0); di < ctx.NData; di++ {
		for spi := uint32(1); spi < ly.Indexes.NPools; spi++ {
			pfact := PoolAvgMax(AMCaP, AMCycle, Avg, pf.PoolIndex(spi), di) // must be CaP
			pfnet := ly.Striatum.BasePF + pfact
			Pools[ly.PoolIndex(spi), di, fsfffb.ModAct] = pfnet
		}
	}
}

//gosl:end

func (ly *Layer) MatrixDefaults() {
	ly.Params.Acts.Decay.Act = 1
	ly.Params.Acts.Decay.Glong = 1 // prevent carryover of NMDA
	ly.Params.Acts.Kir.Gk = 10
	ly.Params.Acts.GabaB.Gk = 0 // Kir replaces GabaB
	// ly.Params.Acts.NMDA.Ge = 0    // Matrix needs nmda, default is fine
	ly.Params.Inhib.Layer.FB = 0 // pure FF
	ly.Params.Inhib.Layer.Gi = 0.5
	ly.Params.Inhib.Pool.On.SetBool(true) // needs both pool and layer if has pools
	ly.Params.Inhib.Pool.FB = 0           // pure FF
	ly.Params.Inhib.Pool.Gi = 0.5
	ly.Params.Inhib.ActAvg.Nominal = 0.25   // pooled should be lower
	ly.Params.Learn.RLRate.On.SetBool(true) // key: sig deriv used outside of rew trials
	ly.Params.Learn.RLRate.Diff.SetBool(false)
	ly.Params.Learn.TrgAvgAct.RescaleOn.SetBool(false) // major effect

	// ly.Params.Learn.NeuroMod.DAMod needs to be set via BuildConfig
	ly.Params.Learn.NeuroMod.DALRateSign.SetBool(true) // critical
	ly.Params.Learn.NeuroMod.DALRateMod = 1
	ly.Params.Learn.NeuroMod.AChLRateMod = 0
	ly.Params.Learn.NeuroMod.DAModGain = 0
	ly.Params.Learn.NeuroMod.BurstGain = 0.1
	ly.Params.Learn.RLRate.SigmoidMin = 0.001

	if ly.Class == "VSMatrixLayer" {
		ly.Params.Inhib.Layer.On.SetBool(true)
		ly.Params.Striatum.IsVS.SetBool(true)
		ly.Params.Acts.Dend.ModBase = 0
		ly.Params.Acts.Dend.ModGain = 2 // for VS case -- otherwise irrelevant
		ly.Params.Learn.NeuroMod.AChDisInhib = 5
		ly.Params.Learn.NeuroMod.BurstGain = 1
	} else {
		ly.Params.Inhib.Layer.On.SetBool(false)
		ly.Params.Striatum.IsVS.SetBool(false)
		ly.Params.Acts.Dend.ModBase = 1
		ly.Params.Acts.Dend.ModGain = 0
		ly.Params.Learn.NeuroMod.AChDisInhib = 0
	}

	// important: user needs to adjust wt scale of some PFC inputs vs others:
	// drivers vs. modulators

	for _, pj := range ly.RecvPaths {
		pj.Params.SWts.Init.SPct = 0
		if pj.Send.Type == GPLayer { // GPeAkToMtx
			pj.Params.SetFixedWts()
			pj.Params.PathScale.Abs = 3
			pj.Params.SWts.Init.Mean = 0.75
			pj.Params.SWts.Init.Var = 0.0
			if ly.Class == "DSMatrixLayer" {
				if strings.Contains(ly.Name, "No") {
					pj.Params.PathScale.Abs = 6
				}
			}
		}
	}
}

func (ly *Layer) MatrixPostBuild() {
	ly.Params.Striatum.ThalLay1Index = ly.BuildConfigFindLayer("ThalLay1Name", false) // optional
	ly.Params.Striatum.ThalLay2Index = ly.BuildConfigFindLayer("ThalLay2Name", false) // optional
	ly.Params.Striatum.ThalLay3Index = ly.BuildConfigFindLayer("ThalLay3Name", false) // optional
	ly.Params.Striatum.ThalLay4Index = ly.BuildConfigFindLayer("ThalLay4Name", false) // optional
	ly.Params.Striatum.ThalLay5Index = ly.BuildConfigFindLayer("ThalLay5Name", false) // optional
	ly.Params.Striatum.ThalLay6Index = ly.BuildConfigFindLayer("ThalLay6Name", false) // optional

	ly.Params.Striatum.OtherIndex = ly.BuildConfigFindLayer("OtherName", true)

	isDorsal := !ly.Params.Striatum.IsVS.Bool()

	if isDorsal {
		ly.Params.Striatum.PFIndex = ly.BuildConfigFindLayer("PFName", true)
		ly.Params.Striatum.PatchD1Index = ly.BuildConfigFindLayer("PatchD1Name", true)
		ly.Params.Striatum.PatchD2Index = ly.BuildConfigFindLayer("PatchD2Name", true)
	}

	dm, err := ly.BuildConfigByName("DAMod")
	if err == nil {
		errors.Log(ly.Params.Learn.NeuroMod.DAMod.SetString(dm))
	}
}

func (ly *Layer) PatchDefaults() {
	ly.Params.VSPatchDefaults()
}

func (ly *Layer) PatchPostBuild() {
	ly.Params.Striatum.OtherIndex = ly.BuildConfigFindLayer("OtherName", true)
	ly.Params.Striatum.PFIndex = ly.BuildConfigFindLayer("PFName", true)
	dm, err := ly.BuildConfigByName("DAMod")
	if err == nil {
		errors.Log(ly.Params.Learn.NeuroMod.DAMod.SetString(dm))
	}
}

////////  GP

func (ly *Layer) GPDefaults() {
	// GP is tonically self-active and has no FFFB inhibition
	// Defaults are for GPePr, Ak has special values below
	ly.Params.Acts.Init.GeBase = 0.4
	ly.Params.Acts.Init.GeVar = 0.2
	ly.Params.Acts.Init.GiVar = 0.1
	ly.Params.Acts.Decay.Act = 0
	ly.Params.Acts.Decay.Glong = 1
	ly.Params.Acts.NMDA.Ge = 0 // carryover of NMDA was causing issues!
	ly.Params.Acts.GabaB.Gk = 0
	ly.Params.Inhib.ActAvg.Nominal = 1 // very active!
	ly.Params.Inhib.Layer.On.SetBool(false)
	ly.Params.Inhib.Pool.On.SetBool(false)

	if ly.Params.GP.GPType == GPeAk {
		ly.Params.Acts.Init.GeBase = 0.2 // definitely lower in bio data, necessary
		ly.Params.Acts.Init.GeVar = 0.1
	}

	for _, pj := range ly.RecvPaths {
		pj.Params.SetFixedWts()
		pj.Params.SWts.Init.Mean = 0.75 // 0.75 -- very similar -- maybe a bit more reliable with 0.8 / 0
		pj.Params.SWts.Init.Var = 0.25  // 0.25
		switch ly.Params.GP.GPType {
		case GPePr:
			switch pj.Send.Type {
			case MatrixLayer:
				pj.Params.PathScale.Abs = 1 // MtxNoToGPePr -- primary NoGo pathway
			case GPLayer:
				pj.Params.PathScale.Abs = 4 // 4 best for DS; GPePrToGPePr -- must be very strong
			case STNLayer:
				pj.Params.PathScale.Abs = 0.5 // STNToGPePr
			}
		case GPeAk:
			switch pj.Send.Type {
			case MatrixLayer:
				pj.Params.PathScale.Abs = 0.5 // MtxGoToGPeAk
			case GPLayer:
				pj.Params.PathScale.Abs = 1 // GPePrToGPeAk
			case STNLayer:
				pj.Params.PathScale.Abs = 0.1 // STNToGPAk
			}
		}
	}

	if ly.Params.GP.GPType == GPi {
		ly.GPiDefaults()
	}
}

func (ly *Layer) GPiDefaults() {
	ly.Params.Acts.Init.GeBase = 0.3
	ly.Params.Acts.Init.GeVar = 0.1
	ly.Params.Acts.Init.GiVar = 0.1
	// note: GPLayer took care of STN input paths

	for _, pj := range ly.RecvPaths {
		pj.Params.SetFixedWts()
		pj.Params.SWts.Init.Mean = 0.75  // 0.75  see above
		pj.Params.SWts.Init.Var = 0.25   // 0.25
		if pj.Send.Type == MatrixLayer { // MtxGoToGPi
			if pj.Send.Class == "VSMatrixLayer" {
				pj.Params.PathScale.Abs = 0.2
			} else {
				pj.Params.PathScale.Abs = 1
			}
		} else if pj.Send.Type == GPLayer { // GPePrToGPi
			pj.Params.PathScale.Abs = 1
		} else if pj.Send.Type == STNLayer { // STNToGPi
			pj.Params.PathScale.Abs = 0.2
		}
	}
}

func (ly *Layer) GPPostBuild() {
	gpnm, err := ly.BuildConfigByName("GPType")
	if err == nil {
		err = ly.Params.GP.GPType.SetString(gpnm)
		if err != nil {
			log.Println(err)
		}
	}
}

////////  STN

func (ly *Layer) STNDefaults() {
	// STN is tonically self-active and has no FFFB inhibition
	ly.Params.Acts.Init.GeBase = 0.1 // was 0.3
	ly.Params.Acts.Init.GeVar = 0.1
	ly.Params.Acts.Init.GiVar = 0.1
	ly.Params.Acts.SKCa.Gk = 2
	ly.Params.Acts.SKCa.CaRDecayTau = 80 // 80 > 150 for longer theta windows
	ly.Params.Acts.Kir.Gk = 10           // 10 > 5 -- key for pause
	ly.Params.Acts.Decay.Act = 0
	ly.Params.Acts.Decay.Glong = 0
	ly.Params.Acts.Decay.LearnCa = 1 // key for non-spaced trials, to refresh immediately
	ly.Params.Acts.Dend.SSGi = 0
	ly.Params.Acts.NMDA.Ge = 0 // fine with 0
	ly.Params.Acts.GabaB.Gk = 0
	ly.Params.Inhib.Layer.On.SetBool(true)
	ly.Params.Inhib.Layer.Gi = 0.5
	ly.Params.Inhib.Layer.FB = 0
	ly.Params.Inhib.Pool.On.SetBool(false)
	ly.Params.Inhib.Pool.Gi = 0.5
	ly.Params.Inhib.Pool.FB = 0
	ly.Params.Inhib.ActAvg.Nominal = 0.15
	ly.Params.Learn.NeuroMod.AChDisInhib = 0 // was 2,

	// if ly.Cls == "VSTNLayer" {
	// 	ly.Params.Inhib.Layer.On.SetBool(false)
	// } else {
	// 	ly.Params.Inhib.Layer.On.SetBool(true)
	// }

	for _, pj := range ly.RecvPaths {
		pj.Params.SetFixedWts()
		pj.Params.SWts.Init.Mean = 0.75
		pj.Params.SWts.Init.Var = 0.25
		if pj.Send.Type == GPLayer { // GPePrToSTN
			pj.Params.PathScale.Abs = 0.5
		} else {
			pj.Params.PathScale.Abs = 2.0 // pfc inputs
		}
	}
}

////////  BGThal

func (ly *Layer) BGThalDefaults() {
	// note: not tonically active
	// ly.Params.Acts.NMDA.Ge = 0 // needs NMDA
	ly.Params.Acts.Decay.Act = 1
	ly.Params.Acts.Decay.Glong = 0.6
	ly.Params.Acts.Dend.SSGi = 0
	ly.Params.Inhib.ActAvg.Nominal = 0.1
	ly.Params.Inhib.Layer.On.SetBool(true)
	ly.Params.Inhib.Layer.Gi = 0.6
	ly.Params.Inhib.Pool.On.SetBool(false)
	ly.Params.Inhib.Pool.Gi = 0.6

	ly.Params.Learn.NeuroMod.AChDisInhib = 1

	for _, pj := range ly.RecvPaths {
		pj.Params.SetFixedWts()
		pj.Params.SWts.Init.Mean = 0.75
		pj.Params.SWts.Init.Var = 0.0
		if strings.HasSuffix(pj.Send.Name, "GPi") { // GPiToBGThal
			pj.Params.PathScale.Abs = 5 // can now be much stronger with PTMaint mod and maint dynamics
			pj.AddClass("GPiToBGThal")
		}
	}
}

////////  VSGated

func (ly *LayerParams) VSGatedDefaults() {
	ly.Inhib.ActAvg.Nominal = 0.5
	ly.Inhib.Layer.On.SetBool(true)
	ly.Inhib.Layer.Gi = 1
	ly.Inhib.Pool.On.SetBool(false)
	ly.Inhib.Pool.Gi = 1
	ly.Acts.Decay.Act = 1
	ly.Acts.Decay.Glong = 1
}
