// Copyright (c) 2025, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package axon

import (
	// "fmt"
	"cogentcore.org/core/math32"
)

//gosl:start

// NuclearParams has parameters that apply to all cerebellum Nuclear model neurons.
// Not just cerebellar nuclei neurons: also applies to PC.
type NuclearParams struct {

	// ActionEnv is the total time envelope for actions to be tracked,
	// in ms (cycles). Must be consistent across microzone elements.
	ActionEnv int32 `default:"180" min:"0"`

	// SendTimeOff is the time offset for sending activations used in learning,
	// relative to the IO-driven LearnNow time. Should be 0 for CNiUp.
	// Must be an even multiple of [CaBinCycles].
	SendTimeOff int32 `default:"40,0" min:"0"`

	// SendTimeWindow is the time window to integrate sending activations
	// used in learning. Must be an even multiple of [CaBinCycles].
	SendTimeWindow int32 `default:"30" min:"0"`
	
	// ActTarget is the target activity level, as measured by CaD.
	// GeBase is adapted, along with excitatory MF inputs in proportion to activity,
	// which is the source of very slow synaptic decay in these pathways.
	ActTarget float32 `default:"0.5" min:"0.0"`

	// Decay is the rate of decay (prior to the learning rate multiplier)
	// for baseline non-learning trials.
	Decay float32 `default:"0.01"`
	
	// GeBaseLRate is the learning rate for neuron-level [GeBase] baseline
	// excitatory conductance, to maintain target activity levels.
	GeBaseLRate float32 `default:"0.01"`

	// CNeDnGiThr is the threshold on integrated GiSyn for triggering learning
	// in CNeCn excitatory downgoing forward-model neurons, which are disinhibited
	// by CNiIO -> CNiDn. Lower values are more stringent (more disinhibition).
	CNeDnGiThr float32 `default:"0.2"`
	
	// IOLayIndex of IO (inferior olive) layer for sending error signals
	// to this layer. Set via SetBuildConfig(IOLayName) setting.
	IOLayIndex int32 `edit:"-"`

	// SendTimeBins = SendTimeWindow / [CaBinCycles].
	SendTimeBins int32 `edit:"-"`
	
	pad, pad1, pad2 int32
}

func (tp *NuclearParams) Update() {
	tp.SendTimeBins = tp.SendTimeWindow / CaBinCycles
}

func (tp *NuclearParams) Defaults() {
	tp.ActionEnv = 180
	tp.SendTimeOff = 40
	tp.SendTimeWindow = 30
	tp.ActTarget = 0.5
	tp.Decay = 0.01
	tp.GeBaseLRate = 0.01
	tp.CNeDnGiThr = 0.2
	tp.Update()
}

// IsNuclear returns true if layer type is cerebellum (Nuclear model).
func (ly *LayerParams) IsNuclear() bool {
	return ly.Type >= IOLayer && ly.Type <= CNeDnLayer
}


// NuclearLearnReset resets LearnNow if past envelope time, in new state
func (ly *LayerParams) NuclearLearnReset(ctx *Context, ni, di uint32) {
	if Neurons[ni, di, LearnNow] == 0.0 { // not done yet
		return
	}
	
	if ly.Type == CNeUpLayer || ly.Type == CNeDnLayer {
		Neurons[ni, di, LearnNow] = 0.0
		Neurons[ni, di, TimePeak] = 0.0
		Neurons[ni, di, GaM] = 0.0
		Neurons[ni, di, GaP] = 0.0
		Neurons[ni, di, GaD] = 0.0
		return
	}
	
	effAct := int32(Neurons[ni, di, TimeCycle]) 
	if effAct == 0 {
		return
	}
	envCyc := ctx.CyclesTotal-effAct // cycle within envelope
	if envCyc >= ly.Nuclear.ActionEnv {
		Neurons[ni, di, TimeCycle] = 0.0
		Neurons[ni, di, TimePeak] = 0.0
		Neurons[ni, di, LearnNow] = 0.0
	}		
}

// NuclearDWtNeuron is the neuron-level learning rule for tonically-active
// Nuclear layers (e.g., [CNeUpLayer], [CNeDnLayer]).
// Used to adjust the GeBase levels per neuron.
func (ly *LayerParams) NuclearDWtNeuron(ctx *Context, ni uint32) {
	dbase := float32(0)
	for di := uint32(0); di < ly.MaxData; di++ {
		if Neurons[ni, di, TimePeak] == 1.0 { // non-baseline
			continue
		}
		aerr := ly.Nuclear.ActTarget - Neurons[ni, di, CaD]
		dbase += aerr
	}
	dbase *= ly.Nuclear.GeBaseLRate
	gbase := NeuronAvgs[ni, GeBase]
	gbase += dbase
	if gbase < 0 {
		gbase = 0
	}
	NeuronAvgs[ni, GeBase] = gbase
}

// IOParams has parameters for the IO inferior olive neurons,
// which compute a temporal offset error signal between CNiIO inhibitory
// predictions and excitatory sensory input, contingent on initial
// above-threshold efferent copy motor trigger input (modulatory).
// Neuron [CaBins] are used to store TimeOff past inhibitory inputs.
type IOParams struct {

	// TimeOff is the time offset for earlier predictive inhibitory inputs to
	// compare against current excitatory inputs to trigger an error,
	// in ms (cycles). Must be an even multiple of [CaBinCycles].
	TimeOff int32 `default:"50" min:"0"`

	// ErrThr is the threshold on the GeSyn - GiSyn_(t-TimeOff) difference
	// to trigger an error.
	ErrThr float32 `default:"0.1" min:"0.0"`
	
	// EfferentThr is the threshold for modulatory [GModSyn] from efferent copy
	// inputs to trigger an activated IO window where error comparison occurs.
	// Efferent inputs can continue post-threshold, but this is the point at which
	// the envelope opens.
	EfferentThr float32 `default:"0.2" min:"0.0"`

	// EfferentOff is the offset from the time of the efferent signal before
	// meaningful sensory comparison can occur. The inhibitory prediction values
	// are assumed to be strongly activated at this time.
	// in ms (cycles). Must be an even multiple of [CaBinCycles].
	EfferentOff int32 `default:"20" min:"0"`

	// GTau is the time constant in ms for integrating [GeSyn] and [GiSyn]
	// excitatory and inhibitory conductances for comparison. 
	// Integration goes into GaM (only for IO neurons).
	GTau float32 `default:"20"`
	
	// Dt = 1 / Tau
	GDt float32 `display:"-"`
	
	pad, pad1 float32
}

func (tp *IOParams) Update() {
	tp.GDt = 1.0 / tp.GTau
}

func (tp *IOParams) Defaults() {
	tp.TimeOff = 50
	tp.ErrThr = 0.1
	tp.EfferentThr = 0.2
	tp.EfferentOff = 20
	tp.GTau = 20
	tp.Update()
}

// IOCopy copies the IO layer [LearnNow] signal.
func (ly *LayerParams) IOCopy(ctx *Context, lpi, pi, ni, di uint32) {
	lni := ni - ly.Indexes.NeurSt
	ioi := uint32(ly.Nuclear.IOLayIndex)
	ioly := GetLayers(ioi)
	Neurons[ni, di, LearnNow] = Neurons[ioly.Indexes.NeurSt+lni, di, LearnNow]
	Neurons[ni, di, TimePeak] = Neurons[ioly.Indexes.NeurSt+lni, di, TimePeak]
	Neurons[ni, di, TimeCycle] = Neurons[ioly.Indexes.NeurSt+lni, di, TimeCycle]
}

// TODO: IO neurons integrate across many distinct comparisons!
// here, we just have 1 IO per pairwise comparison.
// Need to get layer and do indexing or something. Figure out 
// best way to organize later.

// IOLearn computes when an IO learning spike occurs.
// Called in LayerParams::PostSpikeSpecial.
func (ly *LayerParams) IOLearn(ctx *Context, lpi, pi, ni, di uint32) {
	cycTot := float32(ctx.CyclesTotal)
	effAct := int32(Neurons[ni, di, TimeCycle])
	envCyc := ctx.CyclesTotal-effAct // cycle within envelope

	gaP := Neurons[ni, di, GaP] // IOe excitatory input
	gaP += ly.IO.GDt * (Neurons[ni, di, GeSyn] - gaP)
	Neurons[ni, di, GaP] = gaP
	
	gaM := Neurons[ni, di, GaM]
	gaM += ly.IO.GDt * (Neurons[ni, di, GiSyn] - gaM)
	Neurons[ni, di, GaM] = gaM
	
	inhibAct := gaM
	// CaBinCycles to ensure that full bin is filled
	if effAct > 0 && envCyc <= ly.IO.EfferentOff + CaBinCycles {
		inhibAct = 1.0
	}
	CaBinIncrement(inhibAct, ctx.CyclesTotal, ni, di) // always store
	
	Neurons[ni, di, TimeDiff] = 0.0 // set below for display
	Neurons[ni, di, Spike] = 0.0 // default is no spike

	oldInhib := float32(0)
	nbins := ly.IO.TimeOff / CaBinCycles
	nbins = max(1, nbins-1)
	stcyc := ctx.CyclesTotal - ly.IO.TimeOff
	for i := range nbins {
		bi := CaBinForCycle(stcyc + i * CaBinCycles)
		oldInhib += Neurons[ni, di, CaBins + NeuronVars(bi)]
	}
	oldInhib /= float32(nbins)
	Neurons[ni, di, GaD] = oldInhib
	
	if Neurons[ni, di, LearnNow] > 0 { // already learned, done until cleared in NuclearLearnReset
		Neurons[ni, di, Spike] = 0.0
		return
	}
	if effAct == 0 {
		Neurons[ni, di, Spike] = 0.0
		if Neurons[ni, di, GModSyn] > ly.IO.EfferentThr { // efferent always activates.
			Neurons[ni, di, TimeCycle] = cycTot // efferent activation cycle
			Neurons[ni, di, TimePeak] = 0.0
			Neurons[ni, di, LearnNow] = 0.0
		}
		return
	}
	if envCyc <= (ly.IO.TimeOff+ly.IO.EfferentOff) { // nothing until min
		return
	}
	if envCyc >= ly.Nuclear.ActionEnv { // no errors until the end of envelope: baseline spike
		Neurons[ni, di, LearnNow] = cycTot
		Neurons[ni, di, Spike] = 1.0 // baseline spike
		return
	}
	errVal := gaP - oldInhib
	Neurons[ni, di, TimeDiff] = errVal
	if gaP > ly.Learn.Timing.LearnThr && errVal > ly.IO.ErrThr {
		Neurons[ni, di, Spike] = 1.0 // error spike
		Neurons[ni, di, LearnNow] = cycTot // record point of error
		Neurons[ni, di, TimePeak] = 1.0 // records that we got err spike
	}
}

// CNeLearn updates LearnNow for [CNeUpLayer], [CNeDnLayer], based on
// maximum excitatory deviation from target. Also records max negative
// deviation in GaD.
// called in LayerParams::PostSpikeSpecial
func (ly *LayerParams) CNeLearn(ctx *Context, lpi, pi, ni, di uint32) {
	// lni := ni - ly.Indexes.NeurSt
	// ioi := uint32(ly.Nuclear.IOLayIndex)
	// ioly := GetLayers(ioi)
	// Neurons[ni, di, TimeCycle] = Neurons[ioly.Indexes.NeurSt+lni, di, TimeCycle]

	cycTot := float32(ctx.CyclesTotal)

	act := Neurons[ni, di, CaP]
	dev := ly.Nuclear.ActTarget - act // deviation
	adev := math32.Abs(dev) 
	if adev > Neurons[ni, di, GaP] {
		Neurons[ni, di, GaP] = adev
		Neurons[ni, di, GaM] = dev // actual direction for learning
		Neurons[ni, di, LearnNow] = cycTot // learn at max
		Neurons[ni, di, TimePeak] = 1.0 // for visualization
	} else {
		Neurons[ni, di, TimePeak] = 0.0
	}
}

// CNiLearn updates LearnNow for CNiLayer, based on maximum 
// activity time.
// called in LayerParams::PostSpikeSpecial
func (ly *LayerParams) CNiLearn(ctx *Context, lpi, pi, ni, di uint32) {
	ly.IOCopy(ctx, lpi, pi, ni, di)
	cycTot := float32(ctx.CyclesTotal)

	act := Neurons[ni, di, CaP]
	if act > Neurons[ni, di, GaP] {
		Neurons[ni, di, GaP] = act
		Neurons[ni, di, TimeDiff] = cycTot // learn at max
		Neurons[ni, di, GaD] = 1.0 // for visualization
	} else {
		Neurons[ni, di, GaD] = 0.0
	}
}

//gosl:end

// NuclearPostBuild does post-Build config of Nuclear models of the 
// cerebellum based on BuildConfig options.
func (ly *Layer) NuclearPostBuild() {
	ly.Params.Nuclear.IOLayIndex = ly.BuildConfigFindLayer("IOLayName", true)
}

// LinearDefaults sets parameters to allow neurons to linearly encode
// values in their rate of firing, to the extent possible.
func (ly *LayerParams) LinearDefaults() {
	// turn off accommodation currents
	ly.Acts.Mahp.Gk = 0
	ly.Acts.Sahp.Gk = 0
	ly.Acts.KNa.On.SetBool(false)
	// no sustained:
	ly.Acts.NMDA.Ge = 0
	ly.Acts.GabaB.Gk = 0
}

// NuclearDefaults called in Defaults for all Nuclear layers
func (ly *LayerParams) NuclearDefaults() {
	ly.Learn.TrgAvgAct.RescaleOn.SetBool(false)
	ly.Acts.Init.GeBase = 0.25
	ly.Inhib.Layer.On.SetBool(false)
	ly.Acts.Decay.Act = 0.0
	ly.Acts.Decay.Glong = 0.0 // clear long
	ly.Acts.Decay.AHP = 0.0   // clear long

	ly.LinearDefaults()
	
	// ly.Learn.RLRate.SigmoidMin = 1.0 // 1.0 generally better but worth trying 0.05 too
	
	// for _, pj := range lly.RecvPaths {
	// 	pj.Params.SWts.Init.Mean = 0.8
	// 	pj.Params.SWts.Init.Var = 0.0
	// 	if pj.Send.Type != CNiIOLayer {
	// 		pj.Params.SetFixedWts()
	// 	} else {
	// 		pj.Params.SWts.Init.Mean = 0.5
	// 	}
	// }
}

// called in Defaults for [IOLayer] type
func (ly *LayerParams) IODefaults() {
	ly.NuclearDefaults()
	ly.Learn.Timing.On.SetBool(false)
	ly.Acts.Init.GeBase = 0
}

// called in Defaults for [CNiIOLayer] type
func (ly *LayerParams) CNiIODefaults() {
	ly.NuclearDefaults()
	ly.Acts.Init.GeBase = 0
	ly.Nuclear.ActTarget = 0
	ly.Nuclear.SendTimeOff = 40
}

// called in Defaults for [CNiUpLayer] type
func (ly *LayerParams) CNiUpDefaults() {
	ly.NuclearDefaults()
	ly.Acts.Init.GeBase = 0
	ly.Nuclear.ActTarget = 0
	ly.Nuclear.SendTimeOff = 10 // match the excitatory
}

// called in Defaults for [CNeDnLayer] type
func (ly *LayerParams) CNeDnDefaults() {
	ly.NuclearDefaults()
	ly.Acts.Init.GeBase = 0.25
	ly.Nuclear.ActTarget = 0.0
	ly.Nuclear.GeBaseLRate = 0
	ly.Nuclear.SendTimeOff = 20
}

