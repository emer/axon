// Code generated by "gosl"; DO NOT EDIT
// kernel: BetweenGi

// // Layers are all the layer parameters. 
@group(0) @binding(0)
var<storage, read> TensorStrides: array<u32>;
@group(0) @binding(1)
var<storage, read> Layers: array<LayerParams>;
@group(0) @binding(2)
var<storage, read> Paths: array<PathParams>;
@group(0) @binding(3)
var<storage, read> NetworkIxs: array<NetworkIndexes>;
@group(0) @binding(4)
var<storage, read> PoolIxs: array<u32>;
@group(0) @binding(5)
var<storage, read> NeuronIxs: array<u32>;
// // SynapseIxs have index values for each synapse: // providing index into recv, send neurons, path. // [Indexes][NSyns]; NSyns = [Layer][SendPaths][SendNeurons][Syns] 
@group(1) @binding(0)
var<storage, read> SynapseIxs: array<u32>;
@group(1) @binding(1)
var<storage, read> PathSendCon: array<u32>;
@group(1) @binding(2)
var<storage, read> RecvPathIxs: array<u32>;
@group(1) @binding(3)
var<storage, read> PathRecvCon: array<u32>;
@group(1) @binding(4)
var<storage, read> RecvSynIxs: array<u32>;
// // Ctx is the current context state (one only). This is read-only except in // specific kernels. 
@group(2) @binding(0)
var<storage, read_write> Ctx: array<Context>;
@group(2) @binding(1)
var<storage, read_write> Neurons: array<f32>;
@group(2) @binding(2)
var<storage, read_write> NeuronAvgs: array<f32>;
@group(2) @binding(3)
var<storage, read_write> LayerStates: array<f32>;
@group(2) @binding(4)
var<storage, read_write> GlobalScalars: array<f32>;
@group(2) @binding(5)
var<storage, read_write> GlobalVectors: array<f32>;
@group(2) @binding(6)
var<storage, read_write> Exts: array<f32>;
// // Pools are the [PoolVars] float32 state values for layer and sub-pool inhibition, // Including the float32 AvgMax values by Phase and variable: use [AvgMaxVarIndex]. // [Layer * Pools][Data][PoolVars+AvgMax] 
@group(3) @binding(0)
var<storage, read_write> Pools: array<f32>;
@group(3) @binding(1)
var<storage, read_write> PoolsInt: array<i32>;
@group(3) @binding(2)
var<storage, read_write> PathGBuf: array<i32>;
@group(3) @binding(3)
var<storage, read_write> PathGSyns: array<f32>;
@group(3) @binding(4)
var<storage, read_write> Synapses: array<f32>;
@group(3) @binding(5)
var<storage, read_write> SynapseTraces: array<f32>;

alias GPUVars = i32;

@compute @workgroup_size(64, 1, 1)
fn main(@builtin(workgroup_id) wgid: vec3<u32>, @builtin(num_workgroups) nwg: vec3<u32>, @builtin(local_invocation_index) loci: u32) {
	let idx = loci + (wgid.x + wgid.y * nwg.x + wgid.z * nwg.x * nwg.y) * 64;
	BetweenGi(idx);
}

fn Index2D(s0: u32, s1: u32, i0: u32, i1: u32) -> u32 {
	return s0 * i0 + s1 * i1;
}

fn Index1D(s0: u32, i0: u32) -> u32 {
	return s0 * i0;
}

fn Index3D(s0: u32, s1: u32, s2: u32, i0: u32, i1: u32, i2: u32) -> u32 {
	return s0 * i0 + s1 * i1 + s2 * i2;
}


//////// import: "vars.go"

//////// import: "act-layer.go"
fn LayerParams_BetweenGi(ly: LayerParams, ctx: Context, di: u32) {
	var lpi = LayerParams_PoolIndex(ly, u32(u32(0)));
	var maxGi = Pools[Index3D(TensorStrides[130], TensorStrides[131], TensorStrides[132], u32(lpi), u32(di), u32(TotalGi))];
	maxGi = LayerParams_BetweenLayerGiMax(ly, di, maxGi, ly.LayInhib.Index1);
	maxGi = LayerParams_BetweenLayerGiMax(ly, di, maxGi, ly.LayInhib.Index2);
	maxGi = LayerParams_BetweenLayerGiMax(ly, di, maxGi, ly.LayInhib.Index3);
	maxGi = LayerParams_BetweenLayerGiMax(ly, di, maxGi, ly.LayInhib.Index4);
	Pools[Index3D(TensorStrides[130], TensorStrides[131], // our inhib is max of us and everyone in the layer pool
	TensorStrides[132], u32(lpi), u32(di), u32(TotalGi))] = maxGi;
}
fn LayerParams_BetweenLayerGiMax(ly: LayerParams, di: u32, maxGi: f32, layIndex: i32) -> f32 {
	if (layIndex < 0) {
		return maxGi;
	}
	let oly = Layers[u32(layIndex)];
	var opi = LayerParams_PoolIndex(oly, u32(u32(0)));
	var ogi = Pools[Index3D(TensorStrides[130], TensorStrides[131], TensorStrides[132], u32(opi), u32(di), u32(TotalGi))];
	if (ogi > maxGi) {
		return ogi;
	}return maxGi;
}

//////// import: "act-net.go"
fn BetweenGi(i: u32) { //gosl:kernel
	let ctx = Ctx[0];
	var li = Context_ItemIndex(ctx, i);
	if (li >= NetworkIxs[0].NLayers) {
		return;
	}
	var di = Context_DataIndex(ctx, i);
	let layers=Layers[li]; LayerParams_BetweenGi(layers, ctx, di);
}

//////// import: "act-path.go"
alias PathGTypes = i32; //enums:enum
const  ExcitatoryG: PathGTypes = 0;
const  InhibitoryG: PathGTypes = 1;
const  ModulatoryG: PathGTypes = 2;
const  MaintG: PathGTypes = 3;
const  ContextG: PathGTypes = 4;
struct SynComParams {
	GType: PathGTypes,
	Delay: u32,
	MaxDelay: u32,
	DelLen: u32,
}
struct PathScaleParams {
	Rel: f32,
	Abs: f32,
	pad: f32,
	pad1: f32,
}

//////// import: "act.go"
struct SpikeParams {
	Thr: f32,
	VmR: f32,
	Tr: i32,
	RTau: f32,
	Exp: i32,
	ExpSlope: f32,
	ExpThr: f32,
	MaxHz: f32,
	ISITau: f32,
	ISIDt: f32,
	RDt: f32,
	pad: i32,
}
struct DendParams {
	GbarExp: f32,
	GbarR: f32,
	SSGi: f32,
	HasMod: i32,
	ModGain: f32,
	ModACh: i32,
	ModBase: f32,
	pad: i32,
}
struct ActInitParams {
	Vm: f32,
	Act: f32,
	GeBase: f32,
	GiBase: f32,
	GeVar: f32,
	GiVar: f32,
	pad: i32,
	pad1: i32,
}
struct DecayParams {
	Act: f32,
	Glong: f32,
	AHP: f32,
	LearnCa: f32,
	OnRew: i32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
struct DtParams {
	Integ: f32,
	VmTau: f32,
	VmDendTau: f32,
	VmSteps: i32,
	GeTau: f32,
	GiTau: f32,
	IntTau: f32,
	LongAvgTau: f32,
	MaxCycStart: i32,
	VmDt: f32,
	VmDendDt: f32,
	DtStep: f32,
	GeDt: f32,
	GiDt: f32,
	IntDt: f32,
	LongAvgDt: f32,
}
struct SpikeNoiseParams {
	On: i32,
	GeHz: f32,
	Ge: f32,
	GiHz: f32,
	Gi: f32,
	MaintGe: i32,
	GeExpInt: f32,
	GiExpInt: f32,
}
struct ClampParams {
	Ge: f32,
	Add: i32,
	ErrThr: f32,
	pad: f32,
}
struct SMaintParams {
	On: i32,
	NNeurons: f32,
	Gbar: f32,
	Inhib: f32,
	ISI: F32,
}
struct PopCodeParams {
	On: i32,
	Ge: f32,
	Min: f32,
	Max: f32,
	MinAct: f32,
	MinSigma: f32,
	MaxSigma: f32,
	Clip: i32,
}
struct ActParams {
	Spikes: SpikeParams,
	Dend: DendParams,
	Init: ActInitParams,
	Decay: DecayParams,
	Dt: DtParams,
	Gbar: Chans,
	Erev: Chans,
	Clamp: ClampParams,
	Noise: SpikeNoiseParams,
	VmRange: F32,
	Mahp: MahpParams,
	Sahp: SahpParams,
	KNa: KNaMedSlow,
	Kir: KirParams,
	NMDA: NMDAParams,
	MaintNMDA: NMDAParams,
	GabaB: GABABParams,
	VGCC: VGCCParams,
	AK: AKsParams,
	SKCa: SKCaParams,
	SMaint: SMaintParams,
	PopCode: PopCodeParams,
}

//////// import: "chans-ak.go"
struct AKsParams {
	Gbar: f32,
	Hf: f32,
	Mf: f32,
	Voff: f32,
	Vmax: f32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}

//////// import: "chans-chans.go"
struct Chans {
	E: f32,
	L: f32,
	I: f32,
	K: f32,
}

//////// import: "chans-gabab.go"
struct GABABParams {
	Gbar: f32,
	RiseTau: f32,
	DecayTau: f32,
	Gbase: f32,
	GiSpike: f32,
	MaxTime: f32,
	TauFact: f32,
	RiseDt: f32,
	DecayDt: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "chans-kir.go"
struct KirParams {
	Gbar: f32,
	MinfOff: f32,
	MinfTau: f32,
	RiseOff: f32,
	RiseTau: f32,
	DecayOff: f32,
	DecayTau: f32,
	Mrest: f32,
}

//////// import: "chans-kna.go"
struct KNaParams {
	On: i32,
	Rise: f32,
	Max: f32,
	Tau: f32,
	Dt: f32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}
struct KNaMedSlow {
	On: i32,
	TrialSlow: i32,
	pad: i32,
	pad1: i32,
	Med: KNaParams,
	Slow: KNaParams,
}

//////// import: "chans-mahp.go"
struct MahpParams {
	Gbar: f32,
	Voff: f32,
	Vslope: f32,
	TauMax: f32,
	Tadj: f32,
	DtMax: f32,
	pad: i32,
	pad2: i32,
}

//////// import: "chans-nmda.go"
struct NMDAParams {
	Gbar: f32,
	Tau: f32,
	ITau: f32,
	MgC: f32,
	Voff: f32,
	Dt: f32,
	IDt: f32,
	MgFact: f32,
}

//////// import: "chans-sahp.go"
struct SahpParams {
	Gbar: f32,
	CaTau: f32,
	Off: f32,
	Slope: f32,
	TauMax: f32,
	CaDt: f32,
	DtMax: f32,
	pad: i32,
}

//////// import: "chans-skca.go"
struct SKCaParams {
	Gbar: f32,
	C50: f32,
	ActTau: f32,
	DeTau: f32,
	KCaR: f32,
	CaRDecayTau: f32,
	CaInThr: f32,
	CaInTau: f32,
	ActDt: f32,
	DeDt: f32,
	CaRDecayDt: f32,
	CaInDt: f32,
}

//////// import: "chans-vgcc.go"
struct VGCCParams {
	Gbar: f32,
	Ca: f32,
	pad: i32,
	pad1: i32,
}

//////// import: "context.go"
struct Context { //types:add -setters
	NData: u32,
	Mode: i32,
	Testing: i32,
	Phase: i32,
	PlusPhase: i32,
	PhaseCycle: i32,
	Cycle: i32,
	ThetaCycles: i32,
	PlusCycles: i32,
	CaBinCycles: i32,
	CyclesTotal: i32,
	Time: f32,
	TrialsTotal: i32,
	TimePerCycle: f32,
	SlowInterval: i32,
	SlowCounter: i32,
	RandCounter: RandCounter,
}
fn Context_ItemIndex(ctx: Context, idx: u32) -> u32 {
	return idx / ctx.NData;
}
fn Context_DataIndex(ctx: Context, idx: u32) -> u32 {
	return idx % ctx.NData;
}

//////// import: "deep-layer.go"
struct BurstParams {
	ThrRel: f32,
	ThrAbs: f32,
	pad: f32,
	pad1: f32,
}
struct CTParams {
	GeGain: f32,
	DecayTau: f32,
	OFCposPT: i32,
	DecayDt: f32,
}
struct PulvParams {
	DriveScale: f32,
	FullDriveAct: f32,
	DriveLayIndex: i32,
	pad: f32,
}

//////// import: "deep-path.go"

//////// import: "enumgen.go"
const PathGTypesN: PathGTypes = 5;
const GlobalScalarVarsN: GlobalScalarVars = 58;
const GlobalVectorVarsN: GlobalVectorVars = 10;
const GPUVarsN: GPUVars = 23;
const LayerTypesN: LayerTypes = 30;
const LayerVarsN: LayerVars = 12;
const ViewTimesN: ViewTimes = 7;
const DAModTypesN: DAModTypes = 4;
const ValenceTypesN: ValenceTypes = 3;
const NeuronFlagsN: NeuronFlags = 9;
const NeuronVarsN: NeuronVars = 83;
const NeuronAvgVarsN: NeuronAvgVars = 7;
const NeuronIndexVarsN: NeuronIndexVars = 3;
const PathTypesN: PathTypes = 12;
const GPLayerTypesN: GPLayerTypes = 3;
const PoolIndexVarsN: PoolIndexVars = 4;
const PoolIntVarsN: PoolIntVars = 6;
const AvgMaxN: AvgMax = 2;
const AvgMaxPhasesN: AvgMaxPhases = 4;
const AvgMaxVarsN: AvgMaxVars = 7;
const SynapseVarsN: SynapseVars = 5;
const SynapseTraceVarsN: SynapseTraceVars = 3;
const SynapseIndexVarsN: SynapseIndexVars = 3;

//////// import: "fsfffb-enumgen.go"
const InhibVarsN: InhibVars = 16;

//////// import: "fsfffb-fsfffb.go"
struct GiParams {
	On: i32,
	Gi: f32,
	FB: f32,
	FSTau: f32,
	SS: f32,
	SSfTau: f32,
	SSiTau: f32,
	FS0: f32,
	FFAvgTau: f32,
	FFPrv: f32,
	ClampExtMin: f32,
	FSDt: f32,
	SSfDt: f32,
	SSiDt: f32,
	FFAvgDt: f32,
	pad: f32,
}

//////// import: "fsfffb-inhib.go"
alias InhibVars = i32; //enums:enum
const  FFsRaw: InhibVars = 0;
const  FBsRaw: InhibVars = 1;
const  GeExtRaw: InhibVars = 2;
const  FFs: InhibVars = 3;
const  FBs: InhibVars = 4;
const  GeExts: InhibVars = 5;
const  FSi: InhibVars = 6;
const  SSi: InhibVars = 7;
const  SSf: InhibVars = 8;
const  FSGi: InhibVars = 9;
const  SSGi: InhibVars = 10;
const  TotalGi: InhibVars = 11;
const  GiOrig: InhibVars = 12;
const  LayGi: InhibVars = 13;
const  FFAvg: InhibVars = 14;
const  FFAvgPrv: InhibVars = 15;

//////// import: "globals.go"
alias GlobalScalarVars = i32; //enums:enum
const  GvRew: GlobalScalarVars = 0;
const  GvHasRew: GlobalScalarVars = 1;
const  GvRewPred: GlobalScalarVars = 2;
const  GvPrevPred: GlobalScalarVars = 3;
const  GvHadRew: GlobalScalarVars = 4;
const  GvDA: GlobalScalarVars = 5;
const  GvDAtonic: GlobalScalarVars = 6;
const  GvACh: GlobalScalarVars = 7;
const  GvNE: GlobalScalarVars = 8;
const  GvSer: GlobalScalarVars = 9;
const  GvAChRaw: GlobalScalarVars = 10;
const  GvGoalMaint: GlobalScalarVars = 11;
const  GvVSMatrixJustGated: GlobalScalarVars = 12;
const  GvVSMatrixHasGated: GlobalScalarVars = 13;
const  GvCuriosityPoolGated: GlobalScalarVars = 14;
const  GvTime: GlobalScalarVars = 15;
const  GvEffort: GlobalScalarVars = 16;
const  GvUrgencyRaw: GlobalScalarVars = 17;
const  GvUrgency: GlobalScalarVars = 18;
const  GvHasPosUS: GlobalScalarVars = 19;
const  GvHadPosUS: GlobalScalarVars = 20;
const  GvNegUSOutcome: GlobalScalarVars = 21;
const  GvHadNegUSOutcome: GlobalScalarVars = 22;
const  GvPVposSum: GlobalScalarVars = 23;
const  GvPVpos: GlobalScalarVars = 24;
const  GvPVnegSum: GlobalScalarVars = 25;
const  GvPVneg: GlobalScalarVars = 26;
const  GvPVposEst: GlobalScalarVars = 27;
const  GvPVposVar: GlobalScalarVars = 28;
const  GvPVnegEst: GlobalScalarVars = 29;
const  GvPVnegVar: GlobalScalarVars = 30;
const  GvGoalDistEst: GlobalScalarVars = 31;
const  GvGoalDistPrev: GlobalScalarVars = 32;
const  GvProgressRate: GlobalScalarVars = 33;
const  GvGiveUpUtility: GlobalScalarVars = 34;
const  GvContUtility: GlobalScalarVars = 35;
const  GvGiveUpTiming: GlobalScalarVars = 36;
const  GvContTiming: GlobalScalarVars = 37;
const  GvGiveUpProgress: GlobalScalarVars = 38;
const  GvContProgress: GlobalScalarVars = 39;
const  GvGiveUpSum: GlobalScalarVars = 40;
const  GvContSum: GlobalScalarVars = 41;
const  GvGiveUpProb: GlobalScalarVars = 42;
const  GvGiveUp: GlobalScalarVars = 43;
const  GvGaveUp: GlobalScalarVars = 44;
const  GvVSPatchPos: GlobalScalarVars = 45;
const  GvVSPatchPosThr: GlobalScalarVars = 46;
const  GvVSPatchPosRPE: GlobalScalarVars = 47;
const  GvVSPatchPosSum: GlobalScalarVars = 48;
const  GvVSPatchPosPrev: GlobalScalarVars = 49;
const  GvVSPatchPosVar: GlobalScalarVars = 50;
const  GvLHbDip: GlobalScalarVars = 51;
const  GvLHbBurst: GlobalScalarVars = 52;
const  GvLHbPVDA: GlobalScalarVars = 53;
const  GvCeMpos: GlobalScalarVars = 54;
const  GvCeMneg: GlobalScalarVars = 55;
const  GvVtaDA: GlobalScalarVars = 56;
const  GvCaBinWts: GlobalScalarVars = 57;
const MaxGlobalVecN = 16;
alias GlobalVectorVars = i32; //enums:enum
const  GvCost: GlobalVectorVars = 0;
const  GvCostRaw: GlobalVectorVars = 1;
const  GvUSneg: GlobalVectorVars = 2;
const  GvUSnegRaw: GlobalVectorVars = 3;
const  GvDrives: GlobalVectorVars = 4;
const  GvUSpos: GlobalVectorVars = 5;
const  GvVSPatchD1: GlobalVectorVars = 6;
const  GvVSPatchD2: GlobalVectorVars = 7;
const  GvOFCposPTMaint: GlobalVectorVars = 8;
const  GvVSMatrixPoolGated: GlobalVectorVars = 9;

//////// import: "hip_paths.go"
struct HipPathParams {
	Hebb: f32,
	Err: f32,
	SAvgCor: f32,
	SAvgThr: f32,
	SNominal: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "inhib.go"
struct ActAvgParams {
	Nominal: f32,
	RTThr: f32,
	AdaptGi: i32,
	Offset: f32,
	HiTol: f32,
	LoTol: f32,
	AdaptRate: f32,
	pad: f32,
}
struct InhibParams {
	ActAvg: ActAvgParams,
	Layer: GiParams,
	Pool: GiParams,
}

//////// import: "init-layer.go"

//////// import: "kinase-params.go"
struct CaDtParams { //types:add
	MTau: f32,
	PTau: f32,
	DTau: f32,
	MDt: f32,
	PDt: f32,
	DDt: f32,
	pad: i32,
	pad1: i32,
}
struct CaSpikeParams {
	SpikeCaM: f32,
	SpikeCaSyn: f32,
	CaSynTau: f32,
	CaSynDt: f32,
	Dt: CaDtParams,
}

//////// import: "kinase-syncabin.go"
alias SynCaBinEnvelopes = i32; //enums:enum
const  Env30: SynCaBinEnvelopes = 0;
const  Env25: SynCaBinEnvelopes = 1;
const  Env20: SynCaBinEnvelopes = 2;
const  Env10: SynCaBinEnvelopes = 3;
struct SynCaBin { //types:add
	Envelope: SynCaBinEnvelopes,
	Wt1: f32,
	Wt2: f32,
	Wt11: f32,
	Wt10: f32,
	WtT0: f32,
	WtT1: f32,
	WtT2: f32,
}

//////// import: "layerparams.go"
struct LayerIndexes {
	NPools: u32,
	NeurSt: u32,
	NNeurons: u32,
	RecvSt: u32,
	RecvN: u32,
	SendSt: u32,
	SendN: u32,
	ExtsSt: u32,
	ShpPlY: i32,
	ShpPlX: i32,
	ShpUnY: i32,
	ShpUnX: i32,
}
struct LayerInhibIndexes {
	Index1: i32,
	Index2: i32,
	Index3: i32,
	Index4: i32,
}
struct LayerParams {
	Type: LayerTypes,
	Index: u32,
	MaxData: u32,
	PoolSt: u32,
	Acts: ActParams,
	Inhib: InhibParams,
	LayInhib: LayerInhibIndexes,
	Learn: LearnNeuronParams,
	Bursts: BurstParams,
	CT: CTParams,
	Pulv: PulvParams,
	Matrix: MatrixParams,
	GP: GPParams,
	LDT: LDTParams,
	VTA: VTAParams,
	RWPred: RWPredParams,
	RWDa: RWDaParams,
	TDInteg: TDIntegParams,
	TDDa: TDDaParams,
	Indexes: LayerIndexes,
}
fn LayerParams_PoolIndex(ly: LayerParams, pi: u32) -> u32 {
	return ly.PoolSt + pi;
}

//////// import: "layertypes.go"
alias LayerTypes = i32; //enums:enum
const  SuperLayer: LayerTypes = 0;
const  InputLayer: LayerTypes = 1;
const  TargetLayer: LayerTypes = 2;
const  CompareLayer: LayerTypes = 3;
const  CTLayer: LayerTypes = 4;
const  PulvinarLayer: LayerTypes = 5;
const  TRNLayer: LayerTypes = 6;
const  PTMaintLayer: LayerTypes = 7;
const  PTPredLayer: LayerTypes = 8;
const  MatrixLayer: LayerTypes = 9;
const  STNLayer: LayerTypes = 10;
const  GPLayer: LayerTypes = 11;
const  BGThalLayer: LayerTypes = 12;
const  VSGatedLayer: LayerTypes = 13;
const  BLALayer: LayerTypes = 14;
const  CeMLayer: LayerTypes = 15;
const  VSPatchLayer: LayerTypes = 16;
const  LHbLayer: LayerTypes = 17;
const  DrivesLayer: LayerTypes = 18;
const  UrgencyLayer: LayerTypes = 19;
const  USLayer: LayerTypes = 20;
const  PVLayer: LayerTypes = 21;
const  LDTLayer: LayerTypes = 22;
const  VTALayer: LayerTypes = 23;
const  RewLayer: LayerTypes = 24;
const  RWPredLayer: LayerTypes = 25;
const  RWDaLayer: LayerTypes = 26;
const  TDPredLayer: LayerTypes = 27;
const  TDIntegLayer: LayerTypes = 28;
const  TDDaLayer: LayerTypes = 29;

//////// import: "layervars.go"
alias LayerVars = i32; //enums:enum
const  LayerActMAvg: LayerVars = 0;
const  LayerActPAvg: LayerVars = 1;
const  LayerAvgMaxGeM: LayerVars = 2;
const  LayerAvgMaxGiM: LayerVars = 3;
const  LayerGiMult: LayerVars = 4;
const  LayerPhaseDiff: LayerVars = 5;
const  LayerPhaseDiffAvg: LayerVars = 6;
const  LayerPhaseDiffVar: LayerVars = 7;
const  LayerRT: LayerVars = 8;
const  GatedRT: LayerVars = 9;
const  LayerRewPredPos: LayerVars = 10;
const  LayerRewPredNeg: LayerVars = 11;

//////// import: "learn-layer.go"

//////// import: "learn-net.go"

//////// import: "learn-path.go"

//////// import: "learn.go"
struct LearnCaParams {
	Norm: f32,
	SpikeVGCC: i32,
	SpikeVgccCa: f32,
	VgccTau: f32,
	Dt: CaDtParams,
	VgccDt: f32,
	NormInv: f32,
	pad: i32,
	pad2: i32,
}
struct TrgAvgActParams {
	GiBaseInit: f32,
	RescaleOn: i32,
	ErrLRate: f32,
	SynScaleRate: f32,
	SubMean: f32,
	Permute: i32,
	Pool: i32,
	pad: i32,
	TrgRange: F32,
}
struct RLRateParams {
	On: i32,
	SigmoidLinear: i32,
	SigmoidMin: f32,
	Diff: i32,
	SpikeThr: f32,
	DiffThr: f32,
	Min: f32,
	pad: i32,
}
struct LearnNeuronParams {
	CaLearn: LearnCaParams,
	CaSpike: CaSpikeParams,
	LearnNMDA: NMDAParams,
	TrgAvgAct: TrgAvgActParams,
	RLRate: RLRateParams,
	NeuroMod: NeuroModParams,
}
struct SWtInitParams {
	SPct: f32,
	Mean: f32,
	Var: f32,
	Sym: i32,
}
struct SWtAdaptParams {
	On: i32,
	LRate: f32,
	SubMean: f32,
	SigGain: f32,
}
struct SWtParams {
	Init: SWtInitParams,
	Adapt: SWtAdaptParams,
	Limit: F32,
}
struct LRateParams {
	Base: f32,
	Sched: f32,
	Mod: f32,
	Eff: f32,
}
struct DWtParams {
	Trace: i32,
	Tau: f32,
	CaPScale: f32,
	SubMean: f32,
	LearnThr: f32,
	Dt: f32,
	pad: f32,
	pad1: f32,
}
struct HebbParams {
	On: i32,
	Up: f32,
	Down: f32,
	pad: f32,
}
struct LearnSynParams {
	Learn: i32,
	pad: i32,
	pad1: i32,
	pad2: i32,
	LRate: LRateParams,
	DWt: DWtParams,
	SynCaBin: SynCaBin,
	Hebb: HebbParams,
}

//////// import: "looper.go"
alias ViewTimes = i32; //enums:enum
const  Cycle: ViewTimes = 0;
const  FastSpike: ViewTimes = 1;
const  Gamma: ViewTimes = 2;
const  Beta: ViewTimes = 3;
const  Alpha: ViewTimes = 4;
const  Phase: ViewTimes = 5;
const  Theta: ViewTimes = 6;

//////// import: "math32-fastexp.go"

//////// import: "minmax-avgmax.go"
const  MaxFloat32: f32 = 3.402823466e+38;
const  MinFloat32: f32 = 1.175494351e-38;
struct AvgMax32 {
	Avg: f32,
	Max: f32,
	Sum: f32,
	MaxIndex: i32,
	N: i32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}

//////// import: "minmax-minmax32.go"
struct F32 {
	Min: f32,
	Max: f32,
	pad: i32,
	pad1: i32, // for gpu use
}

//////// import: "network.go"
struct NetworkIndexes {
	MaxData: u32,
	MaxDelay: u32,
	NCaBins: i32,
	NLayers: u32,
	NNeurons: u32,
	NPools: u32,
	NPaths: u32,
	NSyns: u32,
	RubiconNPosUSs: u32,
	RubiconNCosts: u32,
	RubiconNNegUSs: u32,
	GPUMaxBuffFloats: u32,
	GPUSynCaBanks: u32,
	pad: u32,
	pad1: u32,
	pad2: u32,
}

//////// import: "neuromod.go"
alias DAModTypes = i32; //enums:enum
const  NoDAMod: DAModTypes = 0;
const  D1Mod: DAModTypes = 1;
const  D2Mod: DAModTypes = 2;
const  D1AbsMod: DAModTypes = 3;
alias ValenceTypes = i32; //enums:enum
const  Positive: ValenceTypes = 0;
const  Negative: ValenceTypes = 1;
const  Cost: ValenceTypes = 2;
struct NeuroModParams {
	DAMod: DAModTypes,
	Valence: ValenceTypes,
	DAModGain: f32,
	DALRateSign: i32,
	DALRateMod: f32,
	AChLRateMod: f32,
	AChDisInhib: f32,
	BurstGain: f32,
	DipGain: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "neuron.go"
alias NeuronFlags = i32; //enums:enum
const  NeuronOff: NeuronFlags = 1;
const  NeuronHasExt: NeuronFlags = 2;
const  NeuronHasTarg: NeuronFlags = 4;
const  NeuronHasCmpr: NeuronFlags = 8;
alias NeuronVars = i32; //enums:enum
const  Spike: NeuronVars = 0;
const  Spiked: NeuronVars = 1;
const  Act: NeuronVars = 2;
const  ActInt: NeuronVars = 3;
const  Ge: NeuronVars = 4;
const  Gi: NeuronVars = 5;
const  Gk: NeuronVars = 6;
const  Inet: NeuronVars = 7;
const  Vm: NeuronVars = 8;
const  VmDend: NeuronVars = 9;
const  ISI: NeuronVars = 10;
const  ISIAvg: NeuronVars = 11;
const  Ext: NeuronVars = 12;
const  Target: NeuronVars = 13;
const  CaM: NeuronVars = 14;
const  CaP: NeuronVars = 15;
const  CaD: NeuronVars = 16;
const  CaDPrev: NeuronVars = 17;
const  CaSyn: NeuronVars = 18;
const  LearnCa: NeuronVars = 19;
const  LearnCaM: NeuronVars = 20;
const  LearnCaP: NeuronVars = 21;
const  LearnCaD: NeuronVars = 22;
const  CaDiff: NeuronVars = 23;
const  RLRate: NeuronVars = 24;
const  GnmdaSyn: NeuronVars = 25;
const  Gnmda: NeuronVars = 26;
const  GnmdaLrn: NeuronVars = 27;
const  GnmdaMaint: NeuronVars = 28;
const  NmdaCa: NeuronVars = 29;
const  Gvgcc: NeuronVars = 30;
const  VgccM: NeuronVars = 31;
const  VgccH: NeuronVars = 32;
const  VgccCa: NeuronVars = 33;
const  VgccCaInt: NeuronVars = 34;
const  Burst: NeuronVars = 35;
const  BurstPrv: NeuronVars = 36;
const  CtxtGe: NeuronVars = 37;
const  CtxtGeRaw: NeuronVars = 38;
const  CtxtGeOrig: NeuronVars = 39;
const  GgabaB: NeuronVars = 40;
const  GABAB: NeuronVars = 41;
const  GABABx: NeuronVars = 42;
const  Gak: NeuronVars = 43;
const  SSGiDend: NeuronVars = 44;
const  GknaMed: NeuronVars = 45;
const  GknaSlow: NeuronVars = 46;
const  Gkir: NeuronVars = 47;
const  KirM: NeuronVars = 48;
const  Gsk: NeuronVars = 49;
const  SKCaIn: NeuronVars = 50;
const  SKCaR: NeuronVars = 51;
const  SKCaM: NeuronVars = 52;
const  Gmahp: NeuronVars = 53;
const  MahpN: NeuronVars = 54;
const  Gsahp: NeuronVars = 55;
const  SahpCa: NeuronVars = 56;
const  SahpN: NeuronVars = 57;
const  ActM: NeuronVars = 58;
const  ActP: NeuronVars = 59;
const  Beta1: NeuronVars = 60;
const  Beta2: NeuronVars = 61;
const  CaPMax: NeuronVars = 62;
const  CaPMaxCa: NeuronVars = 63;
const  GeNoise: NeuronVars = 64;
const  GeNoiseP: NeuronVars = 65;
const  GiNoise: NeuronVars = 66;
const  GiNoiseP: NeuronVars = 67;
const  GeExt: NeuronVars = 68;
const  GeRaw: NeuronVars = 69;
const  GeSyn: NeuronVars = 70;
const  GiRaw: NeuronVars = 71;
const  GiSyn: NeuronVars = 72;
const  GeInt: NeuronVars = 73;
const  GeIntNorm: NeuronVars = 74;
const  GiInt: NeuronVars = 75;
const  GModRaw: NeuronVars = 76;
const  GModSyn: NeuronVars = 77;
const  SMaintP: NeuronVars = 78;
const  GMaintRaw: NeuronVars = 79;
const  GMaintSyn: NeuronVars = 80;
const  NeurFlags: NeuronVars = 81;
const  CaBins: NeuronVars = 82;
alias NeuronAvgVars = i32; //enums:enum
const  ActAvg: NeuronAvgVars = 0;
const  AvgPct: NeuronAvgVars = 1;
const  TrgAvg: NeuronAvgVars = 2;
const  DTrgAvg: NeuronAvgVars = 3;
const  AvgDif: NeuronAvgVars = 4;
const  GeBase: NeuronAvgVars = 5;
const  GiBase: NeuronAvgVars = 6;
alias NeuronIndexVars = i32; //enums:enum
const  NrnNeurIndex: NeuronIndexVars = 0;
const  NrnLayIndex: NeuronIndexVars = 1;
const  NrnSubPool: NeuronIndexVars = 2;

//////// import: "pathparams.go"
const  StartOff: i32 = 0;
const  Nitems: i32 = 1;
const  StartNN: i32 = 2;
struct StartN {
	Start: u32,
	N: u32,
	pad: u32,
	pad1: u32, // todo: see if we can do without these?
}
struct PathIndexes {
	RecvLayer: u32,
	RecvNeurSt: u32,
	RecvNeurN: u32,
	SendLayer: u32,
	SendNeurSt: u32,
	SendNeurN: u32,
	SynapseSt: u32,
	SendConSt: u32,
	RecvConSt: u32,
	RecvSynSt: u32,
	NPathNeurSt: u32,
	pad: u32,
}
struct GScaleValues {
	Scale: f32,
	Rel: f32,
	pad: f32,
	pad1: f32,
}
struct PathParams {
	Type: PathTypes,
	Index: u32,
	pad: i32,
	pad1: i32,
	Indexes: PathIndexes,
	Com: SynComParams,
	PathScale: PathScaleParams,
	SWts: SWtParams,
	Learn: LearnSynParams,
	GScale: GScaleValues,
	RLPred: RLPredPathParams,
	Matrix: MatrixPathParams,
	BLA: BLAPathParams,
	Hip: HipPathParams,
}

//////// import: "pathtypes.go"
alias PathTypes = i32; //enums:enum
const  ForwardPath: PathTypes = 0;
const  BackPath: PathTypes = 1;
const  LateralPath: PathTypes = 2;
const  InhibPath: PathTypes = 3;
const  CTCtxtPath: PathTypes = 4;
const  RWPath: PathTypes = 5;
const  TDPredPath: PathTypes = 6;
const  BLAPath: PathTypes = 7;
const  HipPath: PathTypes = 8;
const  VSPatchPath: PathTypes = 9;
const  VSMatrixPath: PathTypes = 10;
const  DSMatrixPath: PathTypes = 11;

//////// import: "pcore-layer.go"
struct MatrixParams {
	GateThr: f32,
	IsVS: i32,
	OtherMatrixIndex: i32,
	ThalLay1Index: i32,
	ThalLay2Index: i32,
	ThalLay3Index: i32,
	ThalLay4Index: i32,
	ThalLay5Index: i32,
	ThalLay6Index: i32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}
alias GPLayerTypes = i32; //enums:enum
const  GPePr: GPLayerTypes = 0;
const  GPeAk: GPLayerTypes = 1;
const  GPi: GPLayerTypes = 2;
struct GPParams {
	GPType: GPLayerTypes,
	pad: u32,
	pad1: u32,
	pad2: u32,
}

//////// import: "pcore-path.go"
struct MatrixPathParams {
	Credit: f32,
	BasePF: f32,
	Delta: f32,
	VSRewLearn: i32,
}

//////// import: "pool.go"
alias PoolIndexVars = i32; //enums:enum
const  PoolNeurSt: PoolIndexVars = 0;
const  PoolNeurEd: PoolIndexVars = 1;
const  PoolLayerIdx: PoolIndexVars = 2;
const  PoolIsLayer: PoolIndexVars = 3;
alias PoolIntVars = i32; //enums:enum
const  Clamped: PoolIntVars = 0;
const  PoolGated: PoolIntVars = 1;
const  FFsRawInt: PoolIntVars = 2;
const  FBsRawInt: PoolIntVars = 3;
const  GeExtRawInt: PoolIntVars = 4;
const  PoolIntAvgMaxStart: PoolIntVars = 5;
alias AvgMax = i32; //enums:enum
const  Avg: AvgMax = 0;
const  Max: AvgMax = 1;
alias AvgMaxPhases = i32; //enums:enum -trim-prefix AM
const  AMCycle: AvgMaxPhases = 0;
const  AMMinus: AvgMaxPhases = 1;
const  AMPlus: AvgMaxPhases = 2;
const  AMPrev: AvgMaxPhases = 3;
alias AvgMaxVars = i32; //enums:enum -trim-prefix AM
const  AMCaP: AvgMaxVars = 0;
const  AMCaD: AvgMaxVars = 1;
const  AMCaPMax: AvgMaxVars = 2;
const  AMAct: AvgMaxVars = 3;
const  AMGeInt: AvgMaxVars = 4;
const  AMGiInt: AvgMaxVars = 5;
const  AMAvgDif: AvgMaxVars = 6;
const  poolFloatAvgMaxStart = InhibVarsN;
const  PoolVarsN = poolFloatAvgMaxStart + InhibVars(i32(AvgMaxVarsN)*i32(AvgMaxN)*i32(AvgMaxPhasesN));
const  PoolIntVarsTot = PoolIntAvgMaxStart + PoolIntVars(i32(AvgMaxVarsN)*i32(AvgMaxN));
const avgMaxToNeuron = array(CaP, CaD, CaPMax, Act, GeInt, GiInt);

//////// import: "rand.go"
alias RandFunIndex = u32;
const  RandFunActPGe: RandFunIndex = 0;
const  RandFunActPGi: RandFunIndex = 1;
const  RandFunActSMaintP: RandFunIndex = 2;
const  RandFunIndexN: RandFunIndex = 3;

//////// import: "rl-layer.go"
struct RWPredParams {
	PredRange: F32,
}
struct RWDaParams {
	TonicGe: f32,
	RWPredLayIndex: i32,
	pad: u32,
	pad1: u32,
}
struct TDIntegParams {
	Discount: f32,
	PredGain: f32,
	TDPredLayIndex: i32,
	pad: u32,
}
struct TDDaParams {
	TonicGe: f32,
	TDIntegLayIndex: i32,
	pad: u32,
	pad1: u32,
}

//////// import: "rl-path.go"
struct RLPredPathParams {
	OppSignLRate: f32,
	DaTol: f32,
	pad: f32,
	pad1: f32,
}

//////// import: "rubicon-layer.go"
struct LDTParams {
	SrcThr: f32,
	Rew: i32,
	MaintInhib: f32,
	SrcLay1Index: i32,
	SrcLay2Index: i32,
	SrcLay3Index: i32,
	SrcLay4Index: i32,
	pad: f32,
}
struct VTAParams {
	CeMGain: f32,
	LHbGain: f32,
	AChThr: f32,
	pad: f32,
}

//////// import: "rubicon-path.go"
struct BLAPathParams {
	NegDeltaLRate: f32,
	AChThr: f32,
	USTrace: f32,
	pad: f32,
}

//////// import: "rubicon.go"

//////// import: "stats.go"

//////// import: "synapse.go"
alias SynapseVars = i32; //enums:enum
const  Wt: SynapseVars = 0;
const  LWt: SynapseVars = 1;
const  SWt: SynapseVars = 2;
const  DWt: SynapseVars = 3;
const  DSWt: SynapseVars = 4;
alias SynapseTraceVars = i32; //enums:enum
const  Tr: SynapseTraceVars = 0;
const  DTr: SynapseTraceVars = 1;
const  DiDWt: SynapseTraceVars = 2;
alias SynapseIndexVars = i32; //enums:enum
const  SynRecvIndex: SynapseIndexVars = 0;
const  SynSendIndex: SynapseIndexVars = 1;
const  SynPathIndex: SynapseIndexVars = 2;

//////// import: "slrand.wgsl"
fn Philox2x32round(counter: su64, key: u32) -> su64 {
	let mul = Uint32Mul64(u32(0xD256D193), counter.x);
	var ctr: su64;
	ctr.x = mul.y ^ key ^ counter.y;
	ctr.y = mul.x;
	return ctr;
}
fn Philox2x32bumpkey(key: u32) -> u32 {
	return key + u32(0x9E3779B9);
}
fn Philox2x32(counter: su64, key: u32) -> vec2<u32> {
	var ctr = Philox2x32round(counter, key); // 1
	var ky = Philox2x32bumpkey(key);
	ctr = Philox2x32round(ctr, ky); // 2
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 3
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 4
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 5
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 6
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 7
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 8
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 9
	ky = Philox2x32bumpkey(ky);
	return Philox2x32round(ctr, ky); // 10
}
fn RandUint32Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<u32> {
	return Philox2x32(Uint64Add32(counter, funcIndex), key);
}
fn RandUint32(counter: su64, funcIndex: u32, key: u32) -> u32 {
	return Philox2x32(Uint64Add32(counter, funcIndex), key).x;
}
fn RandFloat32Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> {
	return Uint32ToFloat32Vec2(RandUint32Vec2(counter, funcIndex, key));
}
fn RandFloat32(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return Uint32ToFloat32(RandUint32(counter, funcIndex, key));
}
fn RandFloat32Range11Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> {
	return Uint32ToFloat32Vec2(RandUint32Vec2(counter, funcIndex, key));
}
fn RandFloat32Range11(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return Uint32ToFloat32Range11(RandUint32(counter, funcIndex, key));
}
fn RandBoolP(counter: su64, funcIndex: u32, key: u32, p: f32) -> bool { 
	return (RandFloat32(counter, funcIndex, key) < p);
}
fn sincospi(x: f32) -> vec2<f32> {
	let PIf = 3.1415926535897932;
	var r: vec2<f32>;
	r.x = cos(PIf*x);
	r.y = sin(PIf*x);
	return r;
}
fn RandFloat32NormVec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> { 
	let ur = RandUint32Vec2(counter, funcIndex, key);
	var f = sincospi(Uint32ToFloat32Range11(ur.x));
	let r = sqrt(-2.0 * log(Uint32ToFloat32(ur.y))); // guaranteed to avoid 0.
	return f * r;
}
fn RandFloat32Norm(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return RandFloat32Vec2(counter, funcIndex, key).x;
}
fn RandUint32N(counter: su64, funcIndex: u32, key: u32, n: u32) -> u32 { 
	let v = RandFloat32(counter, funcIndex, key);
	return u32(v * f32(n));
}
struct RandCounter {
	Counter: su64,
	HiSeed: u32,
	pad: u32,
}
fn RandCounter_Reset(ct: ptr<function,RandCounter>) {
	(*ct).Counter.x = u32(0);
	(*ct).Counter.y = (*ct).HiSeed;
}
fn RandCounter_Seed(ct: ptr<function,RandCounter>, seed: u32) {
	(*ct).HiSeed = seed;
	RandCounter_Reset(ct);
}
fn RandCounter_Add(ct: ptr<function,RandCounter>, inc: u32) {
	(*ct).Counter = Uint64Add32((*ct).Counter, inc);
}

//////// import: "sltype.wgsl"
alias su64 = vec2<u32>;
fn Uint32Mul64(a: u32, b: u32) -> su64 {
	let LOMASK = (((u32(1))<<16)-1);
	var r: su64;
	r.x = a * b;               /* full low multiply */
	let ahi = a >> 16;
	let alo = a & LOMASK;
	let bhi = b >> 16;
	let blo = b & LOMASK;
	let ahbl = ahi * blo;
	let albh = alo * bhi;
	let ahbl_albh = ((ahbl&LOMASK) + (albh&LOMASK));
	var hit = ahi*bhi + (ahbl>>16) +  (albh>>16);
	hit += ahbl_albh >> 16; /* carry from the sum of lo(ahbl) + lo(albh) ) */
	/* carry from the sum with alo*blo */
	if ((r.x >> u32(16)) < (ahbl_albh&LOMASK)) {
		hit += u32(1);
	}
	r.y = hit; 
	return r;
}
/*
fn Uint32Mul64(a: u32, b: u32) -> su64 {
	return su64(a) * su64(b);
}
*/
fn Uint64Add32(a: su64, b: u32) -> su64 {
	if (b == 0) {
		return a;
	}
	var s = a;
	if (s.x > u32(0xffffffff) - b) {
		s.y++;
		s.x = (b - 1) - (u32(0xffffffff) - s.x);
	} else {
		s.x += b;
	}
	return s;
}
fn Uint64Incr(a: su64) -> su64 {
	var s = a;
	if(s.x == 0xffffffff) {
		s.y++;
		s.x = u32(0);
	} else {
		s.x++;
	}
	return s;
}
fn Uint32ToFloat32(val: u32) -> f32 {
	let factor = f32(1.0) / (f32(u32(0xffffffff)) + f32(1.0));
	let halffactor = f32(0.5) * factor;
	var f = f32(val) * factor + halffactor;
	if (f == 1.0) { // exclude 1
		return bitcast<f32>(0x3F7FFFFF);
	}
	return f;
}
fn Uint32ToFloat32Vec2(val: vec2<u32>) -> vec2<f32> {
	var r: vec2<f32>;
	r.x = Uint32ToFloat32(val.x);
	r.y = Uint32ToFloat32(val.y);
	return r;
}
fn Uint32ToFloat32Range11(val: u32) -> f32 {
	let factor = f32(1.0) / (f32(i32(0x7fffffff)) + f32(1.0));
	let halffactor = f32(0.5) * factor;
	return (f32(val) * factor + halffactor);
}
fn Uint32ToFloat32Range11Vec2(val: vec2<u32>) -> vec2<f32> {
	var r: vec2<f32>;
	r.x = Uint32ToFloat32Range11(val.x);
	r.y = Uint32ToFloat32Range11(val.y);
	return r;
}