// Code generated by "gosl"; DO NOT EDIT
// kernel: DWtSyn

// // Layers are all the layer parameters. 
@group(0) @binding(0)
var<storage, read> TensorStrides: array<u32>;
@group(0) @binding(1)
var<storage, read> Layers: array<LayerParams>;
@group(0) @binding(2)
var<storage, read> Paths: array<PathParams>;
// // NetworkIxs have indexes and sizes for entire network (one only). 
@group(1) @binding(0)
var<storage, read> NetworkIxs: array<NetworkIndexes>;
@group(1) @binding(2)
var<storage, read> NeuronIxs: array<u32>;
@group(1) @binding(3)
var<storage, read> SynapseIxs: array<u32>;
// // Ctx is the current context state (one only). This is read-only except in // specific kernels. 
@group(2) @binding(0)
var<storage, read_write> Ctx: array<Context>;
@group(2) @binding(1)
var<storage, read_write> Neurons: array<f32>;
@group(2) @binding(4)
var<storage, read_write> GlobalScalars: array<f32>;
@group(2) @binding(7)
var<storage, read_write> Pools: array<f32>;
// // PathGBuf is the conductance buffer for accumulating spikes. // Subslices are allocated to each pathway. // Uses int-encoded values for faster GPU atomic integration. // [NPathNeur][Data][MaxDel+1]; NPathNeur = [Layer][RecvPaths][RecvNeurons] 
@group(3) @binding(2)
var<storage, read_write> Synapses: array<f32>;
@group(3) @binding(3)
var<storage, read_write> SynapseTraces0: array<f32>;
@group(3) @binding(4)
var<storage, read_write> SynapseTraces1: array<f32>;
@group(3) @binding(5)
var<storage, read_write> SynapseTraces2: array<f32>;
@group(3) @binding(6)
var<storage, read_write> SynapseTraces3: array<f32>;
@group(3) @binding(7)
var<storage, read_write> SynapseTraces4: array<f32>;
@group(3) @binding(8)
var<storage, read_write> SynapseTraces5: array<f32>;
@group(3) @binding(9)
var<storage, read_write> SynapseTraces6: array<f32>;

alias GPUVars = i32;

@compute @workgroup_size(64, 1, 1)
fn main(@builtin(workgroup_id) wgid: vec3<u32>, @builtin(num_workgroups) nwg: vec3<u32>, @builtin(local_invocation_index) loci: u32) {
	let idx = loci + (wgid.x + wgid.y * nwg.x + wgid.z * nwg.x * nwg.y) * 64;
	DWtSyn(idx);
}

fn Index2D(s0: u32, s1: u32, i0: u32, i1: u32) -> u32 {
	return s0 * i0 + s1 * i1;
}

fn Index3D(s0: u32, s1: u32, s2: u32, i0: u32, i1: u32, i2: u32) -> u32 {
	return s0 * i0 + s1 * i1 + s2 * i2;
}

fn SynapseTracesGet(ix: u32) -> f32 {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		return SynapseTraces0[ix];
	}
	case u32(1): {
		return SynapseTraces1[ix - 536870904];
	}
	case u32(2): {
		return SynapseTraces2[ix - 1073741808];
	}
	case u32(3): {
		return SynapseTraces3[ix - 1610612712];
	}
	case u32(4): {
		return SynapseTraces4[ix - 2147483616];
	}
	case u32(5): {
		return SynapseTraces5[ix - 2684354520];
	}
	default: {
		return SynapseTraces6[ix - 3221225424];
	}
	}
}

fn SynapseTracesSet(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		SynapseTraces0[ix] = vl;
	}
	case u32(1): {
		SynapseTraces1[ix - 536870904] = vl;
	}
	case u32(2): {
		SynapseTraces2[ix - 1073741808] = vl;
	}
	case u32(3): {
		SynapseTraces3[ix - 1610612712] = vl;
	}
	case u32(4): {
		SynapseTraces4[ix - 2147483616] = vl;
	}
	case u32(5): {
		SynapseTraces5[ix - 2684354520] = vl;
	}
	default: {
		SynapseTraces6[ix - 3221225424] = vl;
	}
	}
}

fn SynapseTracesSetAdd(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		SynapseTraces0[ix] += vl;
	}
	case u32(1): {
		SynapseTraces1[ix - 536870904] += vl;
	}
	case u32(2): {
		SynapseTraces2[ix - 1073741808] += vl;
	}
	case u32(3): {
		SynapseTraces3[ix - 1610612712] += vl;
	}
	case u32(4): {
		SynapseTraces4[ix - 2147483616] += vl;
	}
	case u32(5): {
		SynapseTraces5[ix - 2684354520] += vl;
	}
	default: {
		SynapseTraces6[ix - 3221225424] += vl;
	}
	}
}

fn SynapseTracesSetSub(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		SynapseTraces0[ix] -= vl;
	}
	case u32(1): {
		SynapseTraces1[ix - 536870904] -= vl;
	}
	case u32(2): {
		SynapseTraces2[ix - 1073741808] -= vl;
	}
	case u32(3): {
		SynapseTraces3[ix - 1610612712] -= vl;
	}
	case u32(4): {
		SynapseTraces4[ix - 2147483616] -= vl;
	}
	case u32(5): {
		SynapseTraces5[ix - 2684354520] -= vl;
	}
	default: {
		SynapseTraces6[ix - 3221225424] -= vl;
	}
	}
}

fn SynapseTracesSetMul(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		SynapseTraces0[ix] *= vl;
	}
	case u32(1): {
		SynapseTraces1[ix - 536870904] *= vl;
	}
	case u32(2): {
		SynapseTraces2[ix - 1073741808] *= vl;
	}
	case u32(3): {
		SynapseTraces3[ix - 1610612712] *= vl;
	}
	case u32(4): {
		SynapseTraces4[ix - 2147483616] *= vl;
	}
	case u32(5): {
		SynapseTraces5[ix - 2684354520] *= vl;
	}
	default: {
		SynapseTraces6[ix - 3221225424] *= vl;
	}
	}
}

fn SynapseTracesSetDiv(vl: f32, ix: u32) {
	let ii = ix / 536870904;
	switch ii {
	case u32(0): {
		SynapseTraces0[ix] /= vl;
	}
	case u32(1): {
		SynapseTraces1[ix - 536870904] /= vl;
	}
	case u32(2): {
		SynapseTraces2[ix - 1073741808] /= vl;
	}
	case u32(3): {
		SynapseTraces3[ix - 1610612712] /= vl;
	}
	case u32(4): {
		SynapseTraces4[ix - 2147483616] /= vl;
	}
	case u32(5): {
		SynapseTraces5[ix - 2684354520] /= vl;
	}
	default: {
		SynapseTraces6[ix - 3221225424] /= vl;
	}
	}
}


//////// import: "vars.go"

//////// import: "act-layer.go"
fn LayerParams_IsTarget(ly: LayerParams) -> bool {
	return ly.Type == TargetLayer || ly.Type == PulvinarLayer || ly.Type == CNiPredLayer;
}

//////// import: "act-net.go"

//////// import: "act-path.go"
alias PathGTypes = i32; //enums:enum
const  ExcitatoryG: PathGTypes = 0;
const  InhibitoryG: PathGTypes = 1;
const  ModulatoryG: PathGTypes = 2;
const  MaintG: PathGTypes = 3;
const  ContextG: PathGTypes = 4;
struct SynComParams {
	GType: PathGTypes,
	Delay: u32,
	MaxDelay: u32,
	DelLen: u32,
}
struct PathScaleParams {
	Rel: f32,
	Abs: f32,
	pad: f32,
	pad1: f32,
}

//////// import: "act.go"
struct SpikeParams {
	Thr: f32,
	VmR: f32,
	Tr: i32,
	RTau: f32,
	Exp: i32,
	ExpSlope: f32,
	ExpThr: f32,
	MaxHz: f32,
	ISITau: f32,
	ISIDt: f32,
	RDt: f32,
	pad: i32,
}
struct DendParams {
	GExp: f32,
	GR: f32,
	SSGi: f32,
	HasMod: i32,
	ModGain: f32,
	ModACh: i32,
	ModBase: f32,
	pad: i32,
}
struct ActInitParams {
	Vm: f32,
	Act: f32,
	GeBase: f32,
	GiBase: f32,
	GeVar: f32,
	GiVar: f32,
	pad: i32,
	pad1: i32,
}
struct DecayParams {
	Act: f32,
	Glong: f32,
	AHP: f32,
	LearnCa: f32,
	OnRew: i32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
struct DtParams {
	Integ: f32,
	VmC: f32,
	VmDendC: f32,
	VmSteps: i32,
	GeTau: f32,
	GiTau: f32,
	IntTau: f32,
	LongAvgTau: f32,
	MaxCycStart: i32,
	VmDt: f32,
	VmDendDt: f32,
	DtStep: f32,
	GeDt: f32,
	GiDt: f32,
	IntDt: f32,
	LongAvgDt: f32,
	MaxI: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
struct SpikeNoiseParams {
	On: i32,
	GeHz: f32,
	Ge: f32,
	GiHz: f32,
	Gi: f32,
	MaintGe: i32,
	GeExpInt: f32,
	GiExpInt: f32,
}
struct ClampParams {
	Ge: f32,
	Add: i32,
	ErrThr: f32,
	pad: f32,
}
struct SMaintParams {
	On: i32,
	NNeurons: f32,
	Ge: f32,
	Inhib: f32,
	ISI: F32,
}
struct PopCodeParams {
	On: i32,
	Ge: f32,
	Min: f32,
	Max: f32,
	MinAct: f32,
	MinSigma: f32,
	MaxSigma: f32,
	Clip: i32,
}
struct ActParams {
	Spikes: SpikeParams,
	Dend: DendParams,
	Init: ActInitParams,
	Decay: DecayParams,
	Dt: DtParams,
	Gbar: Chans,
	Erev: Chans,
	Clamp: ClampParams,
	Noise: SpikeNoiseParams,
	VmRange: F32,
	Mahp: MahpParams,
	Sahp: SahpParams,
	KNa: KNaMedSlow,
	Kir: KirParams,
	NMDA: NMDAParams,
	MaintNMDA: NMDAParams,
	GabaB: GABABParams,
	VGCC: VGCCParams,
	AK: AKsParams,
	SKCa: SKCaParams,
	SMaint: SMaintParams,
	PopCode: PopCodeParams,
}

//////// import: "cereb-layer.go"
struct CNiPredParams {
	DriveScale: f32,
	FullDriveAct: f32,
	DriveLayIndex: i32,
	pad: f32,
}
struct CNeUpParams {
	ActTarg: f32,
	LearnThr: f32,
	GeBaseLRate: f32,
	PredLayIndex: i32,
	SenseLayIndex: i32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "chans-ak.go"
struct AKsParams {
	Gk: f32,
	Hf: f32,
	Mf: f32,
	Voff: f32,
	Vmax: f32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}

//////// import: "chans-chans.go"
struct Chans {
	E: f32,
	L: f32,
	I: f32,
	K: f32,
}

//////// import: "chans-gabab.go"
struct GABABParams {
	Gk: f32,
	Rise: f32,
	Decay: f32,
	Gbase: f32,
	GiSpike: f32,
	MaxTime: f32,
	TauFact: f32,
	RiseDt: f32,
	DecayDt: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "chans-kir.go"
struct KirParams {
	Gk: f32,
	MinfOff: f32,
	MinfTau: f32,
	RiseOff: f32,
	RiseTau: f32,
	DecayOff: f32,
	DecayTau: f32,
	Mrest: f32,
}

//////// import: "chans-kna.go"
struct KNaParams {
	On: i32,
	Gk: f32,
	Rise: f32,
	Decay: f32,
	DtRise: f32,
	DtDecay: f32,
	pad: i32,
	pad1: i32,
}
struct KNaMedSlow {
	On: i32,
	TrialSlow: i32,
	pad: i32,
	pad1: i32,
	Med: KNaParams,
	Slow: KNaParams,
}

//////// import: "chans-mahp.go"
struct MahpParams {
	Gk: f32,
	Off: f32,
	Slope: f32,
	TauMax: f32,
	Tadj: f32,
	DtMax: f32,
	pad: i32,
	pad2: i32,
}

//////// import: "chans-nmda.go"
struct NMDAParams {
	Ge: f32,
	Tau: f32,
	ITau: f32,
	MgC: f32,
	Voff: f32,
	Dt: f32,
	IDt: f32,
	MgFact: f32,
}

//////// import: "chans-sahp.go"
struct SahpParams {
	Gk: f32,
	CaTau: f32,
	Off: f32,
	Slope: f32,
	TauMax: f32,
	CaDt: f32,
	DtMax: f32,
	pad: i32,
}

//////// import: "chans-skca.go"
struct SKCaParams {
	Gk: f32,
	C50: f32,
	Rise: f32,
	Decay: f32,
	KCaR: f32,
	CaRDecayTau: f32,
	CaInThr: f32,
	CaInTau: f32,
	RiseDt: f32,
	DecayDt: f32,
	CaRDecayDt: f32,
	CaInDt: f32,
}

//////// import: "chans-vgcc.go"
struct VGCCParams {
	Ge: f32,
	Ca: f32,
	pad: i32,
	pad1: i32,
}

//////// import: "context.go"
struct Context { //types:add -setters
	NData: u32,
	Mode: i32,
	Testing: i32,
	MinusPhase: i32,
	PlusPhase: i32,
	PhaseCycle: i32,
	Cycle: i32,
	ThetaCycles: i32,
	MinusCycles: i32,
	PlusCycles: i32,
	CaBinCycles: i32,
	CyclesTotal: i32,
	Time: f32,
	TrialsTotal: i32,
	TimePerCycle: f32,
	SlowInterval: i32,
	SlowCounter: i32,
	AdaptGiInterval: i32,
	AdaptGiCounter: i32,
	pad: i32,
	RandCounter: RandCounter,
}
fn Context_ItemIndex(ctx: Context, idx: u32) -> u32 {
	return idx / ctx.NData;
}
fn Context_DataIndex(ctx: Context, idx: u32) -> u32 {
	return idx % ctx.NData;
}

//////// import: "deep-layer.go"
struct BurstParams {
	ThrRel: f32,
	ThrAbs: f32,
	pad: f32,
	pad1: f32,
}
struct CTParams {
	GeGain: f32,
	DecayTau: f32,
	OFCposPT: i32,
	DecayDt: f32,
}
struct PulvinarParams {
	DriveScale: f32,
	FullDriveAct: f32,
	DriveLayIndex: i32,
	pad: f32,
}

//////// import: "enumgen.go"
const PathGTypesN: PathGTypes = 5;
const GlobalScalarVarsN: GlobalScalarVars = 58;
const GlobalVectorVarsN: GlobalVectorVars = 10;
const GPUVarsN: GPUVars = 23;
const LayerTypesN: LayerTypes = 34;
const LayerVarsN: LayerVars = 12;
const ViewTimesN: ViewTimes = 7;
const DAModTypesN: DAModTypes = 4;
const ValenceTypesN: ValenceTypes = 3;
const NeuronFlagsN: NeuronFlags = 9;
const NeuronVarsN: NeuronVars = 89;
const NeuronAvgVarsN: NeuronAvgVars = 7;
const NeuronIndexVarsN: NeuronIndexVars = 3;
const PathTypesN: PathTypes = 14;
const GPLayerTypesN: GPLayerTypes = 3;
const PoolIndexVarsN: PoolIndexVars = 4;
const PoolIntVarsN: PoolIntVars = 6;
const AvgMaxN: AvgMax = 2;
const AvgMaxPhasesN: AvgMaxPhases = 4;
const AvgMaxVarsN: AvgMaxVars = 7;
const SynapseVarsN: SynapseVars = 5;
const SynapseTraceVarsN: SynapseTraceVars = 3;
const SynapseIndexVarsN: SynapseIndexVars = 3;

//////// import: "fsfffb-enumgen.go"
const InhibVarsN: InhibVars = 19;

//////// import: "fsfffb-fsfffb.go"
struct GiParams {
	On: i32,
	Gi: f32,
	FB: f32,
	FSTau: f32,
	SS: f32,
	SSfTau: f32,
	SSiTau: f32,
	FS0: f32,
	FFAvgTau: f32,
	FFPrv: f32,
	ClampExtMin: f32,
	FSDt: f32,
	SSfDt: f32,
	SSiDt: f32,
	FFAvgDt: f32,
	pad: f32,
}

//////// import: "fsfffb-inhib.go"
alias InhibVars = i32; //enums:enum
const  FFsRaw: InhibVars = 0;
const  FBsRaw: InhibVars = 1;
const  GeExtRaw: InhibVars = 2;
const  FFs: InhibVars = 3;
const  FBs: InhibVars = 4;
const  GeExts: InhibVars = 5;
const  FSi: InhibVars = 6;
const  SSi: InhibVars = 7;
const  SSf: InhibVars = 8;
const  FSGi: InhibVars = 9;
const  SSGi: InhibVars = 10;
const  TotalGi: InhibVars = 11;
const  GiOrig: InhibVars = 12;
const  LayGi: InhibVars = 13;
const  FFAvg: InhibVars = 14;
const  FFAvgPrv: InhibVars = 15;
const  ModAct: InhibVars = 16;
const  DAD1: InhibVars = 17;
const  DAD2: InhibVars = 18;

//////// import: "globals.go"
alias GlobalScalarVars = i32; //enums:enum
const  GvRew: GlobalScalarVars = 0;
const  GvHasRew: GlobalScalarVars = 1;
const  GvRewPred: GlobalScalarVars = 2;
const  GvPrevPred: GlobalScalarVars = 3;
const  GvHadRew: GlobalScalarVars = 4;
const  GvDA: GlobalScalarVars = 5;
const  GvDAtonic: GlobalScalarVars = 6;
const  GvACh: GlobalScalarVars = 7;
const  GvNE: GlobalScalarVars = 8;
const  GvSer: GlobalScalarVars = 9;
const  GvAChRaw: GlobalScalarVars = 10;
const  GvGoalMaint: GlobalScalarVars = 11;
const  GvVSMatrixJustGated: GlobalScalarVars = 12;
const  GvVSMatrixHasGated: GlobalScalarVars = 13;
const  GvCuriosityPoolGated: GlobalScalarVars = 14;
const  GvTime: GlobalScalarVars = 15;
const  GvEffort: GlobalScalarVars = 16;
const  GvUrgencyRaw: GlobalScalarVars = 17;
const  GvUrgency: GlobalScalarVars = 18;
const  GvHasPosUS: GlobalScalarVars = 19;
const  GvHadPosUS: GlobalScalarVars = 20;
const  GvNegUSOutcome: GlobalScalarVars = 21;
const  GvHadNegUSOutcome: GlobalScalarVars = 22;
const  GvPVposSum: GlobalScalarVars = 23;
const  GvPVpos: GlobalScalarVars = 24;
const  GvPVnegSum: GlobalScalarVars = 25;
const  GvPVneg: GlobalScalarVars = 26;
const  GvPVposEst: GlobalScalarVars = 27;
const  GvPVposVar: GlobalScalarVars = 28;
const  GvPVnegEst: GlobalScalarVars = 29;
const  GvPVnegVar: GlobalScalarVars = 30;
const  GvGoalDistEst: GlobalScalarVars = 31;
const  GvGoalDistPrev: GlobalScalarVars = 32;
const  GvProgressRate: GlobalScalarVars = 33;
const  GvGiveUpUtility: GlobalScalarVars = 34;
const  GvContUtility: GlobalScalarVars = 35;
const  GvGiveUpTiming: GlobalScalarVars = 36;
const  GvContTiming: GlobalScalarVars = 37;
const  GvGiveUpProgress: GlobalScalarVars = 38;
const  GvContProgress: GlobalScalarVars = 39;
const  GvGiveUpSum: GlobalScalarVars = 40;
const  GvContSum: GlobalScalarVars = 41;
const  GvGiveUpProb: GlobalScalarVars = 42;
const  GvGiveUp: GlobalScalarVars = 43;
const  GvGaveUp: GlobalScalarVars = 44;
const  GvVSPatchPos: GlobalScalarVars = 45;
const  GvVSPatchPosThr: GlobalScalarVars = 46;
const  GvVSPatchPosRPE: GlobalScalarVars = 47;
const  GvVSPatchPosSum: GlobalScalarVars = 48;
const  GvVSPatchPosPrev: GlobalScalarVars = 49;
const  GvVSPatchPosVar: GlobalScalarVars = 50;
const  GvLHbDip: GlobalScalarVars = 51;
const  GvLHbBurst: GlobalScalarVars = 52;
const  GvLHbPVDA: GlobalScalarVars = 53;
const  GvCeMpos: GlobalScalarVars = 54;
const  GvCeMneg: GlobalScalarVars = 55;
const  GvVtaDA: GlobalScalarVars = 56;
const  GvCaBinWts: GlobalScalarVars = 57;
const MaxGlobalVecN = 16;
alias GlobalVectorVars = i32; //enums:enum
const  GvCost: GlobalVectorVars = 0;
const  GvCostRaw: GlobalVectorVars = 1;
const  GvUSneg: GlobalVectorVars = 2;
const  GvUSnegRaw: GlobalVectorVars = 3;
const  GvDrives: GlobalVectorVars = 4;
const  GvUSpos: GlobalVectorVars = 5;
const  GvVSPatchD1: GlobalVectorVars = 6;
const  GvVSPatchD2: GlobalVectorVars = 7;
const  GvOFCposPTMaint: GlobalVectorVars = 8;
const  GvVSMatrixPoolGated: GlobalVectorVars = 9;

//////// import: "hip_paths.go"
struct HipPathParams {
	Hebb: f32,
	Err: f32,
	SAvgCor: f32,
	SAvgThr: f32,
	SNominal: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "inhib.go"
struct ActAvgParams {
	Nominal: f32,
	RTThr: f32,
	AdaptGi: i32,
	Offset: f32,
	HiTol: f32,
	LoTol: f32,
	AdaptRate: f32,
	AdaptMax: f32,
}
struct InhibParams {
	ActAvg: ActAvgParams,
	Layer: GiParams,
	Pool: GiParams,
}

//////// import: "init-layer.go"

//////// import: "kinase-params.go"
struct CaDtParams { //types:add
	MTau: f32,
	PTau: f32,
	DTau: f32,
	MDt: f32,
	PDt: f32,
	DDt: f32,
	pad: i32,
	pad1: i32,
}
struct CaSpikeParams {
	SpikeCaM: f32,
	SpikeCaSyn: f32,
	CaSynTau: f32,
	CaSynDt: f32,
	Dt: CaDtParams,
}

//////// import: "layerparams.go"
struct LayerIndexes {
	NPools: u32,
	NeurSt: u32,
	NNeurons: u32,
	RecvSt: u32,
	RecvN: u32,
	SendSt: u32,
	SendN: u32,
	ExtsSt: u32,
	ShpPlY: i32,
	ShpPlX: i32,
	ShpUnY: i32,
	ShpUnX: i32,
}
struct LayerInhibIndexes {
	Index1: i32,
	Index2: i32,
	Index3: i32,
	Index4: i32,
}
struct LayerParams {
	Type: LayerTypes,
	Index: u32,
	MaxData: u32,
	PoolSt: u32,
	Acts: ActParams,
	Inhib: InhibParams,
	LayInhib: LayerInhibIndexes,
	Learn: LearnNeuronParams,
	Bursts: BurstParams,
	CT: CTParams,
	Pulvinar: PulvinarParams,
	DSMatrix: DSMatrixParams,
	Striatum: StriatumParams,
	GP: GPParams,
	CNiPred: CNiPredParams,
	CNeUp: CNeUpParams,
	LDT: LDTParams,
	VTA: VTAParams,
	RWPred: RWPredParams,
	RWDa: RWDaParams,
	TDInteg: TDIntegParams,
	TDDa: TDDaParams,
	Indexes: LayerIndexes,
}
fn LayerParams_PoolIndex(ly: LayerParams, pi: u32) -> u32 {
	return ly.PoolSt + pi;
}

//////// import: "layertypes.go"
alias LayerTypes = i32; //enums:enum
const  SuperLayer: LayerTypes = 0;
const  InputLayer: LayerTypes = 1;
const  TargetLayer: LayerTypes = 2;
const  CompareLayer: LayerTypes = 3;
const  CTLayer: LayerTypes = 4;
const  PulvinarLayer: LayerTypes = 5;
const  TRNLayer: LayerTypes = 6;
const  PTMaintLayer: LayerTypes = 7;
const  PTPredLayer: LayerTypes = 8;
const  DSMatrixLayer: LayerTypes = 9;
const  VSMatrixLayer: LayerTypes = 10;
const  DSPatchLayer: LayerTypes = 11;
const  STNLayer: LayerTypes = 12;
const  GPLayer: LayerTypes = 13;
const  BGThalLayer: LayerTypes = 14;
const  VSGatedLayer: LayerTypes = 15;
const  CNiPredLayer: LayerTypes = 16;
const  CNeUpLayer: LayerTypes = 17;
const  BLALayer: LayerTypes = 18;
const  CeMLayer: LayerTypes = 19;
const  VSPatchLayer: LayerTypes = 20;
const  LHbLayer: LayerTypes = 21;
const  DrivesLayer: LayerTypes = 22;
const  UrgencyLayer: LayerTypes = 23;
const  USLayer: LayerTypes = 24;
const  PVLayer: LayerTypes = 25;
const  LDTLayer: LayerTypes = 26;
const  VTALayer: LayerTypes = 27;
const  RewLayer: LayerTypes = 28;
const  RWPredLayer: LayerTypes = 29;
const  RWDaLayer: LayerTypes = 30;
const  TDPredLayer: LayerTypes = 31;
const  TDIntegLayer: LayerTypes = 32;
const  TDDaLayer: LayerTypes = 33;

//////// import: "layervars.go"
alias LayerVars = i32; //enums:enum
const  LayerActMAvg: LayerVars = 0;
const  LayerActPAvg: LayerVars = 1;
const  LayerAvgMaxGeM: LayerVars = 2;
const  LayerAvgMaxGiM: LayerVars = 3;
const  LayerGiMult: LayerVars = 4;
const  LayerPhaseDiff: LayerVars = 5;
const  LayerPhaseDiffAvg: LayerVars = 6;
const  LayerPhaseDiffVar: LayerVars = 7;
const  LayerRT: LayerVars = 8;
const  GatedRT: LayerVars = 9;
const  LayerRewPredPos: LayerVars = 10;
const  LayerRewPredNeg: LayerVars = 11;

//////// import: "learn-layer.go"

//////// import: "learn-net.go"
fn DWtSyn(i: u32) { //gosl:kernel
	let ctx = Ctx[0];
	var syni = Context_ItemIndex(ctx, i);
	if (syni >= NetworkIxs[0].NSyns) {
		return;
	}
	var di = Context_DataIndex(ctx, i);
	var pti = SynapseIxs[Index2D(TensorStrides[20], TensorStrides[21], u32(syni), u32(SynPathIndex))];
	var si = SynapseIxs[Index2D(TensorStrides[20], TensorStrides[21], u32(syni), u32(SynSendIndex))];
	var ri = SynapseIxs[Index2D(TensorStrides[20], TensorStrides[21], u32(syni), u32(SynRecvIndex))];
	let paths=Paths[pti]; let layers=Layers[Paths[pti].Indexes.RecvLayer]; PathParams_DWtSyn(paths, ctx, layers, syni, si, ri, di);
}

//////// import: "learn-path.go"
fn PathParams_DWtSyn(pt: PathParams, ctx: Context, rlay: LayerParams, syni: u32,si: u32,ri: u32,di: u32) {
	if (pt.Learn.Learn == 0) {
		return;
	}
	var isTarget = LayerParams_IsTarget(rlay);
	var spi = NeuronIxs[Index2D(TensorStrides[10], TensorStrides[11], u32(ri), u32(NrnSubPool))];
	var pi = LayerParams_PoolIndex(rlay, spi);
	var lpi = LayerParams_PoolIndex(rlay, u32(u32(0)));
	switch (pt.Type) {
	case CTCtxtPath: {
		PathParams_DWtSynCTCtxt(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case VSMatrixPath: {
		PathParams_DWtSynVSMatrix(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case DSMatrixPath: {
		PathParams_DWtSynDSMatrix(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case VSPatchPath: {
		PathParams_DWtSynVSPatch(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case DSPatchPath: {
		PathParams_DWtSynDSPatch(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case CNiPredToOutPath: {
		PathParams_DWtSynCNeUp(pt, ctx, rlay, syni, si, ri, lpi, pi, di);
	}
	case RWPath: {
		PathParams_DWtSynRWPred(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case TDPredPath: {
		PathParams_DWtSynTDPred(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case BLAPath: {
		PathParams_DWtSynBLA(pt, ctx, syni, si, ri, lpi, pi, di);
	}
	case HipPath: {
		PathParams_DWtSynHip(pt, ctx, syni, si, ri, lpi, pi, di, isTarget);
	} // by default this is the same as DWtSynCortex (w/ unused Hebb component in the algorithm) except that it uses WtFromDWtSynNoLimits
	default: {
		if (pt.Learn.Hebb.On == 1) {
			PathParams_DWtSynHebb(pt, ctx, syni, si, ri, lpi, pi, di);
		} else if (isTarget) {
			PathParams_DWtSynTarget(pt, ctx, syni, si, ri, lpi, pi, di);
		} else {
			PathParams_DWtSynCortex(pt, ctx, syni, si, ri, lpi, pi, di);
		}
	}
	}
}
fn PathParams_SynCa(pt: PathParams, ctx: Context, si: u32,ri: u32,di: u32, syCaP: ptr<function,f32>,syCaD: ptr<function,f32>) {
	var nbins = NetworkIxs[0].NCaBins;
	var cadSt = GvCaBinWts + GlobalScalarVars(nbins);
	var r0 = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaBins + NeuronVars(0)))];
	var s0 = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(CaBins + NeuronVars(0)))];
	var sp = r0 * s0;
	var cp = sp * GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvCaBinWts + GlobalScalarVars(0)), u32(0))];
	var cd = sp * GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(cadSt + GlobalScalarVars(0)), u32(0))];
	var syn20 = pt.Learn.DWt.SynCa20 == 1;
	for (var i = i32(1); i < nbins; i++) {
		var rt = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaBins + NeuronVars(i)))];
		var rt1 = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaBins + NeuronVars(i-1)))];
		var st = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(CaBins + NeuronVars(i)))];
		var st1 = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(CaBins + NeuronVars(i-1)))];
		var sp = f32(0);
		if (syn20) {
			sp = 0.25 * (rt + rt1) * (st + st1);
		} else {
			sp = rt * st;
		}
		cp += sp * GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvCaBinWts + GlobalScalarVars(i)), u32(0))];
		cd += sp * GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(cadSt + GlobalScalarVars(i)), u32(0))];
	}
	*syCaP = pt.Learn.DWt.CaPScale * cp;
	*syCaD = cd;
}
fn PathParams_DWtSynSoftBound(pt: PathParams, ctx: Context, syni: u32,di: u32, dwt: f32) {
	if (dwt == 0) {
		SynapseTracesSet(0.0, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
	} else {
		var lwt = Synapses[Index2D(TensorStrides[170], TensorStrides[171], // linear weight
		u32(syni), u32(LWt))];
		var edw = dwt;
		if (edw > 0) {
			edw *= (1 - lwt);
		} else {
			edw *= lwt;
		}
		SynapseTracesSet(pt.Learn.LRate.Eff * edw, Index3D(TensorStrides[180], TensorStrides[181],
		TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
	}
}
fn PathParams_DWtSynCortex(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var syCaP: f32;
	var syCaD: f32;
	PathParams_SynCa(pt, ctx, si, ri, di, &syCaP, &syCaD);
	SynapseTracesSet(syCaD, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	var tr = DWtParams_SynTrace(pt.Learn.DWt, SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr))), syCaD);
	SynapseTracesSet(tr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	var dwt = f32(0);
	if (syCaP > pt.Learn.DWt.LearnThr || syCaD > pt.Learn.DWt.LearnThr) {
		dwt = tr * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))] * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnDiff))] * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(ETraceLearn))];
	}
	PathParams_DWtSynSoftBound(pt, ctx, syni, di, dwt);
}
fn PathParams_DWtSynTarget(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var syCaP: f32;
	var syCaD: f32;
	PathParams_SynCa(pt, ctx, si, ri, di, &syCaP, &syCaD);
	SynapseTracesSet(syCaD, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	var tr = DWtParams_SynTrace(pt.Learn.DWt, SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr))), syCaD);
	SynapseTracesSet(tr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	var dwt = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))] * (syCaP - syCaD);
	PathParams_DWtSynSoftBound(pt, ctx, syni, di, dwt);
}
fn PathParams_DWtSynCTCtxt(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var syn = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // previous burst, not synCa
	TensorStrides[72], u32(si), u32(di), u32(BurstPrv))];
	SynapseTracesSet(syn, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	var tr = DWtParams_SynTrace(pt.Learn.DWt, SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr))), syn);
	SynapseTracesSet(tr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	var dwt = tr * (Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnCaP))] - Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnCaD))]) * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(ETraceLearn))];
	PathParams_DWtSynSoftBound(pt, ctx, syni, di, dwt);
}
fn PathParams_DWtSynHebb(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var rLearnCaP = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnCaP))];
	var sNrnCap = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(LearnCaP))];
	var lwt = Synapses[Index2D(TensorStrides[170], TensorStrides[171], // linear weight
	u32(syni), u32(LWt))];
	var hebb = rLearnCaP * (pt.Learn.Hebb.Up*sNrnCap*(1-lwt) - pt.Learn.Hebb.Down*(1-sNrnCap)*lwt);
	SynapseTracesSet(pt.Learn.LRate.Eff * hebb, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
}
fn PathParams_DWtSynHip(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32, isTarget: bool) {
	var syCaP: f32;
	var syCaD: f32;
	PathParams_SynCa(pt, ctx, si, ri, di, &syCaP, &syCaD);
	var syn = syCaD; // synaptic activity co-product factor.
	SynapseTracesSet(syn, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	var tr = DWtParams_SynTrace(pt.Learn.DWt, SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr))), syn);
	SynapseTracesSet(tr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	var rLearnCaP = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnCaP))];
	var rLearnCaD = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(LearnCaD))];
	var err = f32(0);
	if (isTarget) {
		err = syCaP - syCaD; // for target layers, syn Ca drives error signal directly
	} else {
		err = tr * (rLearnCaP - rLearnCaD) * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72],
		u32(ri), u32(di), u32(ETraceLearn))];
	}
	var lwt = Synapses[Index2D(TensorStrides[170], TensorStrides[171], // linear weight
	u32(syni), u32(LWt))];
	if (err > 0) {
		err *= (1 - lwt);
	} else {
		err *= lwt;
	}
	var sNrnCap = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(LearnCaP))];
	var savg = 0.5 + pt.Hip.SAvgCor*(pt.Hip.SNominal-0.5);
	savg = 0.5 / max(pt.Hip.SAvgThr, savg); // keep this Sending Average Correction term within bounds (SAvgThr)
	var hebb = rLearnCaP * (sNrnCap*(savg-lwt) - (1-sNrnCap)*lwt);
	var dwt = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))] * pt.Learn.LRate.Eff * (pt.Hip.Hebb*hebb + pt.Hip.Err*err);
	SynapseTracesSet(dwt, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
}
fn PathParams_DWtSynBLA(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var ach = GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvACh), u32(di))];
	var dwt = f32(0);
	if (GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], // learn and reset
	u32(GvHasRew), u32(di))] > 0) {
		var ract = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaD))];
		if (ract < pt.Learn.DWt.LearnThr) {
			ract = f32(0);
		}
		var tr = SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
		var ustr = pt.BLA.USTrace;
		tr = ustr*Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(Burst))] + (1.0-ustr)*tr;
		var delta = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaP))] - Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72],
		u32(ri), u32(di), u32(CaDPrev))];
		if (delta < 0) {
			delta *= pt.BLA.NegDeltaLRate;
		}
		dwt = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))] * tr * delta * ract;
		SynapseTracesSet(0.0, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	} else if (ach > pt.BLA.AChThr) {
		var dtr = ach * Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(Burst))];
		SynapseTracesSet(dtr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
		var tr = DWtParams_SynTrace(pt.Learn.DWt, SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr))), dtr);
		SynapseTracesSet(tr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
	} else {
		SynapseTracesSet(0.0, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	}
	PathParams_DWtSynSoftBound(pt, ctx, syni, di, dwt);
}
fn PathParams_DWtSynRWPred(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var lda = GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvDA), u32(di))];
	var da = lda;
	var lr = pt.Learn.LRate.Eff;
	var eff_lr = lr;
	if (NeuronIxs[Index2D(TensorStrides[10], TensorStrides[11], u32(ri), u32(NrnNeurIndex))] == 0) {
		if (Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(Ge))] > Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // clipped at top, saturate up
		u32(ri), u32(di), u32(Act))] && da > 0) {
			da = f32(0);
		}
		if (Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(Ge))] < Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // clipped at bottom, saturate down
		u32(ri), u32(di), u32(Act))] && da < 0) {
			da = f32(0);
		}
		if (da < 0) {
			eff_lr *= pt.RLPred.OppSignLRate;
		}
	} else {
		eff_lr = -eff_lr; // negative case
		if (Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(Ge))] > Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // clipped at top, saturate up
		u32(ri), u32(di), u32(Act))] && da < 0) {
			da = f32(0);
		}
		if (Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(Ge))] < Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // clipped at bottom, saturate down
		u32(ri), u32(di), u32(Act))] && da > 0) {
			da = f32(0);
		}
		if (da >= 0) {
			eff_lr *= pt.RLPred.OppSignLRate;
		}
	}
	var dwt = da * Neurons[Index3D(TensorStrides[70], TensorStrides[71], // no recv unit activation
	TensorStrides[72], u32(si), u32(di), u32(CaP))];
	SynapseTracesSet(eff_lr * dwt, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
}
fn PathParams_DWtSynTDPred(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var lda = GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvDA), u32(di))];
	var da = lda;
	var lr = pt.Learn.LRate.Eff;
	var eff_lr = lr;
	var ni = NeuronIxs[Index2D(TensorStrides[10], TensorStrides[11], u32(ri), u32(NrnNeurIndex))];
	if (ni == 0) {
		if (da < 0) {
			eff_lr *= pt.RLPred.OppSignLRate;
		}
	} else {
		eff_lr = -eff_lr;
		if (da >= 0) {
			eff_lr *= pt.RLPred.OppSignLRate;
		}
	}
	var dwt = da * Neurons[Index3D(TensorStrides[70], TensorStrides[71], // no recv unit activation, prior trial act
	TensorStrides[72], u32(si), u32(di), u32(CaDPrev))];
	SynapseTracesSet(eff_lr * dwt, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
}
fn PathParams_DWtSynVSMatrix(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var hasRew = GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvHasRew), u32(di))] > 0;
	var ach = GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvACh), u32(di))];
	if (!hasRew && ach < 0.1) {
		SynapseTracesSet(0.0, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));return;
	}
	var rlr = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))];
	var rplus = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaP))];
	var rminus = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaD))];
	var sact = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(CaD))];
	var dtr = ach * (pt.VSMatrix.Delta * sact * (rplus - rminus));
	if (rminus > pt.Learn.DWt.LearnThr) { // key: prevents learning if < threshold
		dtr += ach * (pt.VSMatrix.Credit * sact * rminus);
	}
	var dwt = f32(0);
	if (hasRew) {
		var tr = SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
		if (pt.VSMatrix.RewActLearn == 1) {
			tr += (1 - GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], u32(GvGoalMaint), u32(di))]) * dtr;
		}
		dtr = f32(0);
		dwt = rlr * pt.Learn.LRate.Eff * tr;
	} else {
		dtr *= rlr;
	}
	SynapseTracesSet(dwt, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
	SynapseTracesSet(dtr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	SynapseTracesSetAdd(dtr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
}
fn PathParams_DWtSynDSMatrix(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var rlr = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))];
	var dwt = f32(0);
	var dtr = f32(0);
	if (GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], // US time -- use DA and current recv activity
	u32(GvHasRew), u32(di))] > 0) {
		var tr = SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
		dwt = rlr * pt.Learn.LRate.Eff * tr;
	} else {
		var pfmod = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // syn value is always better
		TensorStrides[72], u32(ri), u32(di), u32(GModSyn))];
		var patchDAD1 = Pools[Index3D(TensorStrides[130], TensorStrides[131], TensorStrides[132], u32(pi), u32(di), u32(DAD1))];
		var patchDAD2 = pt.DSMatrix.D2Scale * Pools[Index3D(TensorStrides[130], TensorStrides[131], TensorStrides[132], u32(pi), u32(di), u32(DAD2))];
		var rplus = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaP))];
		var rminus = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaD))];
		var sact = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(si), u32(di), u32(CaD))];
		dtr = rlr * (pt.DSMatrix.Delta * sact * (rplus - rminus)); // always delta
		if (rminus > pt.Learn.DWt.LearnThr) {                      // key: prevents learning if < threshold
			var act = pt.DSMatrix.Credit * rlr * sact * rminus; // rlr is sig deriv -- todo: CaSyn??
			dtr += (1.0 - pt.DSMatrix.PatchDA) * pfmod * act;   // std credit
			if (pfmod > pt.Learn.DWt.LearnThr) {                // we were active in output
				dtr += pfmod * pt.DSMatrix.PatchDA * ((1.0 - patchDAD1) + patchDAD2) * act;
			} else { // not active; we have no role in the outcome
				dtr += pt.DSMatrix.OffTrace * pt.DSMatrix.PatchDA * (patchDAD2 - patchDAD1) * act;
			}
		}
	}
	SynapseTracesSet(dwt, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
	SynapseTracesSet(dtr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	SynapseTracesSetAdd(dtr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
}
fn PathParams_DWtSynVSPatch(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var ract = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // t-1
	TensorStrides[72], u32(ri), u32(di), u32(CaDPrev))];
	if (ract < pt.Learn.DWt.LearnThr) {
		ract = f32(0);
	}
	var sact = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // t-1
	TensorStrides[72], u32(si), u32(di), u32(CaDPrev))];
	var dwt = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))] * pt.Learn.LRate.Eff * sact * ract;
	SynapseTracesSet(dwt, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
}
fn PathParams_DWtSynDSPatch(pt: PathParams, ctx: Context, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var ract = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(CaD))];
	if (ract < pt.Learn.DWt.LearnThr) {
		ract = f32(0);
	}
	var rlr = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], u32(ri), u32(di), u32(RLRate))];
	var dwt = f32(0);
	var dtr = f32(0);
	if (GlobalScalars[Index2D(TensorStrides[100], TensorStrides[101], // US time -- use DA * tr
	u32(GvHasRew), u32(di))] > 0) {
		var tr = SynapseTracesGet(Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(Tr)));
		dwt = rlr * pt.Learn.LRate.Eff * tr;
	} else {
		var pfmod = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // so much better! todo: why!?
		TensorStrides[72], u32(ri), u32(di), u32(GModSyn))];
		var sact = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // todo: use CaSyn instead of sact * ract? But BG is transient, so no?
		TensorStrides[72], u32(si), u32(di), u32(CaD))];
		dtr = pfmod * rlr * sact * ract; // rlr is just sig deriv
	}
	SynapseTracesSet(dwt, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DiDWt)));
	SynapseTracesSet(dtr, Index3D(TensorStrides[180], TensorStrides[181], TensorStrides[182], u32(syni), u32(di), u32(DTr)));
	SynapseTracesSetAdd(dtr, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182], u32(syni), u32(di), u32(Tr)));
}
fn PathParams_DWtSynCNeUp(pt: PathParams, ctx: Context, rlay: LayerParams, syni: u32,si: u32,ri: u32,lpi: u32,pi: u32,di: u32) {
	var sact = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // sending activity
	u32(si), u32(di), u32(CaD))];
	var ract = Neurons[Index3D(TensorStrides[70], TensorStrides[71], TensorStrides[72], // receiving activity
	u32(ri), u32(di), u32(CaD))];
	var predSenseAct = Neurons[Index3D(TensorStrides[70], TensorStrides[71], // CNiPred * Sense input activity, in PlusPhaseNeuron
	TensorStrides[72], u32(ri), u32(di), u32(RLRate))];
	var dwt = -predSenseAct * sact * (rlay.CNeUp.ActTarg - ract); // minus sign due to inhibitory
	SynapseTracesSet(pt.Learn.LRate.Eff * dwt, Index3D(TensorStrides[180], TensorStrides[181],
	TensorStrides[182],
	u32(syni), u32(di), u32(DiDWt)));
}

//////// import: "learn.go"
struct LearnCaParams {
	Norm: f32,
	SpikeVGCC: i32,
	SpikeVgccCa: f32,
	VgccTau: f32,
	ETraceTau: f32,
	ETraceScale: f32,
	pad: f32,
	pad1: f32,
	Dt: CaDtParams,
	VgccDt: f32,
	ETraceDt: f32,
	NormInv: f32,
	pad2: f32,
}
struct LearnTimingParams {
	On: i32,
	TrialEnd: i32,
	Threshold: f32,
	Sustain: i32,
	Learn: i32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
struct TrgAvgActParams {
	GiBaseInit: f32,
	RescaleOn: i32,
	ErrLRate: f32,
	SynScaleRate: f32,
	SubMean: f32,
	Permute: i32,
	Pool: i32,
	pad: i32,
	TrgRange: F32,
}
struct RLRateParams {
	On: i32,
	SigmoidLinear: i32,
	SigmoidMin: f32,
	Diff: i32,
	SpikeThr: f32,
	DiffThr: f32,
	Min: f32,
	pad: i32,
}
struct LearnNeuronParams {
	CaLearn: LearnCaParams,
	Timing: LearnTimingParams,
	CaSpike: CaSpikeParams,
	LearnNMDA: NMDAParams,
	TrgAvgAct: TrgAvgActParams,
	RLRate: RLRateParams,
	NeuroMod: NeuroModParams,
}
struct SWtInitParams {
	SPct: f32,
	Mean: f32,
	Var: f32,
	Sym: i32,
}
struct SWtAdaptParams {
	On: i32,
	LRate: f32,
	SubMean: f32,
	HiMeanDecay: f32,
	HiMeanThr: f32,
	SigGain: f32,
	pad: f32,
	pad1: f32,
}
struct SWtParams {
	Init: SWtInitParams,
	Adapt: SWtAdaptParams,
	Limit: F32,
}
struct LRateParams {
	Base: f32,
	Sched: f32,
	Mod: f32,
	Eff: f32,
}
struct DWtParams {
	SynCa20: i32,
	CaPScale: f32,
	SubMean: f32,
	SynTraceTau: f32,
	LearnThr: f32,
	SynTraceDt: f32,
	pad: f32,
	pad1: f32,
}
fn DWtParams_SynTrace(tp: DWtParams, tr: f32, syn: f32) -> f32 {
	return tr + tp.SynTraceDt*(syn-tr);
}
struct HebbParams {
	On: i32,
	Up: f32,
	Down: f32,
	pad: f32,
}
struct LearnSynParams {
	Learn: i32,
	pad: i32,
	pad1: i32,
	pad2: i32,
	LRate: LRateParams,
	DWt: DWtParams,
	Hebb: HebbParams,
}

//////// import: "looper.go"
alias ViewTimes = i32; //enums:enum
const  Cycle: ViewTimes = 0;
const  FastSpike: ViewTimes = 1;
const  Gamma: ViewTimes = 2;
const  Beta: ViewTimes = 3;
const  Alpha: ViewTimes = 4;
const  Phase: ViewTimes = 5;
const  Theta: ViewTimes = 6;

//////// import: "math32-fastexp.go"

//////// import: "minmax-avgmax.go"
const  MaxFloat32: f32 = 3.402823466e+38;
const  MinFloat32: f32 = 1.175494351e-38;
struct AvgMax32 {
	Avg: f32,
	Max: f32,
	Sum: f32,
	MaxIndex: i32,
	N: i32,
	pad: i32,
	pad1: i32,
	pad2: i32,
}

//////// import: "minmax-minmax32.go"
struct F32 {
	Min: f32,
	Max: f32,
	pad: i32,
	pad1: i32, // for gpu use
}

//////// import: "network.go"
struct NetworkIndexes {
	MaxData: u32,
	MaxDelay: u32,
	NCaBins: i32,
	NLayers: u32,
	NNeurons: u32,
	NPools: u32,
	NPaths: u32,
	NSyns: u32,
	RubiconNPosUSs: u32,
	RubiconNCosts: u32,
	RubiconNNegUSs: u32,
	pad: u32,
}

//////// import: "neuromod.go"
alias DAModTypes = i32; //enums:enum
const  NoDAMod: DAModTypes = 0;
const  D1Mod: DAModTypes = 1;
const  D2Mod: DAModTypes = 2;
const  D1AbsMod: DAModTypes = 3;
alias ValenceTypes = i32; //enums:enum
const  Positive: ValenceTypes = 0;
const  Negative: ValenceTypes = 1;
const  Cost: ValenceTypes = 2;
struct NeuroModParams {
	DAMod: DAModTypes,
	Valence: ValenceTypes,
	DAModGain: f32,
	DALRateSign: i32,
	DALRateMod: f32,
	AChLRateMod: f32,
	AChDisInhib: f32,
	BurstGain: f32,
	DipGain: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}

//////// import: "neuron.go"
alias NeuronFlags = i32; //enums:enum
const  NeuronOff: NeuronFlags = 1;
const  NeuronHasExt: NeuronFlags = 2;
const  NeuronHasTarg: NeuronFlags = 4;
const  NeuronHasCmpr: NeuronFlags = 8;
alias NeuronVars = i32; //enums:enum
const  Spike: NeuronVars = 0;
const  Spiked: NeuronVars = 1;
const  Act: NeuronVars = 2;
const  ActInt: NeuronVars = 3;
const  Ge: NeuronVars = 4;
const  Gi: NeuronVars = 5;
const  Gk: NeuronVars = 6;
const  Inet: NeuronVars = 7;
const  Vm: NeuronVars = 8;
const  VmDend: NeuronVars = 9;
const  ISI: NeuronVars = 10;
const  ISIAvg: NeuronVars = 11;
const  Ext: NeuronVars = 12;
const  Target: NeuronVars = 13;
const  CaM: NeuronVars = 14;
const  CaP: NeuronVars = 15;
const  CaD: NeuronVars = 16;
const  CaDPrev: NeuronVars = 17;
const  CaSyn: NeuronVars = 18;
const  LearnCa: NeuronVars = 19;
const  LearnCaM: NeuronVars = 20;
const  LearnCaP: NeuronVars = 21;
const  LearnCaD: NeuronVars = 22;
const  CaDiff: NeuronVars = 23;
const  LearnDiff: NeuronVars = 24;
const  LearnNow: NeuronVars = 25;
const  TimerCyc: NeuronVars = 26;
const  SustainCyc: NeuronVars = 27;
const  RLRate: NeuronVars = 28;
const  ETrace: NeuronVars = 29;
const  ETraceLearn: NeuronVars = 30;
const  GnmdaSyn: NeuronVars = 31;
const  Gnmda: NeuronVars = 32;
const  GnmdaLrn: NeuronVars = 33;
const  GnmdaMaint: NeuronVars = 34;
const  NmdaCa: NeuronVars = 35;
const  Gvgcc: NeuronVars = 36;
const  VgccM: NeuronVars = 37;
const  VgccH: NeuronVars = 38;
const  VgccCa: NeuronVars = 39;
const  VgccCaInt: NeuronVars = 40;
const  Burst: NeuronVars = 41;
const  BurstPrv: NeuronVars = 42;
const  CtxtGe: NeuronVars = 43;
const  CtxtGeRaw: NeuronVars = 44;
const  CtxtGeOrig: NeuronVars = 45;
const  GgabaB: NeuronVars = 46;
const  GababM: NeuronVars = 47;
const  GababX: NeuronVars = 48;
const  Gak: NeuronVars = 49;
const  SSGiDend: NeuronVars = 50;
const  GknaMed: NeuronVars = 51;
const  GknaSlow: NeuronVars = 52;
const  Gkir: NeuronVars = 53;
const  KirM: NeuronVars = 54;
const  Gsk: NeuronVars = 55;
const  SKCaIn: NeuronVars = 56;
const  SKCaR: NeuronVars = 57;
const  SKCaM: NeuronVars = 58;
const  Gmahp: NeuronVars = 59;
const  MahpN: NeuronVars = 60;
const  Gsahp: NeuronVars = 61;
const  SahpCa: NeuronVars = 62;
const  SahpN: NeuronVars = 63;
const  ActM: NeuronVars = 64;
const  ActP: NeuronVars = 65;
const  Beta1: NeuronVars = 66;
const  Beta2: NeuronVars = 67;
const  CaPMax: NeuronVars = 68;
const  CaPMaxCa: NeuronVars = 69;
const  GeNoise: NeuronVars = 70;
const  GeNoiseP: NeuronVars = 71;
const  GiNoise: NeuronVars = 72;
const  GiNoiseP: NeuronVars = 73;
const  GeExt: NeuronVars = 74;
const  GeRaw: NeuronVars = 75;
const  GeSyn: NeuronVars = 76;
const  GiRaw: NeuronVars = 77;
const  GiSyn: NeuronVars = 78;
const  GeInt: NeuronVars = 79;
const  GeIntNorm: NeuronVars = 80;
const  GiInt: NeuronVars = 81;
const  GModRaw: NeuronVars = 82;
const  GModSyn: NeuronVars = 83;
const  SMaintP: NeuronVars = 84;
const  GMaintRaw: NeuronVars = 85;
const  GMaintSyn: NeuronVars = 86;
const  NeurFlags: NeuronVars = 87;
const  CaBins: NeuronVars = 88;
alias NeuronAvgVars = i32; //enums:enum
const  ActAvg: NeuronAvgVars = 0;
const  AvgPct: NeuronAvgVars = 1;
const  TrgAvg: NeuronAvgVars = 2;
const  DTrgAvg: NeuronAvgVars = 3;
const  AvgDif: NeuronAvgVars = 4;
const  GeBase: NeuronAvgVars = 5;
const  GiBase: NeuronAvgVars = 6;
alias NeuronIndexVars = i32; //enums:enum
const  NrnNeurIndex: NeuronIndexVars = 0;
const  NrnLayIndex: NeuronIndexVars = 1;
const  NrnSubPool: NeuronIndexVars = 2;

//////// import: "pathparams.go"
const  StartOff: i32 = 0;
const  Nitems: i32 = 1;
const  StartNN: i32 = 2;
struct StartN {
	Start: u32,
	N: u32,
	pad: u32,
	pad1: u32, // todo: see if we can do without these?
}
struct PathIndexes {
	RecvLayer: u32,
	RecvNeurSt: u32,
	RecvNeurN: u32,
	SendLayer: u32,
	SendNeurSt: u32,
	SendNeurN: u32,
	SynapseSt: u32,
	SendConSt: u32,
	RecvConSt: u32,
	RecvSynSt: u32,
	NPathNeurSt: u32,
	pad: u32,
}
struct GScaleValues {
	Scale: f32,
	Rel: f32,
	pad: f32,
	pad1: f32,
}
struct PathParams {
	Type: PathTypes,
	Index: u32,
	pad: i32,
	pad1: i32,
	Indexes: PathIndexes,
	Com: SynComParams,
	PathScale: PathScaleParams,
	SWts: SWtParams,
	Learn: LearnSynParams,
	GScale: GScaleValues,
	RLPred: RLPredPathParams,
	VSMatrix: VSMatrixPathParams,
	DSMatrix: DSMatrixPathParams,
	BLA: BLAPathParams,
	Hip: HipPathParams,
}

//////// import: "pathtypes.go"
alias PathTypes = i32; //enums:enum
const  ForwardPath: PathTypes = 0;
const  BackPath: PathTypes = 1;
const  LateralPath: PathTypes = 2;
const  InhibPath: PathTypes = 3;
const  CTCtxtPath: PathTypes = 4;
const  DSPatchPath: PathTypes = 5;
const  VSPatchPath: PathTypes = 6;
const  VSMatrixPath: PathTypes = 7;
const  DSMatrixPath: PathTypes = 8;
const  CNiPredToOutPath: PathTypes = 9;
const  RWPath: PathTypes = 10;
const  TDPredPath: PathTypes = 11;
const  BLAPath: PathTypes = 12;
const  HipPath: PathTypes = 13;

//////// import: "pcore-layer.go"
struct DSMatrixParams {
	PatchD1Range: F32,
	PatchD2Range: F32,
	PatchDAModGain: f32,
	PatchBurstGain: f32,
	PatchD1Index: i32,
	PatchD2Index: i32,
}
struct StriatumParams {
	GateThr: f32,
	OtherIndex: i32,
	PFIndex: i32,
	ThalLay1Index: i32,
	ThalLay2Index: i32,
	ThalLay3Index: i32,
	ThalLay4Index: i32,
	ThalLay5Index: i32,
	ThalLay6Index: i32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
alias GPLayerTypes = i32; //enums:enum
const  GPePr: GPLayerTypes = 0;
const  GPeAk: GPLayerTypes = 1;
const  GPi: GPLayerTypes = 2;
struct GPParams {
	GPType: GPLayerTypes,
	pad: u32,
	pad1: u32,
	pad2: u32,
}

//////// import: "pcore-path.go"
struct DSMatrixPathParams {
	PatchDA: f32,
	Credit: f32,
	Delta: f32,
	D2Scale: f32,
	OffTrace: f32,
	pad: f32,
	pad1: f32,
	pad2: f32,
}
struct VSMatrixPathParams {
	RewActLearn: i32,
	Delta: f32,
	Credit: f32,
	pad: f32,
}

//////// import: "pool.go"
alias PoolIndexVars = i32; //enums:enum
const  PoolNeurSt: PoolIndexVars = 0;
const  PoolNeurEd: PoolIndexVars = 1;
const  PoolLayerIdx: PoolIndexVars = 2;
const  PoolIsLayer: PoolIndexVars = 3;
alias PoolIntVars = i32; //enums:enum
const  Clamped: PoolIntVars = 0;
const  PoolGated: PoolIntVars = 1;
const  FFsRawInt: PoolIntVars = 2;
const  FBsRawInt: PoolIntVars = 3;
const  GeExtRawInt: PoolIntVars = 4;
const  PoolIntAvgMaxStart: PoolIntVars = 5;
alias AvgMax = i32; //enums:enum
const  Avg: AvgMax = 0;
const  Max: AvgMax = 1;
alias AvgMaxPhases = i32; //enums:enum -trim-prefix AM
const  AMCycle: AvgMaxPhases = 0;
const  AMMinus: AvgMaxPhases = 1;
const  AMPlus: AvgMaxPhases = 2;
const  AMPrev: AvgMaxPhases = 3;
alias AvgMaxVars = i32; //enums:enum -trim-prefix AM
const  AMCaP: AvgMaxVars = 0;
const  AMCaD: AvgMaxVars = 1;
const  AMCaPMax: AvgMaxVars = 2;
const  AMAct: AvgMaxVars = 3;
const  AMGeInt: AvgMaxVars = 4;
const  AMGiInt: AvgMaxVars = 5;
const  AMAvgDif: AvgMaxVars = 6;
const  poolFloatAvgMaxStart = InhibVarsN;
const  PoolVarsTotal = poolFloatAvgMaxStart + InhibVars(i32(AvgMaxVarsN)*i32(AvgMaxN)*i32(AvgMaxPhasesN));
const  PoolIntVarsTot = PoolIntAvgMaxStart + PoolIntVars(i32(AvgMaxVarsN)*i32(AvgMaxN));
const avgMaxToNeuron = array(CaP, CaD, CaPMax, Act, GeInt, GiInt);

//////// import: "rand.go"
alias RandFunIndex = u32;
const  RandFunActPGe: RandFunIndex = 0;
const  RandFunActPGi: RandFunIndex = 1;
const  RandFunActSMaintP: RandFunIndex = 2;
const  RandFunIndexN: RandFunIndex = 3;

//////// import: "rl-layer.go"
struct RWPredParams {
	PredRange: F32,
}
struct RWDaParams {
	TonicGe: f32,
	RWPredLayIndex: i32,
	pad: u32,
	pad1: u32,
}
struct TDIntegParams {
	Discount: f32,
	PredGain: f32,
	TDPredLayIndex: i32,
	pad: u32,
}
struct TDDaParams {
	TonicGe: f32,
	TDIntegLayIndex: i32,
	pad: u32,
	pad1: u32,
}

//////// import: "rl-path.go"
struct RLPredPathParams {
	OppSignLRate: f32,
	DaTol: f32,
	pad: f32,
	pad1: f32,
}

//////// import: "rubicon-layer.go"
struct LDTParams {
	SrcThr: f32,
	Rew: i32,
	MaintInhib: f32,
	SrcLay1Index: i32,
	SrcLay2Index: i32,
	SrcLay3Index: i32,
	SrcLay4Index: i32,
	pad: f32,
}
struct VTAParams {
	CeMGain: f32,
	LHbGain: f32,
	AChThr: f32,
	pad: f32,
}

//////// import: "rubicon-path.go"
struct BLAPathParams {
	NegDeltaLRate: f32,
	AChThr: f32,
	USTrace: f32,
	pad: f32,
}

//////// import: "rubicon.go"

//////// import: "stats.go"

//////// import: "synapse.go"
alias SynapseVars = i32; //enums:enum
const  Wt: SynapseVars = 0;
const  LWt: SynapseVars = 1;
const  SWt: SynapseVars = 2;
const  DWt: SynapseVars = 3;
const  DSWt: SynapseVars = 4;
alias SynapseTraceVars = i32; //enums:enum
const  Tr: SynapseTraceVars = 0;
const  DTr: SynapseTraceVars = 1;
const  DiDWt: SynapseTraceVars = 2;
alias SynapseIndexVars = i32; //enums:enum
const  SynRecvIndex: SynapseIndexVars = 0;
const  SynSendIndex: SynapseIndexVars = 1;
const  SynPathIndex: SynapseIndexVars = 2;

//////// import: "slrand.wgsl"
fn Philox2x32round(counter: su64, key: u32) -> su64 {
	let mul = Uint32Mul64(u32(0xD256D193), counter.x);
	var ctr: su64;
	ctr.x = mul.y ^ key ^ counter.y;
	ctr.y = mul.x;
	return ctr;
}
fn Philox2x32bumpkey(key: u32) -> u32 {
	return key + u32(0x9E3779B9);
}
fn Philox2x32(counter: su64, key: u32) -> vec2<u32> {
	var ctr = Philox2x32round(counter, key); // 1
	var ky = Philox2x32bumpkey(key);
	ctr = Philox2x32round(ctr, ky); // 2
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 3
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 4
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 5
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 6
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 7
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 8
	ky = Philox2x32bumpkey(ky);
	ctr = Philox2x32round(ctr, ky); // 9
	ky = Philox2x32bumpkey(ky);
	return Philox2x32round(ctr, ky); // 10
}
fn RandUint32Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<u32> {
	return Philox2x32(Uint64Add32(counter, funcIndex), key);
}
fn RandUint32(counter: su64, funcIndex: u32, key: u32) -> u32 {
	return Philox2x32(Uint64Add32(counter, funcIndex), key).x;
}
fn RandFloat32Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> {
	return Uint32ToFloat32Vec2(RandUint32Vec2(counter, funcIndex, key));
}
fn RandFloat32(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return Uint32ToFloat32(RandUint32(counter, funcIndex, key));
}
fn RandFloat32Range11Vec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> {
	return Uint32ToFloat32Vec2(RandUint32Vec2(counter, funcIndex, key));
}
fn RandFloat32Range11(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return Uint32ToFloat32Range11(RandUint32(counter, funcIndex, key));
}
fn RandBoolP(counter: su64, funcIndex: u32, key: u32, p: f32) -> bool { 
	return (RandFloat32(counter, funcIndex, key) < p);
}
fn sincospi(x: f32) -> vec2<f32> {
	let PIf = 3.1415926535897932;
	var r: vec2<f32>;
	r.x = cos(PIf*x);
	r.y = sin(PIf*x);
	return r;
}
fn RandFloat32NormVec2(counter: su64, funcIndex: u32, key: u32) -> vec2<f32> { 
	let ur = RandUint32Vec2(counter, funcIndex, key);
	var f = sincospi(Uint32ToFloat32Range11(ur.x));
	let r = sqrt(-2.0 * log(Uint32ToFloat32(ur.y))); // guaranteed to avoid 0.
	return f * r;
}
fn RandFloat32Norm(counter: su64, funcIndex: u32, key: u32) -> f32 { 
	return RandFloat32Vec2(counter, funcIndex, key).x;
}
fn RandUint32N(counter: su64, funcIndex: u32, key: u32, n: u32) -> u32 { 
	let v = RandFloat32(counter, funcIndex, key);
	return u32(v * f32(n));
}
struct RandCounter {
	Counter: su64,
	HiSeed: u32,
	pad: u32,
}
fn RandCounter_Reset(ct: ptr<function,RandCounter>) {
	(*ct).Counter.x = u32(0);
	(*ct).Counter.y = (*ct).HiSeed;
}
fn RandCounter_Seed(ct: ptr<function,RandCounter>, seed: u32) {
	(*ct).HiSeed = seed;
	RandCounter_Reset(ct);
}
fn RandCounter_Add(ct: ptr<function,RandCounter>, inc: u32) {
	(*ct).Counter = Uint64Add32((*ct).Counter, inc);
}

//////// import: "sltype.wgsl"
alias su64 = vec2<u32>;
fn Uint32Mul64(a: u32, b: u32) -> su64 {
	let LOMASK = (((u32(1))<<16)-1);
	var r: su64;
	r.x = a * b;               /* full low multiply */
	let ahi = a >> 16;
	let alo = a & LOMASK;
	let bhi = b >> 16;
	let blo = b & LOMASK;
	let ahbl = ahi * blo;
	let albh = alo * bhi;
	let ahbl_albh = ((ahbl&LOMASK) + (albh&LOMASK));
	var hit = ahi*bhi + (ahbl>>16) +  (albh>>16);
	hit += ahbl_albh >> 16; /* carry from the sum of lo(ahbl) + lo(albh) ) */
	/* carry from the sum with alo*blo */
	if ((r.x >> u32(16)) < (ahbl_albh&LOMASK)) {
		hit += u32(1);
	}
	r.y = hit; 
	return r;
}
/*
fn Uint32Mul64(a: u32, b: u32) -> su64 {
	return su64(a) * su64(b);
}
*/
fn Uint64Add32(a: su64, b: u32) -> su64 {
	if (b == 0) {
		return a;
	}
	var s = a;
	if (s.x > u32(0xffffffff) - b) {
		s.y++;
		s.x = (b - 1) - (u32(0xffffffff) - s.x);
	} else {
		s.x += b;
	}
	return s;
}
fn Uint64Incr(a: su64) -> su64 {
	var s = a;
	if(s.x == 0xffffffff) {
		s.y++;
		s.x = u32(0);
	} else {
		s.x++;
	}
	return s;
}
fn Uint32ToFloat32(val: u32) -> f32 {
	let factor = f32(1.0) / (f32(u32(0xffffffff)) + f32(1.0));
	let halffactor = f32(0.5) * factor;
	var f = f32(val) * factor + halffactor;
	if (f == 1.0) { // exclude 1
		return bitcast<f32>(0x3F7FFFFF);
	}
	return f;
}
fn Uint32ToFloat32Vec2(val: vec2<u32>) -> vec2<f32> {
	var r: vec2<f32>;
	r.x = Uint32ToFloat32(val.x);
	r.y = Uint32ToFloat32(val.y);
	return r;
}
fn Uint32ToFloat32Range11(val: u32) -> f32 {
	let factor = f32(1.0) / (f32(i32(0x7fffffff)) + f32(1.0));
	let halffactor = f32(0.5) * factor;
	return (f32(val) * factor + halffactor);
}
fn Uint32ToFloat32Range11Vec2(val: vec2<u32>) -> vec2<f32> {
	var r: vec2<f32>;
	r.x = Uint32ToFloat32Range11(val.x);
	r.y = Uint32ToFloat32Range11(val.y);
	return r;
}