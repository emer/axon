// Copyright (c) 2019, The Emergent Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package axon

import (
	"cogentcore.org/core/tensor"
	"github.com/emer/emergent/v2/etime"
	"github.com/emer/emergent/v2/paths"
)


//	Primary Algorithmic interface.
//
// The following methods constitute the primary user-called API during Alpha Cycle
// to compute one complete algorithmic alpha cycle update.

// GlobalsReset resets all global values to 0, for all NData
func GlobalsReset() {
	nix := GetNetworkIxs(0)
	for di := uint32(0); di < nix.MaxData; di++ {
		for vg := GvRew; vg < GlobalScalarVarsN; vg++ {
			GlobalScalars[vg, di] = 0
		}
		for vn := GvCost; vn < GlobalVectorVarsN; vn++ {
			for ui := uint32(0); ui < MaxGlobalVecN; ui++ {
				GlobalVectors[vn, ui, di] = 0
			}
		}
	}
}

// NewState handles all initialization at start of new input pattern.
// This is called *before* applying external input data and operates across
// all data parallel values.  The current Context.NData should be set
// properly prior to calling this and subsequent Cycle methods.
func (nt *Network) NewState(mode etime.Modes) {
	// if nt.GPU.On { // todo: this has a bug in neuron-level access in updating SpkPrv
	// 	nt.GPU.RunNewState()
	// 	return
	// }
	ctx := nt.Context()
	ctx.NewState(mode)
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.NewState(ctx)
	}
	// if nt.GPU.On {
	// 	nt.GPU.SyncStateGBufToGPU()
	// }
}

// Cycle runs one cycle of activation updating using threading methods.
func (nt *Network) Cycle() {
	// todo: chunks of 10 cycles
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	ld := int(nix.NLayers * ctx.NData)
	pd := int(nix.NPools * ctx.NData)
	RunGatherSpikes(nd)
	RunLayerGi(ld)
	RunBetweenGi(ld)
	RunPoolGi(pd)
	RunCycleNeuron(nd)
	RunSendSpike(nd)
	RunCyclePost(ld)
	RunCycleInc(1)

	// todo: fix this:
	// var ldt, vta *Layer
	// for _, ly := range nt.Layers {
	// 	if ly.Type == VTALayer {
	// 		vta = ly
	// 	} else if ly.Type == LDTLayer {
	// 		ldt = ly
	// 	} else {
	// 		ly.CyclePost(ctx)
	// 	}
	// }
	// // ordering of these is important
	// if ldt != nil {
	// 	ldt.CyclePost(ctx)
	// }
	// if vta != nil {
	// 	vta.CyclePost(ctx)
	// }
}

// InitExt initializes external input state.
// Call prior to applying external inputs to layers.
func (nt *Network) InitExt() {
	// note: important to do this for GPU
	// to ensure partial inputs work the same way on CPU and GPU.
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitExt()
	}
}

// ApplyExts applies external inputs to layers, based on values
// that were set in prior layer-specific ApplyExt calls.
// This does nothing on the CPU, but is critical for the GPU,
// and should be added to all sims where GPU will be used.
func (nt *Network) ApplyExts() {
	if !UseGPU {
		return
	}
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunApplyExtsNeuron(nd)
}

// MinusPhase does updating after end of minus phase.
func (nt *Network) MinusPhase() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	pd := int(nix.NPools * ctx.NData)
	RunMinusPhasePool(pd)
	RunMinusPhaseNeuron(nd)
	nt.MinusPhasePost()
	// todo:
	// nt.GPU.SyncStateToGPU()
}

// MinusPhasePost does special CPU post processing.
func (nt *Network) MinusPhasePost() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.MinusPhasePost(ctx)
	}
}

// PlusPhaseStart does updating at the start of the plus phase:
// applies Target inputs as External inputs.
func (nt *Network) PlusPhaseStart() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	RunPlusPhaseStartNeuron(nd)
}

// PlusPhase does updating after end of plus phase
func (nt *Network) PlusPhase() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	nd := int(nix.NNeurons * ctx.NData)
	pd := int(nix.NPools * ctx.NData)
	RunPlusPhasePool(pd)
	RunPlusPhaseNeuron(nd)
	nt.PlusPhasePost()
	// todo:
	// nt.GPU.SyncStateToGPU()
}

// PlusPhasePost happens on the CPU always.
func (nt *Network) PlusPhasePost() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.PlusPhasePost(ctx)
	}
}

// TargToExt sets external input Ext from target values Target
// This is done at end of MinusPhase to allow targets to drive activity in plus phase.
// This can be called separately to simulate alpha cycles within theta cycles, for example.
func (nt *Network) TargToExt() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.TargToExt(ctx)
	}
}

// ClearTargExt clears external inputs Ext that were set from target values Target.
// This can be called to simulate alpha cycles within theta cycles, for example.
func (nt *Network) ClearTargExt() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.ClearTargExt(ctx)
	}
}

// SpkSt1 saves current acts into SpkSt1 (using CaSpkP)
func (nt *Network) SpkSt1() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.SpkSt1(ctx)
	}
}

// SpkSt2 saves current acts into SpkSt2 (using CaSpkP)
func (nt *Network) SpkSt2() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.SpkSt2(ctx)
	}
}

////////  Learn methods

// DWt computes the weight change (learning) based on current running-average activation values
func (nt *Network) DWt() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	sd := int(nix.NSyns * ctx.NData)
	RunDWtSyn(sd)
	RunDWtFromDiSyn(int(nix.NSyns))
}

// WtFromDWt updates the weights from delta-weight changes.
// Also does ctx.SlowInc() and calls SlowAdapt at SlowInterval
func (nt *Network) WtFromDWt() {
	nix := nt.NetIxs()
	ctx := nt.Context()
	RunDWtSubMeanPath(int(nix.NPaths))
	RunWtFromDWtSyn(int(nix.NSyns))
	if ctx.SlowInc() {
		nt.SlowAdapt()
	}
}

// SlowAdapt is the layer-level slow adaptation functions: Synaptic scaling,
// and adapting inhibition
func (nt *Network) SlowAdapt() {
	// note: for now doing all this slow stuff CPU-side
	// These Sync calls always check if GPU is On
	// nt.GPU.SyncAllFromGPU() // todo:

	// todo: convert this to GPU mode
	
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.SlowAdapt(ctx)
	}
	for _, pt := range nt.Paths {
		pt.SlowAdapt(ctx)
	}
	// nt.LayerMapSeq(func(ly *Layer) { ly.SlowAdapt(ctx) }, "SlowAdapt")
	// nt.PathMapSeq(func(pj *Path) { pj.SlowAdapt(ctx) }, "SlowAdapt")

	// nt.GPU.SyncAllToGPU()
	// nt.GPU.SyncSynCaToGPU() // was cleared
}


//gosl:start

//////// Kernels for all parallel CPU / GPU compute are here:

// GatherSpikes is the kernel over Neurons * Data for gathering
// spike inputs sent on the previous cycle.
func GatherSpikes(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].GatherSpikes(ctx, ni, di)
}

// LayerGi is the kernel over Layers * Data for updating Gi inhibition.
func LayerGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	li := ctx.ItemIndex(i)
	Layers[li].LayerGi(ctx, li, di)
}

// BetweenGi is the kernel over Layers * Data for updating Gi
// inhibition between layers.
func BetweenGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	li := ctx.ItemIndex(i)
	Layers[li].BetweenGi(ctx, di)
}

// PoolGi is the kernel over Pools * Data for updating Gi inhibition.
func PoolGi(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	pi := ctx.ItemIndex(i)
	PoolPoolGi(ctx, pi, di)
}

// CycleNeuron is the kernel over Neurons * Data to do
// one cycle (msec) of updating at the neuron level.
func CycleNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].CycleNeuron(ctx, ni, di)
}

// SendSpike is the kernel over Neurons * Data to
// send spike signal for neurons over threshold.
func SendSpike(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].SendSpike(ctx, ni, di)
}

// CyclePost is the kernel over Layers * Data to
// update state after each Cycle of updating.
func CyclePost(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	li := ctx.ItemIndex(i)
	Layers[li].CyclePost(ctx, di)
}

// CycleInc is the kernel over 1 call to increment the cycle counter.
func CycleInc(i uint32) { //gosl:kernel
	if i != 0 {
		return
	}
	ctx := GetCtx(0)
	ctx.CycleInc()
}

// ApplyExtsNeuron is the kernel over Neurons * Data to
// apply Ext external input to the neurons receiving inputs.
func ApplyExtsNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].ApplyExtsNeuron(ni, di)
}

// MinusPhasePool is the kernel over Pools * Data to
// do pool-level updating after end of minus phase.
func MinusPhasePool(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	pi := ctx.ItemIndex(i)
	li := PoolsInt[PoolLayerIdx, pi, di]
	Layers[li].MinusPhasePool(ctx, pi, di)
}

// MinusPhaseNeuron is the kernel over Neurons * Data to
// do neuron-level updating after end of minus phase.
func MinusPhaseNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].MinusPhaseNeuron(ctx, ni, di)
}

// PlusPhaseStartNeuron is the kernel over Neurons * Data to
// do neuron-level updating at start of plus phase.
func PlusPhaseStartNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].PlusPhaseStartNeuron(ctx, ni, di)
}

// PlusPhasePool is the kernel over Pools * Data to
// do pool-level updating after end of plus phase.
func PlusPhasePool(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	pi := ctx.ItemIndex(i)
	li := PoolsInt[PoolLayerIdx, pi, di]
	Layers[li].PlusPhasePool(ctx, pi, di)
}

// PlusPhaseNeuron is the kernel over Neurons * Data to
// do neuron-level updating after end of plus phase.
func PlusPhaseNeuron(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	ni := ctx.ItemIndex(i)
	li := NeuronIxs[NrnLayIndex, ni]
	Layers[li].PlusPhaseNeuron(ctx, ni, di)
}

// DWtSyn is the kernel over Synapses * Data to
// compute weight changes (learning).
func DWtSyn(i uint32) { //gosl:kernel
	ctx := GetCtx(0)
	di := ctx.DataIndex(i)
	syni := ctx.ItemIndex(i)
	pti := SynapseIxs[SynPathIndex, syni]
	si := SynapseIxs[SynSendIndex, syni]
	ri := SynapseIxs[SynRecvIndex, syni]
	Paths[pti].DWtSyn(ctx, &Layers[Paths[pti].Indexes.RecvLayer], syni, si, ri, di)
}

// DWtFromDiSyn is the kernel over Synapses (not * Data) to
// integrate DWt over Di data parallel values.
func DWtFromDiSyn(syni uint32) { //gosl:kernel
	ctx := GetCtx(0)
	pti := SynapseIxs[SynPathIndex, syni]
	Paths[pti].DWtFromDi(ctx, syni)
}

// DWtSubMeanPath is the kernel over Paths to 
// compute DWt - mean(DWt).
func DWtSubMeanPath(pti uint32) { //gosl:kernel
	ctx := GetCtx(0)
	Paths[pti].DWtSubMean(ctx, pti)
}

// WtFromDWtSyn is the kernel over Synapses (not * Data) to
// compute Wt from DWt weight changes.
func WtFromDWtSyn(syni uint32) { //gosl:kernel
	ctx := GetCtx(0)
	pti := SynapseIxs[SynPathIndex, syni]
	Paths[pti].WtFromDWtSyn(ctx, syni)
}

//gosl:end


////////  Init methods

// InitWeights initializes synaptic weights and all other associated long-term state variables
// including running-average state values (e.g., layer running average activations etc)
func (nt *Network) InitWeights() { //types:add
	ctx := nt.Context()
	for di := uint32(0); di < ctx.NData; di++ {
		nt.Rubicon.Reset(di)
	}
	nt.BuildPathGBuf()
	ctx.SlowCtr = 0
	ctx.SynCaCtr = 0
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitWeights(ctx, nt) // calls InitActs too
	}
	// separate pass to enforce symmetry
	// st := time.Now()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitWtSym(ctx)
	}
	// dur := time.Now().Sub(st)
	// fmt.Printf("sym: %v\n", dur)
	// nt.GPU.SyncAllToGPU()
	// nt.GPU.SyncSynCaToGPU() // only time we call this
	// nt.GPU.SyncGBufToGPU()
}

// InitTopoSWts initializes SWt structural weight parameters from
// path types that support topographic weight patterns, having flags set to support it,
// includes: paths.PoolTile paths.Circle.
// call before InitWeights if using Topo wts
func (nt *Network) InitTopoSWts() {
	ctx := nt.Context()
	swts := &tensor.Float32{}
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		for i := 0; i < ly.NumRecvPaths(); i++ {
			pj := ly.RecvPaths[i]
			if pj.Off {
				continue
			}
			pat := pj.Pattern
			switch pt := pat.(type) {
			case *paths.PoolTile:
				if !pt.HasTopoWeights() {
					continue
				}
				slay := pj.Send
				pt.TopoWeights(&slay.Shape, &ly.Shape, swts)
				pj.SetSWtsRPool(ctx, swts)
			case *paths.Circle:
				if !pt.TopoWeights {
					continue
				}
				pj.SetSWtsFunc(ctx, pt.GaussWts)
			}
		}
	}
}

// InitGScale computes the initial scaling factor for synaptic input conductances G,
// stored in GScale.Scale, based on sending layer initial activation.
func (nt *Network) InitGScale() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitGScale(ctx)
	}
}

// DecayState decays activation state by given proportion
// e.g., 1 = decay completely, and 0 = decay not at all.
// glong = separate decay factor for long-timescale conductances (g)
// This is called automatically in NewState, but is avail
// here for ad-hoc decay cases.
func (nt *Network) DecayState(decay, glong, ahp float32) {
	ctx := nt.Context()
	// todo: move to gpu
	// nt.GPU.SyncStateFromGPU() // note: because we have to sync back, we need to sync from first to be current
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		for di := uint32(0); di < ctx.NData; di++ {
			ly.DecayState(ctx, di, decay, glong, ahp)
		}
	}
	// nt.GPU.SyncStateToGPU()
}

// DecayStateByType decays activation state for given layer types
// by given proportion e.g., 1 = decay completely, and 0 = decay not at all.
// glong = separate decay factor for long-timescale conductances (g)
func (nt *Network) DecayStateByType(decay, glong, ahp float32, types ...LayerTypes) {
	nt.DecayStateLayers(decay, glong, ahp, nt.LayersByType(types...)...)
}

// DecayStateByClass decays activation state for given class name(s)
// by given proportion e.g., 1 = decay completely, and 0 = decay not at all.
// glong = separate decay factor for long-timescale conductances (g)
func (nt *Network) DecayStateByClass(decay, glong, ahp float32, classes ...string) {
	nt.DecayStateLayers(decay, glong, ahp, nt.LayersByClass(classes...)...)
}

// DecayStateLayers decays activation state for given layers
// by given proportion e.g., 1 = decay completely, and 0 = decay not at all.
// glong = separate decay factor for long-timescale conductances (g).
// If this is not being called at the start, around NewState call,
// then you should also call: nt.GPU.SyncGBufToGPU()
// to zero the GBuf values which otherwise will persist spikes in flight.
func (nt *Network) DecayStateLayers(decay, glong, ahp float32, layers ...string) {
	ctx := nt.Context()
	// todo: move to gpu
	// nt.GPU.SyncStateFromGPU() // note: because we have to sync back, we need to sync from first to be current
	for _, lynm := range layers {
		ly := nt.LayerByName(lynm)
		if ly.Off {
			continue
		}
		for di := uint32(0); di < ctx.NData; di++ {
			ly.DecayState(ctx, di, decay, glong, ahp)
		}
	}
	// nt.GPU.SyncStateToGPU()
}

// InitActs fully initializes activation state -- not automatically called
func (nt *Network) InitActs() { //types:add
	// todo: move to gpu
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.InitActs(ctx)
	}
	// nt.GPU.SyncStateToGPU() // todo:
	// nt.GPU.SyncGBufToGPU() // zeros everyone
}

// UpdateExtFlags updates the neuron flags for external input based on current
// layer Type field -- call this if the Type has changed since the last
// ApplyExt* method call.
func (nt *Network) UpdateExtFlags() {
	ctx := nt.Context()
	for _, ly := range nt.Layers {
		if ly.Off {
			continue
		}
		ly.UpdateExtFlags(ctx)
	}
}

// SynFail updates synaptic failure
func (nt *Network) SynFail() {
	// todo:
	// nt.PathMapSeq(func(pj *Path) { pj.SynFail(ctx) }, "SynFail")
}

// LRateMod sets the LRate modulation parameter for Paths, which is
// for dynamic modulation of learning rate (see also LRateSched).
// Updates the effective learning rate factor accordingly.
func (nt *Network) LRateMod(mod float32) {
	for _, ly := range nt.Layers {
		// if ly.Off { // keep all sync'd
		// 	continue
		// }
		ly.LRateMod(mod)
	}
}

// LRateSched sets the schedule-based learning rate multiplier.
// See also LRateMod.
// Updates the effective learning rate factor accordingly.
func (nt *Network) LRateSched(sched float32) {
	for _, ly := range nt.Layers {
		// if ly.Off { // keep all sync'd
		// 	continue
		// }
		ly.LRateSched(sched)
	}
}

// SetSubMean sets the SubMean parameters in all the layers in the network
// trgAvg is for Learn.TrgAvgAct.SubMean
// path is for the paths Learn.Trace.SubMean
// in both cases, it is generally best to have both parameters set to 0
// at the start of learning
func (nt *Network) SetSubMean(trgAvg, path float32) {
	for _, ly := range nt.Layers {
		// if ly.Off { // keep all sync'd
		// 	continue
		// }
		ly.SetSubMean(trgAvg, path)
	}
}

//////////////////////////////////////////////////////////////////////////////////////
//  Lesion methods

// LayersSetOff sets the Off flag for all layers to given setting
func (nt *Network) LayersSetOff(off bool) {
	for _, ly := range nt.Layers {
		ly.SetOff(off)
	}
}

// UnLesionNeurons unlesions neurons in all layers in the network.
// Provides a clean starting point for subsequent lesion experiments.
func (nt *Network) UnLesionNeurons() {
	for _, ly := range nt.Layers {
		// if ly.Off { // keep all sync'd
		// 	continue
		// }
		ly.UnLesionNeurons()
	}
}

////////  Methods used in MPI computation, which don't depend on MPI specifically

// CollectDWts writes all of the synaptic DWt values to given dwts slice
// which is pre-allocated to given nwts size if dwts is nil,
// in which case the method returns true so that the actual length of
// dwts can be passed next time around.
// Used for MPI sharing of weight changes across processors.
// This calls SyncSynapsesFromGPU() (nop if not GPU) first.
func (nt *Network) CollectDWts(dwts *[]float32) bool {
	// nt.GPU.SyncSynapsesFromGPU()
	idx := 0
	made := false
	if *dwts == nil {
		nwts := 0
		for _, ly := range nt.Layers {
			nwts += 5                // ActAvgValues
			nwts += int(ly.NNeurons) // ActAvg
			if ly.Params.IsLearnTrgAvg() {
				nwts += int(ly.NNeurons)
			}
			for _, pj := range ly.SendPaths {
				nwts += int(pj.NSyns) + 3 // Scale, AvgAvg, MaxAvg
			}
		}
		*dwts = make([]float32, nwts)
		made = true
	}
	for li, ly := range nt.Layers {
		nn := ly.NNeurons
		(*dwts)[idx+0] = LayerStates[LayerActMAvg, li, 0]
		(*dwts)[idx+1] = LayerStates[LayerActPAvg, li, 0]
		(*dwts)[idx+2] = LayerStates[LayerAvgMaxGeM, li, 0]
		(*dwts)[idx+3] = LayerStates[LayerAvgMaxGiM, li, 0]
		(*dwts)[idx+4] = LayerStates[LayerGiMult, li, 0]
		idx += 5
		for lni := uint32(0); lni < nn; lni++ {
			ni := ly.NeurStIndex + lni
			(*dwts)[idx+int(lni)] = NeuronAvgs[ActAvg, ni]
		}
		idx += int(nn)
		if ly.Params.IsLearnTrgAvg() {
			for lni := uint32(0); lni < nn; lni++ {
				ni := ly.NeurStIndex + lni
				(*dwts)[idx+int(lni)] = NeuronAvgs[DTrgAvg, ni]
			}
			idx += int(nn)
		}
		for _, pj := range ly.SendPaths {
			for lni := range pj.SendCon {
				scon := pj.SendCon[lni]
				for syi := scon.Start; syi < scon.Start+scon.N; syi++ {
					syni := pj.SynStIndex + syi
					(*dwts)[idx+int(syi)] = Synapses[DWt, syni]
					// if syni < 100 {
					// 	fmt.Printf("%d: %d = %g\n", syni, syi, (*dwts)[idx+int(syi)])
					// }
				}
			}
			idx += int(pj.NSyns)
		}
	}
	return made
}

// SetDWts sets the DWt weight changes from given array of floats, which must be correct size
// navg is the number of processors aggregated in these dwts -- some variables need to be
// averaged instead of summed (e.g., ActAvg)
// This calls SyncSynapsesToGPU() (nop if not GPU) after.
func (nt *Network) SetDWts(dwts []float32, navg int) {
	idx := 0
	davg := 1 / float32(navg)
	for li, ly := range nt.Layers {
		nn := ly.NNeurons
		LayerStates[LayerActMAvg, li, 0] = davg * dwts[idx+0]
		LayerStates[LayerActPAvg, li, 0] = davg * dwts[idx+1]
		LayerStates[LayerAvgMaxGeM, li, 0] = davg * dwts[idx+2]
		LayerStates[LayerAvgMaxGiM, li, 0] = davg * dwts[idx+3]
		LayerStates[LayerGiMult, li, 0] = davg * dwts[idx+4]
		idx += 5
		for lni := uint32(0); lni < nn; lni++ {
			ni := ly.NeurStIndex + lni
			NeuronAvgs[ActAvg, ni] = davg * dwts[idx+int(lni)]
		}
		idx += int(nn)
		if ly.Params.IsLearnTrgAvg() {
			for lni := uint32(0); lni < nn; lni++ {
				ni := ly.NeurStIndex + lni
				NeuronAvgs[DTrgAvg, ni] = dwts[idx+int(lni)]
			}
			idx += int(nn)
		}
		for _, pj := range ly.SendPaths {
			for lni := range pj.SendCon {
				scon := pj.SendCon[lni]
				for syi := scon.Start; syi < scon.Start+scon.N; syi++ {
					syni := pj.SynStIndex + syi
					Synapses[DWt, syni] = dwts[idx+int(syi)]
					// if syni < 100 {
					// 	fmt.Printf("%d: %d = %g = %g\n", syni, syi, dwts[idx+int(syi)], Synapses[DWt, syni])
					// }
				}
			}
			idx += int(pj.NSyns)
		}
	}
	// nt.GPU.SyncSynapsesToGPU() // gpu will use dwts to update
}


